{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ã€ERNIE-4.5-VL-28Bã€‘åŸºäºERNIE-4.5-VL-28B-Paddleæœ¬åœ°åŒ–éƒ¨ç½²+RAG+å¤šAgentååŒçš„å¤šæ¨¡æ€æ™ºèƒ½åŒ»ç–—é—®è¯Šç³»ç»Ÿ\n",
    "\n",
    "## é¡¹ç›®æ¦‚è¿°\n",
    "\n",
    "æœ¬é¡¹ç›®åŸºäº**æœ¬åœ°åŒ–éƒ¨ç½²çš„ERNIE-4.5-VL-28B-A3B-Paddle**å¤šæ¨¡æ€å¤§æ¨¡å‹ï¼Œæ„å»ºäº†ä¸€ä¸ªé›†æˆRAGçŸ¥è¯†åº“æ£€ç´¢ä¸å¤šAgentååŒæœºåˆ¶çš„æ™ºèƒ½åŒ»ç–—é—®è¯Šç³»ç»Ÿã€‚é€šè¿‡FastDeployæ¡†æ¶å®ç°æ¨¡å‹çš„é«˜æ•ˆæœ¬åœ°éƒ¨ç½²ï¼Œç»“åˆChromaDBçŸ¥è¯†åº“å’Œå¤šæ¨¡æ€ç†è§£èƒ½åŠ›ï¼Œä¸ºç”¨æˆ·æä¾›ä¸“ä¸šçš„åŒ»ç–—å’¨è¯¢æœåŠ¡ã€‚\n",
    "\n",
    "### ğŸ¯ é¡¹ç›®äº®ç‚¹\n",
    "\n",
    "- **ğŸ¥ å®Œæ•´åŒ»ç–—åœºæ™¯**ï¼šä»ç—‡çŠ¶æè¿°åˆ°æ²»ç–—å»ºè®®çš„å…¨æµç¨‹æ™ºèƒ½é—®è¯Š\n",
    "- **ğŸ–¼ï¸ å¤šæ¨¡æ€èåˆ**ï¼šæ”¯æŒæ–‡æœ¬+å›¾åƒçš„æ··åˆè¾“å…¥ï¼Œå¯åˆ†æçš®è‚¤ç—…å˜ç­‰åŒ»ç–—å›¾åƒ  \n",
    "- **ğŸ§  æœ¬åœ°åŒ–éƒ¨ç½²**ï¼šåŸºäºERNIE-4.5-VL-28B-A3B-Paddleçš„å®Œå…¨æœ¬åœ°åŒ–æ–¹æ¡ˆï¼Œæ•°æ®å®‰å…¨å¯æ§\n",
    "- **ğŸ“š çŸ¥è¯†åº“é©±åŠ¨**ï¼šChromaDBæ„å»ºçš„åŒ»å­¦çŸ¥è¯†åº“ï¼Œæ”¯æŒç—‡çŠ¶ã€ç–¾ç—…ã€æ²»ç–—æ–¹æ¡ˆçš„æ™ºèƒ½æ£€ç´¢\n",
    "- **ğŸ¤– å¤šAgentååŒ**ï¼šç—‡çŠ¶è§£æã€çŸ¥è¯†æ£€ç´¢ã€è¯Šæ–­å†³ç­–ç­‰ä¸“ä¸šAgentçš„ååŒå·¥ä½œ\n",
    "- **âš¡ é«˜æ€§èƒ½æ¨ç†**ï¼šFastDeployåŠ é€Ÿæ¡†æ¶ï¼Œå•æœºå¤šå¡éƒ¨ç½²ï¼Œæ¨ç†å»¶è¿Ÿä¼˜åŒ–\n",
    "\n",
    "### ğŸ—ï¸ ç³»ç»Ÿæ¶æ„å›¾\n",
    "\n",
    "```mermaid\n",
    "graph TD\n",
    "    A[ç”¨æˆ·é—®è¯Šè¾“å…¥] --> B[Gradioå‰ç«¯ç•Œé¢]\n",
    "    B --> C[MedicalConsultation]\n",
    "    C --> D[AgentCoordinatoråè°ƒå™¨]\n",
    "    \n",
    "    D --> E[ERNIE-4.5-VLæœ¬åœ°æ¨¡å‹]\n",
    "    E --> F[FastDeployæ¨ç†å¼•æ“]\n",
    "    F --> G[å¤šæ¨¡æ€ç†è§£]\n",
    "    \n",
    "    D --> H[SymptomParserAgent]\n",
    "    D --> I[KnowledgeRetrievalAgent] \n",
    "    D --> J[DiagnosisAgent]\n",
    "    \n",
    "    I --> K[ChromaDBçŸ¥è¯†åº“]\n",
    "    K --> L[ç—‡çŠ¶åº“]\n",
    "    K --> M[ç–¾ç—…åº“]\n",
    "    K --> N[æ²»ç–—åº“]\n",
    "    \n",
    "    H --> O[ç—‡çŠ¶æå–]\n",
    "    I --> P[çŸ¥è¯†æ£€ç´¢]\n",
    "    J --> Q[é£é™©è¯„ä¼°]\n",
    "    J --> R[æ²»ç–—å»ºè®®]\n",
    "    \n",
    "    O --> S[è¯Šæ–­ç»“æœæ•´åˆ]\n",
    "    P --> S\n",
    "    Q --> S\n",
    "    R --> S\n",
    "    \n",
    "    S --> T[ç»“æ„åŒ–åŒ»ç–—æŠ¥å‘Š]\n",
    "    T --> B\n",
    "```\n",
    "\n",
    "### ğŸ† æŠ€æœ¯åˆ›æ–°æ€»ç»“\n",
    "\n",
    "æœ¬é¡¹ç›®å®ç°äº†ä»**å¤§æ¨¡å‹æœ¬åœ°åŒ–éƒ¨ç½²**åˆ°**æ™ºèƒ½åŒ»ç–—åº”ç”¨**çš„å®Œæ•´æŠ€æœ¯é“¾è·¯ï¼š\n",
    "\n",
    "1. **ğŸ”¥ æ ¸å¿ƒçªç ´**ï¼š28Bå‚æ•°ERNIE-4.5-VLå¤šæ¨¡æ€å¤§æ¨¡å‹çš„é«˜æ•ˆæœ¬åœ°åŒ–éƒ¨ç½²\n",
    "2. **ğŸ§  æ™ºèƒ½å‡çº§**ï¼šRAGçŸ¥è¯†åº“æ£€ç´¢ + å¤šAgentååŒçš„åŒ»ç–—ä¸“å®¶ç³»ç»Ÿ  \n",
    "3. **ğŸ›¡ï¸ æ•°æ®å®‰å…¨**ï¼šå®Œå…¨æœ¬åœ°åŒ–æ–¹æ¡ˆï¼Œæ‚£è€…éšç§é›¶æ³„éœ²\n",
    "4. **âš¡ æ€§èƒ½ä¼˜åŒ–**ï¼šFastDeployæ¨ç†åŠ é€Ÿï¼Œç§’çº§å“åº”åŒ»ç–—é—®è¯Š\n",
    "\n",
    "### ğŸ› ï¸ æŠ€æœ¯æ ˆé€‰æ‹©\n",
    "\n",
    "| å±‚çº§ | æŠ€æœ¯ç»„ä»¶ | ç‰ˆæœ¬ | ä½œç”¨ |\n",
    "|------|---------|------|------|\n",
    "| **AIæ¨¡å‹å±‚** | ERNIE-4.5-VL-28B-A3B-Paddle | 28Bå‚æ•° | å¤šæ¨¡æ€ç†è§£ä¸ç”Ÿæˆ |\n",
    "| **æ¨ç†æ¡†æ¶** | FastDeploy | æœ€æ–°ç‰ˆ | æ¨¡å‹éƒ¨ç½²ä¸æ¨ç†åŠ é€Ÿ |\n",
    "| **çŸ¥è¯†åº“** | ChromaDB | 1.0.15 | å‘é‡æ•°æ®åº“ä¸è¯­ä¹‰æ£€ç´¢ |\n",
    "| **Webæ¡†æ¶** | Gradio | 5.35.0 | äº¤äº’å¼ç”¨æˆ·ç•Œé¢ |\n",
    "| **Agentæ¡†æ¶** | è‡ªç ”å¤šAgentç³»ç»Ÿ | - | ä»»åŠ¡åè°ƒä¸ä¸šåŠ¡é€»è¾‘ |\n",
    "| **æ•°æ®å¤„ç†** | Pillow + NumPy | 10.2.0 + 1.24.3 | å›¾åƒå¤„ç†ä¸æ•°å€¼è®¡ç®— |\n",
    "\n",
    "## ğŸ¥ æ™ºèƒ½åŒ»ç–—é—®è¯Šç³»ç»Ÿå®ç°\n",
    "\n",
    "### æ ¸å¿ƒåŠŸèƒ½æ¨¡å—\n",
    "\n",
    "#### 1. å¤šæ¨¡æ€è¾“å…¥å¤„ç†\n",
    "```python\n",
    "class ErnieClient:\n",
    "    def medical_image_analysis(self, image_path: str) -> str:\n",
    "        \"\"\"åŒ»ç–—å›¾åƒåˆ†æ\"\"\"\n",
    "        with open(image_path, \"rb\") as image_file:\n",
    "            base64_image = base64.b64encode(image_file.read()).decode(\"utf-8\")\n",
    "        \n",
    "        messages = [{\n",
    "            \"role\": \"user\", \n",
    "            \"content\": [\n",
    "                {\"type\": \"image_url\", \"image_url\": {\"url\": f\"data:image/jpeg;base64,{base64_image}\"}},\n",
    "                {\"type\": \"text\", \"text\": \"è¯·åˆ†æè¿™å¼ åŒ»ç–—å›¾åƒï¼Œæè¿°å¯è§çš„ç—‡çŠ¶ç‰¹å¾\"}\n",
    "            ]\n",
    "        }]\n",
    "        # è°ƒç”¨æœ¬åœ°ERNIE-4.5-VLæ¨¡å‹\n",
    "        return self._call_local_model(messages)\n",
    "```\n",
    "\n",
    "#### 2. çŸ¥è¯†åº“æ£€ç´¢ç³»ç»Ÿ\n",
    "```python\n",
    "class KnowledgeBase:\n",
    "    def __init__(self, persist_directory=\"medical_kb\"):\n",
    "        # ä½¿ç”¨ChromaDBæ„å»ºåŒ»å­¦çŸ¥è¯†åº“\n",
    "        self.client = chromadb.PersistentClient(path=persist_directory)\n",
    "        \n",
    "        # åˆ›å»ºä¸“ä¸šåŒ»å­¦é›†åˆ\n",
    "        self.symptoms_collection = self.client.get_or_create_collection(\"symptoms\")\n",
    "        self.diseases_collection = self.client.get_or_create_collection(\"diseases\")  \n",
    "        self.treatments_collection = self.client.get_or_create_collection(\"treatments\")\n",
    "```\n",
    "\n",
    "#### 3. å¤šAgentååŒç³»ç»Ÿ\n",
    "```python\n",
    "class AgentCoordinator:\n",
    "    def process_consultation(self, text_input: str, image_path: str = None):\n",
    "        # 1. å›¾åƒåˆ†æï¼ˆå¦‚æœæä¾›ï¼‰\n",
    "        image_analysis = self.ernie.medical_image_analysis(image_path) if image_path else None\n",
    "        \n",
    "        # 2. ç—‡çŠ¶è§£æAgent\n",
    "        symptoms = self.symptom_parser.parse_symptoms(text_input, image_analysis)\n",
    "        \n",
    "        # 3. çŸ¥è¯†æ£€ç´¢Agent  \n",
    "        medical_info = self.knowledge_retriever.retrieve_relevant_info(symptoms)\n",
    "        \n",
    "        # 4. è¯Šæ–­å†³ç­–Agent\n",
    "        risk_assessment = self.diagnosis_agent.analyze_risk_level(symptoms, medical_info)\n",
    "        treatment_plan = self.diagnosis_agent.generate_treatment_plan(symptoms, medical_info)\n",
    "        \n",
    "        return {\n",
    "            \"symptoms\": symptoms,\n",
    "            \"risk_assessment\": risk_assessment, \n",
    "            \"treatment_plan\": treatment_plan,\n",
    "            \"image_analysis\": image_analysis\n",
    "        }\n",
    "```\n",
    "\n",
    "### ğŸ¯ åº”ç”¨åœºæ™¯ä¸æ•ˆæœ\n",
    "\n",
    "#### å…¸å‹ä½¿ç”¨æµç¨‹\n",
    "1. **ç”¨æˆ·è¾“å…¥**ï¼šæè¿°ç—‡çŠ¶ + ä¸Šä¼ ç—…å˜å›¾ç‰‡ï¼ˆå¯é€‰ï¼‰\n",
    "2. **å¤šæ¨¡æ€åˆ†æ**ï¼šERNIE-4.5-VLåŒæ—¶ç†è§£æ–‡æœ¬å’Œå›¾åƒ\n",
    "3. **ç—‡çŠ¶æå–**ï¼šAIè¯†åˆ«å…³é”®ç—‡çŠ¶å’ŒåŒ»å­¦æœ¯è¯­\n",
    "4. **çŸ¥è¯†æ£€ç´¢**ï¼šä»ä¸“ä¸šåŒ»å­¦åº“ä¸­æ£€ç´¢ç›¸å…³ç–¾ç—…ä¿¡æ¯\n",
    "5. **é£é™©è¯„ä¼°**ï¼šè¯„ä¼°ç—…æƒ…ä¸¥é‡ç¨‹åº¦å’Œå°±åŒ»ç´§æ€¥æ€§\n",
    "6. **æ²»ç–—å»ºè®®**ï¼šç”Ÿæˆä¸ªæ€§åŒ–çš„æ£€æŸ¥ã€ç”¨è¯å’Œç”Ÿæ´»å»ºè®®\n",
    "\n",
    "#### ç³»ç»Ÿä¼˜åŠ¿\n",
    "- **æ•°æ®å®‰å…¨**ï¼šå®Œå…¨æœ¬åœ°åŒ–éƒ¨ç½²ï¼Œæ‚£è€…æ•°æ®ä¸å‡ºæœ¬åœ°\n",
    "- **ä¸“ä¸šå‡†ç¡®**ï¼šåŸºäº28Bå‚æ•°çš„ä¸“ä¸šåŒ»å­¦æ¨¡å‹\n",
    "- **å“åº”å¿«é€Ÿ**ï¼šæœ¬åœ°æ¨ç†ï¼Œæ— ç½‘ç»œå»¶è¿Ÿ\n",
    "- **æŒç»­å­¦ä¹ **ï¼šçŸ¥è¯†åº“å¯ä¸æ–­æ‰©å……å’Œæ›´æ–°\n",
    "\n",
    "## ğŸ§  ERNIE-4.5-VL-28B-A3B-Paddleæ¨¡å‹é€‰æ‹©\n",
    "\n",
    "### ä¸ºä»€ä¹ˆé€‰æ‹©ERNIE-4.5-VL-28B-A3B-Paddleï¼Ÿ\n",
    "\n",
    "#### æ–‡å¿ƒå¼€æºæ¨¡å‹çš„é€‰æ‹©\n",
    "\n",
    "### ERNIE-4.5æ¨¡å‹ç³»åˆ—è§„æ ¼å¯¹æ¯”è¡¨\n",
    "\n",
    "| æ¨¡å‹ç³»åˆ— | æ¨¡å‹åç§° | æ€»å‚æ•° | æ¿€æ´»å‚æ•° | æ¨¡æ€æ”¯æŒ | ä¸Šä¸‹æ–‡é•¿åº¦ | ä¸»è¦ç”¨é€” | éƒ¨ç½²åœºæ™¯ |\n",
    "|---------|---------|--------|---------|---------|-----------|---------|---------|\n",
    "| **A47Bå¤§è§„æ¨¡** | ERNIE-4.5-300B-A47B-Base | 300B | 47B | æ–‡æœ¬ | 128K | é¢„è®­ç»ƒåŸºåº§ | äº‘ç«¯GPUé›†ç¾¤ |\n",
    "| | ERNIE-4.5-300B-A47B | 300B | 47B | æ–‡æœ¬ | 128K | æŒ‡ä»¤éµå¾ª/åˆ›æ„ç”Ÿæˆ | äº‘ç«¯GPUé›†ç¾¤ |\n",
    "| | ERNIE-4.5-VL-424B-A47B-Base | 424B | 47B | æ–‡æœ¬+è§†è§‰ | 128K | å¤šæ¨¡æ€é¢„è®­ç»ƒ | äº‘ç«¯GPUé›†ç¾¤ |\n",
    "| | ERNIE-4.5-VL-424B-A47B | 424B | 47B | æ–‡æœ¬+è§†è§‰ | 128K | å›¾æ–‡ç†è§£/ç”Ÿæˆ | äº‘ç«¯GPUé›†ç¾¤ |\n",
    "| **A3Bä¸­ç­‰è§„æ¨¡** | ERNIE-4.5-21B-A3B-Base | 21B | 3B | æ–‡æœ¬ | 128K | é¢„è®­ç»ƒåŸºåº§ | å•æœºå¤šå¡ |\n",
    "| | ERNIE-4.5-21B-A3B | 21B | 3B | æ–‡æœ¬ | 128K | å¯¹è¯/æ–‡æ¡£å¤„ç† | å•æœºå¤šå¡ |\n",
    "| | ERNIE-4.5-VL-28B-A3B-Base | 28B | 3B | æ–‡æœ¬+è§†è§‰ | 128K | å¤šæ¨¡æ€é¢„è®­ç»ƒ | å•æœºå¤šå¡ |\n",
    "| | ERNIE-4.5-VL-28B-A3B | 28B | 3B | æ–‡æœ¬+è§†è§‰ | 128K | è½»é‡å¤šæ¨¡æ€åº”ç”¨ | å•æœºå¤šå¡ |\n",
    "| **0.3Bè½»é‡** | ERNIE-4.5-0.3B-Base | 0.3B | 0.3B | æ–‡æœ¬ | 4K | ç«¯ä¾§é¢„è®­ç»ƒ | ç§»åŠ¨ç«¯/è¾¹ç¼˜ |\n",
    "| | ERNIE-4.5-0.3B | 0.3B | 0.3B | æ–‡æœ¬ | 4K | å®æ—¶å¯¹è¯ | ç§»åŠ¨ç«¯/è¾¹ç¼˜ |\n",
    "\n",
    "### æ¨¡å‹è§„æ ¼é€‰æ‹©ç­–ç•¥è¡¨\n",
    "\n",
    "| åº”ç”¨åœºæ™¯ | æ¨èæ¨¡å‹ | ç†ç”± | ç¡¬ä»¶è¦æ±‚ | æ¨ç†å»¶è¿Ÿ |\n",
    "|---------|---------|------|---------|---------|\n",
    "| **å¤æ‚æ¨ç†ä»»åŠ¡** | ERNIE-4.5-300B-A47B | æœ€å¼ºæ¨ç†èƒ½åŠ› | 8Ã—A100(80GB) | é«˜ |\n",
    "| **åˆ›æ„å†…å®¹ç”Ÿæˆ** | ERNIE-4.5-300B-A47B | æœ€ä½³åˆ›æ„è¡¨ç° | 8Ã—A100(80GB) | é«˜ |\n",
    "| **å¤šæ¨¡æ€ç†è§£** | ERNIE-4.5-VL-424B-A47B | å›¾æ–‡èåˆç†è§£ | 8Ã—A100(80GB) | é«˜ |\n",
    "| **æ—¥å¸¸å¯¹è¯å®¢æœ** | ERNIE-4.5-21B-A3B | æ€§èƒ½æˆæœ¬å¹³è¡¡ | 4Ã—V100(32GB) | ä¸­ |\n",
    "| **æ–‡æ¡£ä¿¡æ¯æŠ½å–** | ERNIE-4.5-21B-A3B | ç†è§£èƒ½åŠ›å……è¶³ | 4Ã—V100(32GB) | ä¸­ |\n",
    "| **è½»é‡å¤šæ¨¡æ€** | ERNIE-4.5-VL-28B-A3B | å›¾æ–‡å¤„ç†å‡è¡¡ | 4Ã—V100(32GB) | ä¸­ |\n",
    "| **ç§»åŠ¨ç«¯åº”ç”¨** | ERNIE-4.5-0.3B | ä½å»¶è¿Ÿå¿«å“åº” | 1Ã—GPU/CPU | ä½ |\n",
    "| **è¾¹ç¼˜è®¡ç®—** | ERNIE-4.5-0.3B | èµ„æºæ¶ˆè€—æœ€å° | CPU/NPU | ä½ |\n",
    "\n",
    "### ä¸ºä»€ä¹ˆé€‰æ‹©ERNIE-4.5-VL-28B-A3B-Paddleæ¨¡å‹ï¼Ÿ\n",
    "\n",
    "#### 1. **æ€§èƒ½ä¸æˆæœ¬çš„æœ€ä½³å¹³è¡¡**\n",
    "- **å‚æ•°è§„æ¨¡é€‚ä¸­**ï¼š28Bæ€»å‚æ•°ï¼Œ3Bæ¿€æ´»å‚æ•°ï¼Œåœ¨ä¿è¯æ¨ç†èƒ½åŠ›çš„åŒæ—¶æ§åˆ¶äº†è®¡ç®—æˆæœ¬\n",
    "- **ç¡¬ä»¶è¦æ±‚åˆç†**ï¼šæ”¯æŒå•æœºå¤šå¡éƒ¨ç½²ï¼ˆ4Ã—V100æˆ–2Ã—A100ï¼‰ï¼Œç›¸æ¯”A47Bç³»åˆ—é™ä½äº†75%çš„ç¡¬ä»¶é—¨æ§›\n",
    "- **æ¨ç†å»¶è¿Ÿé€‚ä¸­**ï¼šåœ¨ä¿è¯è¾“å‡ºè´¨é‡çš„å‰æä¸‹ï¼Œå“åº”é€Ÿåº¦æ¯”å¤§è§„æ¨¡æ¨¡å‹å¿«3-5å€\n",
    "\n",
    "#### 2. **å¤šæ¨¡æ€èƒ½åŠ›çªå‡º**\n",
    "- **æ–‡æœ¬+è§†è§‰èåˆ**ï¼šåŸç”Ÿæ”¯æŒå›¾æ–‡ç†è§£ï¼Œæ— éœ€é¢å¤–çš„è§†è§‰ç¼–ç å™¨\n",
    "- **é•¿ä¸Šä¸‹æ–‡æ”¯æŒ**ï¼š128K tokenä¸Šä¸‹æ–‡é•¿åº¦ï¼Œå¯å¤„ç†é•¿æ–‡æ¡£å’Œå¤šå¼ å›¾ç‰‡\n",
    "- **åº”ç”¨åœºæ™¯ä¸°å¯Œ**ï¼šé€‚åˆæ–‡æ¡£åˆ†æã€å›¾åƒæè¿°ã€å¤šæ¨¡æ€é—®ç­”ç­‰ä»»åŠ¡\n",
    "\n",
    "#### 3. **éƒ¨ç½²å‹å¥½æ€§**\n",
    "- **AIStudioå¹³å°ä¼˜åŒ–**ï¼šå®˜æ–¹æ·±åº¦é€‚é…ï¼Œæä¾›ä¸€é”®ä¸‹è½½å’Œéƒ¨ç½²\n",
    "- **FastDeployé›†æˆ**ï¼šå®Œæ•´çš„æ¨ç†åŠ é€Ÿå’ŒæœåŠ¡åŒ–æ”¯æŒ\n",
    "- **å¼€æºç”Ÿæ€**ï¼šPaddlePaddleç”Ÿæ€ç³»ç»Ÿï¼Œæ–‡æ¡£å®Œå–„ï¼Œç¤¾åŒºæ´»è·ƒ\n",
    "\n",
    "#### 4. **å®é™…åº”ç”¨ä»·å€¼**\n",
    "- **ä¼ä¸šçº§å¯ç”¨**ï¼šç›¸æ¯”0.3Bæ¨¡å‹ï¼Œç†è§£èƒ½åŠ›å’Œç”Ÿæˆè´¨é‡æ˜¾è‘—æå‡\n",
    "- **æˆæœ¬å¯æ§**ï¼šç›¸æ¯”A47Bç³»åˆ—ï¼Œéƒ¨ç½²æˆæœ¬é™ä½70%ï¼Œè¿è¥æˆæœ¬é™ä½60%\n",
    "- **æ‰©å±•æ€§å¼º**ï¼šæ”¯æŒLoRAå¾®è°ƒï¼Œå¯é’ˆå¯¹ç‰¹å®šåœºæ™¯è¿›è¡Œä¼˜åŒ–\n",
    "\n",
    "#### 5. **æŠ€æœ¯å…ˆè¿›æ€§**\n",
    "- **MoEæ¶æ„**ï¼šä¸“å®¶æ··åˆæ¨¡å‹ï¼Œæ¿€æ´»å‚æ•°ä»…ä¸ºæ€»å‚æ•°çš„1/9ï¼Œæ¨ç†æ•ˆç‡é«˜\n",
    "- **å¤šæ¨¡æ€å¯¹é½**ï¼šè§†è§‰å’Œæ–‡æœ¬ç‰¹å¾æ·±åº¦èåˆï¼Œç†è§£èƒ½åŠ›æ¥è¿‘GPT-4V\n",
    "- **ä¸­æ–‡ä¼˜åŒ–**ï¼šé’ˆå¯¹ä¸­æ–‡åœºæ™¯æ·±åº¦ä¼˜åŒ–ï¼Œåœ¨ä¸­æ–‡å¤šæ¨¡æ€ä»»åŠ¡ä¸Šè¡¨ç°ä¼˜å¼‚\n",
    "\n",
    "#### é€‰æ‹©å»ºè®®\n",
    "**æ¨èåœºæ™¯**ï¼š\n",
    "- ä¸­å°ä¼ä¸šå¤šæ¨¡æ€AIåº”ç”¨å¼€å‘\n",
    "- æ•™è‚²ç§‘ç ”é¡¹ç›®çš„å¤šæ¨¡æ€å®éªŒ\n",
    "- ä¸ªäººå¼€å‘è€…çš„AIäº§å“åŸå‹éªŒè¯\n",
    "- éœ€è¦å›¾æ–‡ç†è§£èƒ½åŠ›çš„ä¸šåŠ¡ç³»ç»Ÿ\n",
    "\n",
    "**ä¸æ¨èåœºæ™¯**ï¼š\n",
    "- å¯¹æ¨ç†å»¶è¿Ÿè¦æ±‚æé«˜çš„å®æ—¶ç³»ç»Ÿï¼ˆé€‰æ‹©0.3Bï¼‰\n",
    "- é¢„ç®—å……è¶³ä¸”è¿½æ±‚æè‡´æ€§èƒ½çš„åœºæ™¯ï¼ˆé€‰æ‹©A47Bï¼‰\n",
    "- çº¯æ–‡æœ¬åº”ç”¨ä¸”å¯¹å¤šæ¨¡æ€æ— éœ€æ±‚ï¼ˆé€‰æ‹©21B-A3Bï¼‰\n",
    "\n",
    "## ğŸš€ ERNIE-4.5-VLæ¨¡å‹æœ¬åœ°åŒ–éƒ¨ç½²æ–¹æ¡ˆ\n",
    "\n",
    "### ä¸€ã€ç¯å¢ƒå‡†å¤‡\n",
    "### 1. ç¡¬ä»¶è¦æ±‚\n",
    "- **GPU**ï¼šNVIDIA A100 80GBï¼ˆæ”¯æŒå•å¡/å¤šå¡ï¼Œæ¨èCUDA 11.8+ï¼‰  \n",
    "- **å†…å­˜**ï¼šâ‰¥60GB RAM  \n",
    "- **å­˜å‚¨**ï¼šâ‰¥60GBï¼ˆæ¨¡å‹çº¦28GBï¼Œéœ€é¢„ç•™æ—¥å¿—/ç¼“å­˜ç©ºé—´ï¼‰  \n",
    "\n",
    "### 2. è½¯ä»¶ä¾èµ–"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-07-06T13:00:11.836046Z",
     "iopub.status.busy": "2025-07-06T13:00:11.835593Z"
    },
    "scrolled": true,
    "tags": []
   },
   "outputs": [],
   "source": [
    "%%capture\n",
    "!python -m pip install fastdeploy-gpu -i https://www.paddlepaddle.org.cn/packages/stable/fastdeploy-gpu-80_90/ --extra-index-url https://mirrors.tuna.tsinghua.edu.cn/pypi/web/simple"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. ç¯å¢ƒéªŒè¯\n",
    "#### â‘  æ£€æŸ¥CUDAç‰ˆæœ¬"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-07-07T17:25:11.092125Z",
     "iopub.status.busy": "2025-07-07T17:25:11.091792Z",
     "iopub.status.idle": "2025-07-07T17:25:11.310890Z",
     "shell.execute_reply": "2025-07-07T17:25:11.310222Z",
     "shell.execute_reply.started": "2025-07-07T17:25:11.092105Z"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "nvcc: NVIDIA (R) Cuda compiler driver\r\n",
      "Copyright (c) 2005-2024 NVIDIA Corporation\r\n",
      "Built on Tue_Oct_29_23:50:19_PDT_2024\r\n",
      "Cuda compilation tools, release 12.6, V12.6.85\r\n",
      "Build cuda_12.6.r12.6/compiler.35059454_0\r\n"
     ]
    }
   ],
   "source": [
    "!nvcc --version\n",
    "# é¢„æœŸè¾“å‡ºç¤ºä¾‹ï¼š"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### â‘¡ æ£€æŸ¥GPUä¿¡æ¯"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-07-07T17:25:27.824496Z",
     "iopub.status.busy": "2025-07-07T17:25:27.824188Z",
     "iopub.status.idle": "2025-07-07T17:25:28.730838Z",
     "shell.execute_reply": "2025-07-07T17:25:28.730260Z",
     "shell.execute_reply.started": "2025-07-07T17:25:27.824477Z"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tue Jul  8 01:25:28 2025       \r\n",
      "+-----------------------------------------------------------------------------------------+\r\n",
      "| NVIDIA-SMI 570.148.08             Driver Version: 570.148.08     CUDA Version: 12.8     |\r\n",
      "|-----------------------------------------+------------------------+----------------------+\r\n",
      "| GPU  Name                 Persistence-M | Bus-Id          Disp.A | Volatile Uncorr. ECC |\r\n",
      "| Fan  Temp   Perf          Pwr:Usage/Cap |           Memory-Usage | GPU-Util  Compute M. |\r\n",
      "|                                         |                        |               MIG M. |\r\n",
      "|=========================================+========================+======================|\r\n",
      "|   0  NVIDIA A800-SXM4-80GB          On  |   00000000:D3:00.0 Off |                    0 |\r\n",
      "| N/A   41C    P0             66W /  400W |       0MiB /  81920MiB |      0%      Default |\r\n",
      "|                                         |                        |             Disabled |\r\n",
      "+-----------------------------------------+------------------------+----------------------+\r\n",
      "                                                                                         \r\n",
      "+-----------------------------------------------------------------------------------------+\r\n",
      "| Processes:                                                                              |\r\n",
      "|  GPU   GI   CI              PID   Type   Process name                        GPU Memory |\r\n",
      "|        ID   ID                                                               Usage      |\r\n",
      "|=========================================================================================|\r\n",
      "|  No running processes found                                                             |\r\n",
      "+-----------------------------------------------------------------------------------------+\r\n"
     ]
    }
   ],
   "source": [
    "# æ£€æŸ¥GPUçŠ¶æ€å’Œæ˜¾å­˜\n",
    "!nvidia-smi\n",
    "# é¢„æœŸè¾“å‡ºç¤ºä¾‹ï¼š"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### â‘¢ å¸¸è§ç¯å¢ƒé—®é¢˜æ’æŸ¥"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [],
   "source": [
    "# æ£€æŸ¥PaddlePaddle GPUæ”¯æŒ\n",
    "!python -c \"import paddle; print('GPUå¯ç”¨:', paddle.is_compiled_with_cuda()); print('GPUè®¾å¤‡æ•°:', paddle.device.cuda.device_count())\"\n",
    "\n",
    "# æ£€æŸ¥FastDeployå®‰è£…\n",
    "!python -c \"from fastdeploy import LLM, SamplingParams; print('FastDeployå®‰è£…æˆåŠŸï¼')\"\n",
    "\n",
    "# æ£€æŸ¥OpenAIåº“ç‰ˆæœ¬\n",
    "!python -c \"import openai; print('OpenAIåº“ç‰ˆæœ¬:', openai.__version__)\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## äºŒã€æ¨¡å‹ä¸‹è½½ä¸ç›®å½•ç»“æ„\n",
    "### 1. ä¸‹è½½æ¨¡å‹æ–‡ä»¶"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [],
   "source": [
    "%%capture\n",
    "# ä½¿ç”¨AIStudioå‘½ä»¤ä¸‹è½½æ¨¡å‹\n",
    "!aistudio download --model PaddlePaddle/ERNIE-4.5-VL-28B-A3B-Paddle --local_dir /home/aistudio/work/models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-07-07T17:28:11.223932Z",
     "iopub.status.busy": "2025-07-07T17:28:11.223616Z",
     "iopub.status.idle": "2025-07-07T17:28:11.427076Z",
     "shell.execute_reply": "2025-07-07T17:28:11.426503Z",
     "shell.execute_reply.started": "2025-07-07T17:28:11.223912Z"
    },
    "scrolled": true,
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "total 57441133\r\n",
      "-rw-r--r-- 1 aistudio aistudio      11366 Jul  6 18:57 LICENSE\r\n",
      "-rw-r--r-- 1 aistudio aistudio       9077 Jul  6 18:56 README.md\r\n",
      "-rw-r--r-- 1 aistudio aistudio      86904 Jul  6 18:56 added_tokens.json\r\n",
      "-rw-r--r-- 1 aistudio aistudio       1306 Jul  6 18:57 config.json\r\n",
      "-rw-r--r-- 1 aistudio aistudio        134 Jul  6 18:57 generation_config.json\r\n",
      "-rw-r--r-- 1 aistudio aistudio 4991326368 Jul  6 18:57 model-00001-of-00012.safetensors\r\n",
      "-rw-r--r-- 1 aistudio aistudio 4988696384 Jul  6 18:56 model-00002-of-00012.safetensors\r\n",
      "-rw-r--r-- 1 aistudio aistudio 4999185600 Jul  6 18:56 model-00003-of-00012.safetensors\r\n",
      "-rw-r--r-- 1 aistudio aistudio 4995268296 Jul  6 18:57 model-00004-of-00012.safetensors\r\n",
      "-rw-r--r-- 1 aistudio aistudio 4988696984 Jul  6 18:56 model-00005-of-00012.safetensors\r\n",
      "-rw-r--r-- 1 aistudio aistudio 4999193256 Jul  6 18:57 model-00006-of-00012.safetensors\r\n",
      "-rw-r--r-- 1 aistudio aistudio 4995261896 Jul  6 18:57 model-00007-of-00012.safetensors\r\n",
      "-rw-r--r-- 1 aistudio aistudio 4999183248 Jul  6 18:56 model-00008-of-00012.safetensors\r\n",
      "-rw-r--r-- 1 aistudio aistudio 4995271816 Jul  6 18:57 model-00009-of-00012.safetensors\r\n",
      "-rw-r--r-- 1 aistudio aistudio 4988696992 Jul  6 18:57 model-00010-of-00012.safetensors\r\n",
      "-rw-r--r-- 1 aistudio aistudio 4999190216 Jul  6 18:57 model-00011-of-00012.safetensors\r\n",
      "-rw-r--r-- 1 aistudio aistudio 3877260800 Jul  6 18:57 model-00012-of-00012.safetensors\r\n",
      "-rw-r--r-- 1 aistudio aistudio     691887 Jul  6 18:56 model.safetensors.index.json\r\n",
      "-rw-r--r-- 1 aistudio aistudio        615 Jul  6 18:56 preprocessor_config.json\r\n",
      "-rw-r--r-- 1 aistudio aistudio      62694 Jul  6 18:56 special_tokens_map.json\r\n",
      "-rw-r--r-- 1 aistudio aistudio    1614362 Jul  6 18:56 tokenizer.model\r\n",
      "-rw-r--r-- 1 aistudio aistudio       3606 Jul  6 18:56 tokenizer_config.json\r\n"
     ]
    }
   ],
   "source": [
    "# æŸ¥çœ‹æ¨¡å‹æ–‡ä»¶\n",
    "!ls -l work/models"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. ç›®å½•ç»“æ„\n",
    "```\n",
    "work/\n",
    "â””â”€â”€ models/\n",
    "    â”œâ”€â”€ LICENSE                           # è®¸å¯è¯æ–‡ä»¶\n",
    "    â”œâ”€â”€ README.md                         # æ¨¡å‹è¯´æ˜æ–‡æ¡£\n",
    "    â”œâ”€â”€ added_tokens.json                 # æ–°å¢tokené…ç½®\n",
    "    â”œâ”€â”€ config.json                       # æ¨¡å‹é…ç½®æ–‡ä»¶\n",
    "    â”œâ”€â”€ generation_config.json            # ç”Ÿæˆé…ç½®æ–‡ä»¶\n",
    "    â”œâ”€â”€ model-00001-of-00012.safetensors  # æ¨¡å‹å‚æ•°æ–‡ä»¶(åˆ†ç‰‡1/12)\n",
    "    â”œâ”€â”€ model-00002-of-00012.safetensors  # æ¨¡å‹å‚æ•°æ–‡ä»¶(åˆ†ç‰‡2/12)\n",
    "    â”œâ”€â”€ model-00003-of-00012.safetensors  # æ¨¡å‹å‚æ•°æ–‡ä»¶(åˆ†ç‰‡3/12)\n",
    "    â”œâ”€â”€ model-00004-of-00012.safetensors  # æ¨¡å‹å‚æ•°æ–‡ä»¶(åˆ†ç‰‡4/12)\n",
    "    â”œâ”€â”€ model-00005-of-00012.safetensors  # æ¨¡å‹å‚æ•°æ–‡ä»¶(åˆ†ç‰‡5/12)\n",
    "    â”œâ”€â”€ model-00006-of-00012.safetensors  # æ¨¡å‹å‚æ•°æ–‡ä»¶(åˆ†ç‰‡6/12)\n",
    "    â”œâ”€â”€ model-00007-of-00012.safetensors  # æ¨¡å‹å‚æ•°æ–‡ä»¶(åˆ†ç‰‡7/12)\n",
    "    â”œâ”€â”€ model-00008-of-00012.safetensors  # æ¨¡å‹å‚æ•°æ–‡ä»¶(åˆ†ç‰‡8/12)\n",
    "    â”œâ”€â”€ model-00009-of-00012.safetensors  # æ¨¡å‹å‚æ•°æ–‡ä»¶(åˆ†ç‰‡9/12)\n",
    "    â”œâ”€â”€ model-00010-of-00012.safetensors  # æ¨¡å‹å‚æ•°æ–‡ä»¶(åˆ†ç‰‡10/12)\n",
    "    â”œâ”€â”€ model-00011-of-00012.safetensors  # æ¨¡å‹å‚æ•°æ–‡ä»¶(åˆ†ç‰‡11/12)\n",
    "    â”œâ”€â”€ model-00012-of-00012.safetensors  # æ¨¡å‹å‚æ•°æ–‡ä»¶(åˆ†ç‰‡12/12)\n",
    "    â”œâ”€â”€ model.safetensors.index.json      # æ¨¡å‹åˆ†ç‰‡ç´¢å¼•æ–‡ä»¶\n",
    "    â”œâ”€â”€ preprocessor_config.json          # é¢„å¤„ç†å™¨é…ç½®\n",
    "    â”œâ”€â”€ special_tokens_map.json           # ç‰¹æ®Štokenæ˜ å°„\n",
    "    â”œâ”€â”€ tokenizer.model                   # åˆ†è¯å™¨æ¨¡å‹æ–‡ä»¶\n",
    "    â””â”€â”€ tokenizer_config.json             # åˆ†è¯å™¨é…ç½®æ–‡ä»¶\n",
    "```\n",
    "\n",
    "### 3. æ–‡ä»¶è¯´æ˜\n",
    "| æ–‡ä»¶ç±»å‹ | æ–‡ä»¶å | è¯´æ˜ |\n",
    "|---------|--------|------|\n",
    "| **æ¨¡å‹æƒé‡** | model-00001~00012-of-00012.safetensors | æ¨¡å‹å‚æ•°åˆ†ç‰‡æ–‡ä»¶ï¼Œå®‰å…¨å¼ é‡æ ¼å¼ |\n",
    "| **ç´¢å¼•æ–‡ä»¶** | model.safetensors.index.json | æ¨¡å‹åˆ†ç‰‡ç´¢å¼•ï¼ŒæŒ‡å®šæ¯ä¸ªå‚æ•°åœ¨å“ªä¸ªåˆ†ç‰‡ä¸­ |\n",
    "| **é…ç½®æ–‡ä»¶** | config.json | æ¨¡å‹æ¶æ„é…ç½®ï¼ŒåŒ…å«å±‚æ•°ã€éšè—å±‚å¤§å°ç­‰ |\n",
    "| **ç”Ÿæˆé…ç½®** | generation_config.json | æ–‡æœ¬ç”Ÿæˆç›¸å…³é…ç½®ï¼Œå¦‚æœ€å¤§é•¿åº¦ã€é‡‡æ ·å‚æ•°ç­‰ |\n",
    "| **åˆ†è¯å™¨** | tokenizer.model | SentencePieceåˆ†è¯å™¨æ¨¡å‹ |\n",
    "| **åˆ†è¯å™¨é…ç½®** | tokenizer_config.json | åˆ†è¯å™¨é…ç½®å‚æ•° |\n",
    "| **é¢„å¤„ç†å™¨** | preprocessor_config.json | å›¾åƒé¢„å¤„ç†é…ç½®ï¼ˆå¤šæ¨¡æ€æ¨¡å‹ä¸“ç”¨ï¼‰ |\n",
    "| **ç‰¹æ®Štoken** | special_tokens_map.json | ç‰¹æ®Šæ ‡è®°æ˜ å°„ï¼Œå¦‚paddingã€unknownç­‰ |\n",
    "| **æ–°å¢token** | added_tokens.json | ç”¨æˆ·è‡ªå®šä¹‰æ·»åŠ çš„token |\n",
    "\n",
    "## ä¸‰ã€å¯åŠ¨æœåŠ¡ï¼ˆå…³é”®å‘½ä»¤ï¼‰"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-07-06T10:57:33.976246Z",
     "iopub.status.busy": "2025-07-06T10:57:33.975924Z"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/opt/conda/envs/python35-paddle120-env/lib/python3.10/site-packages/paddle/utils/cpp_extension/extension_utils.py:715: UserWarning: No ccache found. Please be aware that recompiling all source files may be required. You can download and install ccache from: https://github.com/ccache/ccache/blob/master/doc/INSTALL.md\r\n",
      "  warnings.warn(warning_message)\r\n",
      "/home/aistudio/external-libraries/lib/python3.10/site-packages/_distutils_hack/__init__.py:30: UserWarning: Setuptools is replacing distutils. Support for replacing an already imported distutils is deprecated. In the future, this condition will fail. Register concerns at https://github.com/pypa/setuptools/issues/new?template=distutils-deprecation.yml\r\n",
      "  warnings.warn(\r\n",
      "\u001b[32m[2025-07-06 18:57:55,035] [    INFO]\u001b[0m - loading configuration file work/models/preprocessor_config.json\u001b[0m\r\n",
      "INFO     2025-07-06 18:57:58,188 5574  engine.py[line:206] Waitting worker processes ready...\r\n",
      "Loading Weights: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 100/100 [01:17<00:00,  1.30it/s]\r\n",
      "Loading Layers: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 100/100 [00:07<00:00, 13.31it/s]\r\n",
      "INFO     2025-07-06 18:59:35,857 5574  engine.py[line:276] Worker processes are launched with 119.6253821849823 seconds.\r\n",
      "INFO     2025-07-06 18:59:35,857 5574  api_server.py[line:91] Launching metrics service at http://0.0.0.0:8181/metrics\r\n",
      "INFO     2025-07-06 18:59:35,857 5574  api_server.py[line:94] Launching chat completion service at http://0.0.0.0:8180/v1/chat/completions\r\n",
      "INFO     2025-07-06 18:59:35,857 5574  api_server.py[line:97] Launching completion service at http://0.0.0.0:8180/v1/completions\r\n",
      "\u001b[32mINFO\u001b[0m:     Started server process [\u001b[36m5574\u001b[0m]\r\n",
      "\u001b[32mINFO\u001b[0m:     Waiting for application startup.\r\n",
      "\u001b[32m[2025-07-06 18:59:54,481] [    INFO]\u001b[0m - loading configuration file work/models/preprocessor_config.json\u001b[0m\r\n",
      "\u001b[32mINFO\u001b[0m:     Application startup complete.\r\n",
      "\u001b[32mINFO\u001b[0m:     Uvicorn running on \u001b[1mhttp://0.0.0.0:8180\u001b[0m (Press CTRL+C to quit)\r\n"
     ]
    }
   ],
   "source": [
    "python -m fastdeploy.entrypoints.openai.api_server \\\n",
    "       --model work/models \\\n",
    "       --port 8180 \\\n",
    "       --metrics-port 8181 \\\n",
    "       --engine-worker-queue-port 8182 \\\n",
    "       --max-model-len 32768 \\\n",
    "       --enable-mm \\\n",
    "       --reasoning-parser ernie-45-vl \\\n",
    "       --max-num-seqs 32"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### æœåŠ¡å¯åŠ¨å‚æ•°è¯¦ç»†è¯´æ˜\n",
    "\n",
    "| å‚æ•°åç§° | å‚æ•°è¯´æ˜ | é»˜è®¤å€¼ | ç¤ºä¾‹å€¼ |\n",
    "|---------|---------|-------|-------|\n",
    "| `--model` | æ¨¡å‹æ–‡ä»¶è·¯å¾„ï¼ŒåŒ…å«æ¨¡å‹æƒé‡å’Œé…ç½®æ–‡ä»¶çš„ç›®å½• | å¿…é€‰ | `work/models` |\n",
    "| `--port` | APIæœåŠ¡ç›‘å¬ç«¯å£ï¼Œå®¢æˆ·ç«¯é€šè¿‡æ­¤ç«¯å£è®¿é—®æœåŠ¡ | 8000 | `8180` |\n",
    "| `--metrics-port` | ç›‘æ§æŒ‡æ ‡æœåŠ¡ç«¯å£ï¼Œç”¨äºæ€§èƒ½ç›‘æ§å’Œå¥åº·æ£€æŸ¥ | 8001 | `8181` |\n",
    "| `--engine-worker-queue-port` | å¼•æ“å·¥ä½œé˜Ÿåˆ—ç«¯å£ï¼Œç”¨äºå†…éƒ¨ä»»åŠ¡è°ƒåº¦ | 8002 | `8182` |\n",
    "| `--max-model-len` | æ¨¡å‹æœ€å¤§æ”¯æŒçš„åºåˆ—é•¿åº¦ï¼ˆtokenæ•°ï¼‰ | 2048 | `32768` |\n",
    "| `--enable-mm` | å¯ç”¨å¤šæ¨¡æ€åŠŸèƒ½ï¼ˆæ–‡æœ¬+å›¾åƒå¤„ç†ï¼‰ | False | `å¼€å¯` |\n",
    "| `--reasoning-parser` | æ¨ç†è§£æå™¨ç±»å‹ï¼ŒæŒ‡å®šæ¨¡å‹çš„æ¨ç†é€»è¾‘ | æ—  | `ernie-45-vl` |\n",
    "| `--max-num-seqs` | æœ€å¤§å¹¶å‘åºåˆ—æ•°ï¼Œæ§åˆ¶æ‰¹å¤„ç†å¤§å° | 256 | `32` |\n",
    "\n",
    "### å…¶ä»–å¸¸ç”¨å‚æ•°\n",
    "\n",
    "| å‚æ•°åç§° | å‚æ•°è¯´æ˜ | é»˜è®¤å€¼ | å¤‡æ³¨ |\n",
    "|---------|---------|-------|------|\n",
    "| `--host` | æœåŠ¡ç»‘å®šçš„ä¸»æœºåœ°å€ | 0.0.0.0 | è®¾ç½®ä¸º0.0.0.0å…è®¸å¤–éƒ¨è®¿é—® |\n",
    "| `--trust-remote-code` | ä¿¡ä»»è¿œç¨‹ä»£ç æ‰§è¡Œ | False | åŠ è½½è‡ªå®šä¹‰æ¨¡å‹æ—¶éœ€è¦ |\n",
    "| `--tensor-parallel-size` | å¼ é‡å¹¶è¡Œå¤§å°ï¼ˆå¤šGPUï¼‰ | 1 | æ ¹æ®GPUæ•°é‡è®¾ç½® |\n",
    "| `--gpu-memory-utilization` | GPUå†…å­˜åˆ©ç”¨ç‡ | 0.9 | å»ºè®®0.8-0.95ä¹‹é—´ |\n",
    "| `--max-num-batched-tokens` | æœ€å¤§æ‰¹å¤„ç†tokenæ•° | è‡ªåŠ¨è®¡ç®— | æ ¹æ®GPUæ˜¾å­˜è°ƒæ•´ |\n",
    "| `--swap-space` | äº¤æ¢ç©ºé—´å¤§å°(GB) | 4 | å†…å­˜ä¸è¶³æ—¶ä½¿ç”¨ |\n",
    "| `--enable-lora` | å¯ç”¨LoRAé€‚é…å™¨ | False | å¾®è°ƒæ¨¡å‹æ—¶ä½¿ç”¨ |\n",
    "| `--max-log-len` | æœ€å¤§æ—¥å¿—é•¿åº¦ | æ— é™åˆ¶ | æ§åˆ¶æ—¥å¿—æ–‡ä»¶å¤§å° |\n",
    "\n",
    "### æœåŠ¡éªŒè¯\n",
    "```bash\n",
    "# æ£€æŸ¥æ¨¡å‹æ˜¯å¦æ­£å¸¸åŠ è½½\n",
    "curl http://localhost:8180/v1/models\n",
    "\n",
    "# é¢„æœŸè¾“å‡ºï¼ˆåŒ…å«æ¨¡å‹IDï¼‰\n",
    "{\"data\":[{\"id\":\"ernie-4.5-vl-28b-a3b-paddle\",\"object\":\"model\"}]}\n",
    "```\n",
    "\n",
    "## å››ã€æ¨¡å‹è°ƒç”¨ç¤ºä¾‹\n",
    "\n",
    "### 1. OpenAIåº“è°ƒç”¨æ–¹å¼\n",
    "\n",
    "#### â‘  æ–‡æœ¬ç”Ÿæˆ\n",
    "```python\n",
    "import openai\n",
    "\n",
    "host = \"0.0.0.0\"\n",
    "port = \"8180\"\n",
    "client = openai.Client(base_url=f\"http://{host}:{port}/v1\", api_key=\"null\")\n",
    "\n",
    "response = client.chat.completions.create(\n",
    "    model=\"null\",\n",
    "    messages=[\n",
    "        {\"role\": \"user\", \"content\": \"ä½ æ˜¯Aistudioå’Œæ–‡å¿ƒå¤§æ¨¡å‹å¼€å‘çš„æ™ºèƒ½åŠ©æ‰‹ï¼Œè¯·ä»‹ç»ä¸€ä¸‹ä½ è‡ªå·±.\"}\n",
    "    ],\n",
    "    stream=True,\n",
    ")\n",
    "\n",
    "for chunk in response:\n",
    "    if chunk.choices[0].delta:\n",
    "        print(chunk.choices[0].delta.content, end='')\n",
    "```\n",
    "\n",
    "#### â‘¡ å›¾åƒæè¿°ç”Ÿæˆ\n",
    "```python\n",
    "import openai\n",
    "import base64\n",
    "\n",
    "def encode_image(image_path):\n",
    "    with open(image_path, \"rb\") as image_file:\n",
    "        return base64.b64encode(image_file.read()).decode('utf-8')\n",
    "\n",
    "client = openai.Client(\n",
    "    base_url=\"http://0.0.0.0:8180/v1\",\n",
    "    api_key=\"null\"\n",
    ")\n",
    "\n",
    "response = client.chat.completions.create(\n",
    "    model=\"null\",\n",
    "    messages=[\n",
    "        {\n",
    "            \"role\": \"user\",\n",
    "            \"content\": [\n",
    "                {\n",
    "                    \"type\": \"image_url\",\n",
    "                    \"image_url\": {\n",
    "                        \"url\": f\"data:image/jpeg;base64,{encode_image('1.jpg')}\"\n",
    "                    }\n",
    "                },\n",
    "                {\n",
    "                    \"type\": \"text\",\n",
    "                    \"text\": \"ç”Ÿæˆè¿™å¼ å›¾ç‰‡çš„æè¿°\"\n",
    "                }\n",
    "            ]\n",
    "        }\n",
    "    ],\n",
    "    stream=True,\n",
    ")\n",
    "\n",
    "print(\"å›¾ç‰‡æè¿°ï¼š\", end='', flush=True)\n",
    "for chunk in response:\n",
    "    if chunk.choices and chunk.choices[0].delta.content:\n",
    "        print(chunk.choices[0].delta.content, end='', flush=True)\n",
    "print()\n",
    "```\n",
    "\n",
    "### 2. requestsåº“è°ƒç”¨æ–¹å¼\n",
    "\n",
    "#### â‘  æ–‡æœ¬ç”Ÿæˆ\n",
    "```python\n",
    "import requests\n",
    "import json\n",
    "\n",
    "url = \"http://localhost:8180/v1/chat/completions\"\n",
    "headers = {\"Content-Type\": \"application/json\"}\n",
    "payload = {\n",
    "    \"model\": \"null\",\n",
    "    \"messages\": [\n",
    "        {\"role\": \"user\", \"content\": \"ä½ æ˜¯Aistudioå’Œæ–‡å¿ƒå¤§æ¨¡å‹å¼€å‘çš„æ™ºèƒ½åŠ©æ‰‹ï¼Œè¯·ä»‹ç»ä¸€ä¸‹ä½ è‡ªå·±.\"}\n",
    "    ],\n",
    "    \"stream\": True\n",
    "}\n",
    "\n",
    "response = requests.post(url, headers=headers, json=payload, stream=True)\n",
    "\n",
    "for line in response.iter_lines():\n",
    "    if line:\n",
    "        line = line.decode('utf-8').replace('data: ', '')\n",
    "        \n",
    "        if line.strip() == '[DONE]':\n",
    "            continue\n",
    "        try:\n",
    "            data = json.loads(line)\n",
    "            \n",
    "            if 'choices' in data and len(data['choices']) > 0:\n",
    "                delta = data['choices'][0].get('delta', {})\n",
    "                content = delta.get('content', '')\n",
    "                if content:\n",
    "                    print(content, end='', flush=True)\n",
    "        except json.JSONDecodeError as e:\n",
    "            print(f\"Error decoding line: {line}\")\n",
    "            print(f\"Error: {e}\")\n",
    "\n",
    "print()\n",
    "```\n",
    "\n",
    "#### â‘¡ å›¾åƒæè¿°ç”Ÿæˆ\n",
    "```python\n",
    "import requests\n",
    "import json\n",
    "import base64\n",
    "\n",
    "def encode_image(image_path):\n",
    "    with open(image_path, \"rb\") as image_file:\n",
    "        return base64.b64encode(image_file.read()).decode('utf-8')\n",
    "\n",
    "url = \"http://localhost:8180/v1/chat/completions\"\n",
    "headers = {\"Content-Type\": \"application/json\"}\n",
    "payload = {\n",
    "    \"model\": \"null\",\n",
    "    \"messages\": [\n",
    "        {\n",
    "            \"role\": \"user\",\n",
    "            \"content\": [\n",
    "                {\"type\": \"image_url\", \"image_url\": {\"url\": f\"data:image/jpeg;base64,{encode_image('1.jpg')}\"}},\n",
    "                {\"type\": \"text\", \"text\": \"ç”Ÿæˆå›¾ç‰‡æè¿°\"}\n",
    "            ]\n",
    "        }\n",
    "    ],\n",
    "    \"stream\": True\n",
    "}\n",
    "\n",
    "response = requests.post(url, headers=headers, json=payload, stream=True)\n",
    "\n",
    "for line in response.iter_lines():\n",
    "    if line:\n",
    "        line = line.decode('utf-8').replace('data: ', '')\n",
    "        \n",
    "        if line.strip() == '[DONE]':\n",
    "            continue\n",
    "        try:\n",
    "            data = json.loads(line)\n",
    "            \n",
    "            if 'choices' in data and len(data['choices']) > 0:\n",
    "                delta = data['choices'][0].get('delta', {})\n",
    "                content = delta.get('content', '')\n",
    "                if content:\n",
    "                    print(content, end='', flush=True)\n",
    "        except json.JSONDecodeError as e:\n",
    "            print(f\"Error decoding line: {line}\")\n",
    "            print(f\"Error: {e}\")\n",
    "\n",
    "print()\n",
    "```\n",
    "\n",
    "### 3. è°ƒç”¨å‚æ•°è¯´æ˜\n",
    "\n",
    "#### å¸¸ç”¨å‚æ•°é…ç½®\n",
    "```python\n",
    "# å®Œæ•´çš„è°ƒç”¨å‚æ•°ç¤ºä¾‹\n",
    "response = client.chat.completions.create(\n",
    "    model=\"null\",                    # æ¨¡å‹åç§°ï¼ˆå›ºå®šå€¼ï¼‰\n",
    "    messages=[...],                  # æ¶ˆæ¯åˆ—è¡¨\n",
    "    stream=True,                     # æ˜¯å¦å¯ç”¨æµå¼å“åº”\n",
    "    max_tokens=2048,                 # æœ€å¤§ç”Ÿæˆtokenæ•°\n",
    "    temperature=0.7,                 # æ¸©åº¦å‚æ•°(0.0-2.0)\n",
    "    top_p=0.9,                      # æ ¸é‡‡æ ·å‚æ•°(0.0-1.0)\n",
    "    frequency_penalty=0.0,           # é¢‘ç‡æƒ©ç½š(-2.0-2.0)\n",
    "    presence_penalty=0.0,            # å­˜åœ¨æƒ©ç½š(-2.0-2.0)\n",
    "    stop=[\"<|endoftext|>\"],         # åœæ­¢è¯åˆ—è¡¨\n",
    ")\n",
    "```\n",
    "\n",
    "#### å‚æ•°è¯¦ç»†è¯´æ˜\n",
    "| å‚æ•°åç§° | ç±»å‹ | é»˜è®¤å€¼ | è¯´æ˜ |\n",
    "|---------|------|--------|------|\n",
    "| `model` | str | \"null\" | æ¨¡å‹åç§°ï¼Œæœ¬åœ°éƒ¨ç½²æ—¶å›ºå®šä¸º\"null\" |\n",
    "| `messages` | list | å¿…é€‰ | å¯¹è¯æ¶ˆæ¯åˆ—è¡¨ï¼ŒåŒ…å«roleå’Œcontent |\n",
    "| `stream` | bool | False | æ˜¯å¦å¯ç”¨æµå¼å“åº” |\n",
    "| `max_tokens` | int | è‡ªåŠ¨ | æœ€å¤§ç”Ÿæˆtokenæ•°é‡ |\n",
    "| `temperature` | float | 1.0 | æ§åˆ¶éšæœºæ€§ï¼Œå€¼è¶Šé«˜è¶Šéšæœº |\n",
    "| `top_p` | float | 1.0 | æ ¸é‡‡æ ·ï¼Œæ§åˆ¶è¯æ±‡é€‰æ‹©èŒƒå›´ |\n",
    "| `frequency_penalty` | float | 0.0 | é¢‘ç‡æƒ©ç½šï¼Œå‡å°‘é‡å¤å†…å®¹ |\n",
    "| `presence_penalty` | float | 0.0 | å­˜åœ¨æƒ©ç½šï¼Œé¼“åŠ±è°ˆè®ºæ–°è¯é¢˜ |\n",
    "| `stop` | list | None | åœæ­¢ç”Ÿæˆçš„å­—ç¬¦ä¸²åˆ—è¡¨ |\n",
    "\n",
    "## äº”ã€å¸¸è§é—®é¢˜ä¸è§£å†³æ–¹æ¡ˆ\n",
    "### 1. ç«¯å£å ç”¨é—®é¢˜\n",
    "```bash\n",
    "# æŸ¥çœ‹ç«¯å£å ç”¨è¿›ç¨‹\n",
    "lsof -i:8180\n",
    "\n",
    "# ç»ˆæ­¢è¿›ç¨‹ï¼ˆæ›¿æ¢<PID>ä¸ºå®é™…è¿›ç¨‹å·ï¼‰\n",
    "kill -9 <PID>\n",
    "```\n",
    "\n",
    "### 2. æ¨¡å‹åŠ è½½å¤±è´¥\n",
    "- **æ£€æŸ¥ç›®å½•**ï¼šç¡®è®¤`work/models`ä¸‹å­˜åœ¨å®Œæ•´çš„æ¨¡å‹æ–‡ä»¶ï¼ˆ.pdparams/config.json/vocab.txtï¼‰  \n",
    "- **è§£æå™¨å‚æ•°**ï¼šç¡®ä¿å¯åŠ¨å‘½ä»¤åŒ…å«`--reasoning-parser ernie-45-vl`  \n",
    "- **é©±åŠ¨ç‰ˆæœ¬**ï¼šNVIDIAé©±åŠ¨éœ€â‰¥520.61.05ï¼ˆæ”¯æŒA100ï¼‰  \n",
    "\n",
    "### 3. æµå¼å“åº”å¼‚å¸¸\n",
    "- ç¡®ä¿`stream=True`å‚æ•°æ­£ç¡®ä¼ é€’  \n",
    "- æ£€æŸ¥æœåŠ¡æ—¥å¿—ï¼ˆ`fastdeploy_server.log`ï¼‰æ˜¯å¦æœ‰å†…å­˜/æ˜¾å­˜ä¸è¶³æŠ¥é”™  \n",
    "\n",
    "\n",
    "## å…­ã€æµ‹è¯•ç”¨ä¾‹\n",
    "### 1. æ–‡æœ¬ç”ŸæˆéªŒè¯\n",
    "- **è¾“å…¥**ï¼š`\"æ€»ç»“æœ¬æ•™ç¨‹çš„æ ¸å¿ƒæ­¥éª¤\"`  \n",
    "- **é¢„æœŸ**ï¼šè¾“å‡ºåŒ…å«\"ç¯å¢ƒé…ç½®\"ã€\"æœåŠ¡å¯åŠ¨\"ã€\"æ¥å£è°ƒç”¨\"ç­‰å…³é”®è¯çš„è¿è´¯æ–‡æœ¬  \n",
    "\n",
    "### 2. å›¾åƒæè¿°éªŒè¯\n",
    "- **æµ‹è¯•å›¾ç‰‡**ï¼šä½¿ç”¨åŒ…å«è‡ªç„¶åœºæ™¯çš„jpgæ–‡ä»¶ï¼ˆå¦‚å±±æ°´ã€äººç‰©æ´»åŠ¨ï¼‰  \n",
    "- **é¢„æœŸ**ï¼šè¾“å‡ºåŒ…å«æ™¯ç‰©ç‰¹å¾ï¼ˆå¦‚\"è“å¤©ç™½äº‘ä¸‹çš„ç»¿è‰²è‰åŸ\"ï¼‰ã€åŠ¨ä½œæè¿°ï¼ˆå¦‚\"äººç‰©æ­£åœ¨æ¹–è¾¹æ•£æ­¥\"ï¼‰çš„è¯­å¥  \n",
    "\n",
    "## ä¸ƒã€æ™ºèƒ½åŒ»ç–—é—®è¯Šç³»ç»Ÿéƒ¨ç½²\n",
    "\n",
    "### 1. ç³»ç»Ÿä¾èµ–å®‰è£…\n",
    "```bash\n",
    "# æ›´æ–°ä¾èµ–åŒ…ç‰ˆæœ¬\n",
    "pip install -r requirements.txt\n",
    "```\n",
    "\n",
    "### 2. åŒ»å­¦çŸ¥è¯†åº“åˆå§‹åŒ–\n",
    "```bash\n",
    "# åˆå§‹åŒ–ChromaDBåŒ»å­¦çŸ¥è¯†åº“\n",
    "python init_knowledge_base.py\n",
    "\n",
    "# å¯åŠ¨åä¼šåˆ›å»ºä»¥ä¸‹é›†åˆï¼š\n",
    "# - symptoms: ç—‡çŠ¶çŸ¥è¯†åº“\n",
    "# - diseases: ç–¾ç—…çŸ¥è¯†åº“  \n",
    "# - treatments: æ²»ç–—æ–¹æ¡ˆåº“\n",
    "```\n",
    "\n",
    "### 3. å¯åŠ¨å®Œæ•´ç³»ç»Ÿ\n",
    "```bash\n",
    "# ç¬¬ä¸€æ­¥ï¼šå¯åŠ¨ERNIE-4.5-VLæ¨¡å‹æœåŠ¡\n",
    "python -m fastdeploy.entrypoints.openai.api_server \\\n",
    "       --model work/models \\\n",
    "       --port 8180 \\\n",
    "       --enable-mm \\\n",
    "       --reasoning-parser ernie-45-vl\n",
    "\n",
    "# ç¬¬äºŒæ­¥ï¼šå¯åŠ¨åŒ»ç–—é—®è¯ŠWebç•Œé¢  \n",
    "python main.gradio.py\n",
    "```\n",
    "\n",
    "### 4. ç³»ç»ŸéªŒè¯\n",
    "```bash\n",
    "# è¿è¡Œç³»ç»Ÿæµ‹è¯•\n",
    "python test_system.py\n",
    "\n",
    "# é¢„æœŸè¾“å‡ºï¼š\n",
    "# âœ… ERNIE æœåŠ¡è¿æ¥æˆåŠŸ\n",
    "# âœ… çŸ¥è¯†åº“è¿æ¥æ­£å¸¸  \n",
    "# âœ… ç—‡çŠ¶åˆ†æåŠŸèƒ½æ­£å¸¸\n",
    "# âœ… é—®è¯Šæµç¨‹å®Œæˆ\n",
    "```\n",
    "\n",
    "## å…«ã€åŠŸèƒ½å±•ç¤ºä¸æ•ˆæœ\n",
    "\n",
    "### ğŸ–¼ï¸ ç³»ç»Ÿç•Œé¢\n",
    "![æ™ºèƒ½åŒ»ç–—é—®è¯Šç³»ç»Ÿä¸»ç•Œé¢](https://ai-studio-static-online.cdn.bcebos.com/9071eee410474644988213a51be33c75de6f65b21f5b44328d25094600a98361)\n",
    "\n",
    "### ğŸ“‹ è¯Šæ–­æŠ¥å‘Šç¤ºä¾‹\n",
    "![å¤šæ¨¡æ€é—®è¯Šç»“æœ](https://ai-studio-static-online.cdn.bcebos.com/b899c223a17849f3ae0414b569f480bc24c98fc54fbf4923b57e24eb15850c65)\n",
    "\n",
    "### ğŸ” å›¾åƒåˆ†æèƒ½åŠ›  \n",
    "![çš®è‚¤ç—…å˜å›¾åƒåˆ†æ](https://ai-studio-static-online.cdn.bcebos.com/be14a288a7a848a783b700d5292b767eddf11bee1253412c95460e0619dadba2)\n",
    "\n",
    "### ğŸ’Š æ²»ç–—å»ºè®®è¾“å‡ºæ ¼å¼\n",
    "```\n",
    "ã€ç—‡çŠ¶åˆ†æã€‘\n",
    "è¯†åˆ«åˆ°çš„ç—‡çŠ¶ï¼šå‘çƒ­ã€å’³å—½ã€ä¹åŠ›\n",
    "\n",
    "ã€é£é™©è¯„ä¼°ã€‘  \n",
    "é£é™©ç­‰çº§ï¼šâš ï¸âš ï¸ (å»ºè®®æ™®é€šé—¨è¯Šå°±åŒ»)\n",
    "å»ºè®®ï¼š\n",
    "- ç—‡çŠ¶æŒç»­æ—¶é—´è¾ƒçŸ­ï¼Œæš‚æ— ä¸¥é‡å¹¶å‘ç—‡\n",
    "- å»ºè®®åŠæ—¶å°±åŒ»æ’æŸ¥æ„ŸæŸ“æ€§ç–¾ç—…\n",
    "\n",
    "ã€å»ºè®®æ£€æŸ¥é¡¹ç›®ã€‘\n",
    "- è¡€å¸¸è§„æ£€æŸ¥\n",
    "- Cååº”è›‹ç™½æ£€æµ‹\n",
    "- èƒ¸éƒ¨Xå…‰ç‰‡\n",
    "\n",
    "ã€ç”¨è¯å»ºè®®ã€‘\n",
    "- å¯¹ç—‡æ²»ç–—ï¼šå¸ƒæ´›èŠ¬é€€çƒ­\n",
    "- æ­¢å’³åŒ–ç—°ï¼šå¤æ–¹ç”˜è‰ç‰‡\n",
    "- è¯·éµåŒ»å˜±ç”¨è¯ï¼Œé¿å…è‡ªè¡Œç”¨è¯\n",
    "\n",
    "ã€ç”Ÿæ´»å»ºè®®ã€‘  \n",
    "- å……åˆ†ä¼‘æ¯ï¼Œé¿å…å‰§çƒˆè¿åŠ¨\n",
    "- å¤šé¥®æ°´ï¼Œä¿æŒå®¤å†…é€šé£\n",
    "- æ³¨æ„ä¿æš–ï¼Œé¿å…å†æ¬¡å—å‡‰\n",
    "```\n",
    "\n",
    "## ä¹ã€æŠ€æœ¯åˆ›æ–°ç‚¹\n",
    "\n",
    "### ğŸ”¬ æ ¸å¿ƒæŠ€æœ¯ä¼˜åŠ¿\n",
    "\n",
    "#### 1. æœ¬åœ°åŒ–å¤šæ¨¡æ€å¤§æ¨¡å‹\n",
    "- **æ¨¡å‹è§„æ¨¡**ï¼š28Bå‚æ•°ï¼Œ3Bæ¿€æ´»å‚æ•°çš„é«˜æ•ˆMoEæ¶æ„\n",
    "- **å¤šæ¨¡æ€èƒ½åŠ›**ï¼šåŸç”Ÿæ”¯æŒæ–‡æœ¬+å›¾åƒçš„è”åˆç†è§£\n",
    "- **éƒ¨ç½²ä¼˜åŒ–**ï¼šFastDeployæ¡†æ¶ï¼Œå•æœºå¤šå¡é«˜æ•ˆæ¨ç†\n",
    "- **æ•°æ®å®‰å…¨**ï¼šå®Œå…¨æœ¬åœ°åŒ–ï¼Œæ‚£è€…éšç§é›¶æ³„éœ²\n",
    "\n",
    "#### 2. RAGå¢å¼ºçŸ¥è¯†ç³»ç»Ÿ\n",
    "- **å‘é‡åŒ–å­˜å‚¨**ï¼šChromaDBæ„å»ºçš„é«˜æ•ˆè¯­ä¹‰æ£€ç´¢\n",
    "- **åˆ†å±‚çŸ¥è¯†åº“**ï¼šç—‡çŠ¶ã€ç–¾ç—…ã€æ²»ç–—æ–¹æ¡ˆçš„ç»“æ„åŒ–ç®¡ç†\n",
    "- **å®æ—¶æ£€ç´¢**ï¼šæ¯«ç§’çº§çš„ç›¸ä¼¼åº¦åŒ¹é…å’ŒçŸ¥è¯†å¬å›\n",
    "- **åŠ¨æ€æ›´æ–°**ï¼šæ”¯æŒçŸ¥è¯†åº“çš„å¢é‡æ›´æ–°å’Œæ‰©å±•\n",
    "\n",
    "#### 3. å¤šAgentååŒæ¶æ„\n",
    "- **æ¨¡å—åŒ–è®¾è®¡**ï¼šæ¯ä¸ªAgentè´Ÿè´£ç‰¹å®šçš„åŒ»ç–—ä»»åŠ¡\n",
    "- **æ™ºèƒ½ç¼–æ’**ï¼šAgentCoordinatorç»Ÿä¸€è°ƒåº¦å’Œæ•°æ®æµç®¡ç†\n",
    "- **å®¹é”™æœºåˆ¶**ï¼šå•ä¸ªAgentå¤±è´¥ä¸å½±å“æ•´ä½“ç³»ç»Ÿè¿è¡Œ\n",
    "- **å¯æ‰©å±•æ€§**ï¼šæ–°å¢åŒ»ç–—ä¸“ç§‘Agentå³æ’å³ç”¨\n",
    "\n",
    "#### 4. ç”¨æˆ·ä½“éªŒä¼˜åŒ–\n",
    "- **æµå¼å“åº”**ï¼šå®æ—¶æ˜¾ç¤ºAIåˆ†æè¿‡ç¨‹ï¼Œæå‡äº¤äº’ä½“éªŒ\n",
    "- **å¤šç«¯é€‚é…**ï¼šWebç•Œé¢æ”¯æŒPCå’Œç§»åŠ¨ç«¯è®¿é—®\n",
    "- **ç»“æœå¯è§†åŒ–**ï¼šç»“æ„åŒ–åŒ»ç–—æŠ¥å‘Šï¼Œæ˜“äºç†è§£å’Œä¿å­˜\n",
    "- **æ“ä½œä¾¿æ·**ï¼šæ‹–æ‹½ä¸Šä¼ å›¾ç‰‡ï¼Œæ–‡æœ¬æ¡†å¿«é€Ÿè¾“å…¥\n",
    "\n",
    "## åã€åº”ç”¨ä»·å€¼ä¸åœºæ™¯\n",
    "\n",
    "### ğŸ¥ åŒ»ç–—åœºæ™¯åº”ç”¨\n",
    "\n",
    "#### åŸºå±‚åŒ»ç–—æœºæ„\n",
    "- **åˆæ­¥é—®è¯Š**ï¼šååŠ©å…¨ç§‘åŒ»ç”Ÿè¿›è¡Œç—‡çŠ¶åˆ†æ\n",
    "- **åˆ†è¯Šè¾…åŠ©**ï¼šè¯„ä¼°æ‚£è€…ç—…æƒ…ç´§æ€¥ç¨‹åº¦  \n",
    "- **çŸ¥è¯†æ”¯æŒ**ï¼šä¸ºåŒ»ç”Ÿæä¾›ç–¾ç—…è¯Šç–—å‚è€ƒ\n",
    "\n",
    "#### è¿œç¨‹åŒ»ç–—æœåŠ¡\n",
    "- **åœ¨çº¿å’¨è¯¢**ï¼š24å°æ—¶æ™ºèƒ½åŒ»ç–—å’¨è¯¢æœåŠ¡\n",
    "- **å›¾åƒè¯Šæ–­**ï¼šçš®è‚¤ç—…ã€å¤–ä¼¤ç­‰å¯è§†åŒ–ç–¾ç—…åˆ†æ\n",
    "- **å¥åº·æ•™è‚²**ï¼šæä¾›ä¸“ä¸šçš„å¥åº·ç®¡ç†å»ºè®®\n",
    "\n",
    "#### ä¸ªäººå¥åº·ç®¡ç†\n",
    "- **ç—‡çŠ¶è‡ªæŸ¥**ï¼šç”¨æˆ·è‡ªä¸»è¿›è¡Œå¥åº·çŠ¶å†µè¯„ä¼°\n",
    "- **å°±åŒ»æŒ‡å¯¼**ï¼šæä¾›ç§‘å­¦çš„å°±åŒ»å»ºè®®å’Œç§‘å®¤æ¨è\n",
    "- **ç”¨è¯å’¨è¯¢**ï¼šåŸºäºç—‡çŠ¶çš„å®‰å…¨ç”¨è¯æŒ‡å¯¼\n",
    "\n",
    "### ğŸ’¡ æŠ€æœ¯ä»·å€¼\n",
    "\n",
    "#### è¡Œä¸šæ¨åŠ¨\n",
    "- **AIåŒ»ç–—æ ‡å‡†åŒ–**ï¼šå¤šæ¨¡æ€åŒ»ç–—AIçš„æŠ€æœ¯èŒƒå¼\n",
    "- **æœ¬åœ°åŒ–éƒ¨ç½²**ï¼šä¸ºåŒ»ç–—æ•°æ®å®‰å…¨æä¾›è§£å†³æ–¹æ¡ˆ\n",
    "- **å¼€æºç”Ÿæ€**ï¼šåŸºäºPaddlePaddleçš„å®Œæ•´æŠ€æœ¯æ ˆ\n",
    "\n",
    "#### åˆ›æ–°çªç ´\n",
    "- **å¤šæ¨¡æ€èåˆ**ï¼šå›¾æ–‡ä¸€ä½“åŒ–çš„åŒ»ç–—ç†è§£èƒ½åŠ›\n",
    "- **çŸ¥è¯†åº“é©±åŠ¨**ï¼šRAGæŠ€æœ¯åœ¨åŒ»ç–—é¢†åŸŸçš„æ·±åº¦åº”ç”¨\n",
    "- **AgentååŒ**ï¼šä¸“ä¸šåŒ–AIç³»ç»Ÿçš„åä½œæœºåˆ¶\n",
    "\n",
    "## åä¸€ã€ç³»ç»Ÿç›‘æ§ä¸ç»´æŠ¤\n",
    "\n",
    "### ğŸ“Š æ€§èƒ½ç›‘æ§\n",
    "```bash\n",
    "# æŸ¥çœ‹æ¨¡å‹æœåŠ¡çŠ¶æ€\n",
    "curl http://localhost:8180/v1/models\n",
    "\n",
    "# ç›‘æ§ç³»ç»Ÿèµ„æºä½¿ç”¨\n",
    "nvidia-smi  # GPUä½¿ç”¨æƒ…å†µ\n",
    "top         # CPUå’Œå†…å­˜ä½¿ç”¨\n",
    "\n",
    "# æŸ¥çœ‹æœåŠ¡æ—¥å¿—\n",
    "tail -f logs/gradio_app_*.log\n",
    "\n",
    "\n",
    "### ğŸ“ è”ç³»æ–¹å¼\n",
    "- **é¡¹ç›®ä½œè€…**ï¼šWechat: X_ruilian"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-07-06T13:47:22.113188Z",
     "iopub.status.busy": "2025-07-06T13:47:22.112841Z",
     "iopub.status.idle": "2025-07-06T13:47:36.519914Z",
     "shell.execute_reply": "2025-07-06T13:47:36.519349Z",
     "shell.execute_reply.started": "2025-07-06T13:47:22.113166Z"
    },
    "scrolled": true,
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-07-06 21:47:22,130 - INFO - HTTP Request: POST http://0.0.0.0:8180/v1/chat/completions \"HTTP/1.1 200 OK\"\r\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\r\n",
      "\r\n",
      "æˆ‘æ˜¯ç”± **Aistudio**ï¼ˆç™¾åº¦å¼€æºçš„AIå¼€å‘å¹³å°ï¼‰ä¸ **æ–‡å¿ƒå¤§æ¨¡å‹** æŠ€æœ¯æ¡†æ¶å…±åŒèµ‹èƒ½çš„æ™ºèƒ½åŠ©æ‰‹ã€‚ä»¥ä¸‹æ˜¯æˆ‘çš„æ ¸å¿ƒç‰¹ç‚¹ä¸åŠŸèƒ½ä»‹ç»ï¼š\r\n",
      "\r\n",
      "### 1. **æŠ€æœ¯èƒŒæ™¯**\r\n",
      "   - åŸºäºç™¾åº¦è‡ªä¸»ç ”å‘çš„ **æ–‡å¿ƒå¤§æ¨¡å‹** åŸºç¡€èƒ½åŠ›ï¼Œèåˆå¤šæ¨¡æ€ç†è§£ä¸ç”ŸæˆæŠ€æœ¯ï¼Œå…·å¤‡å¼ºå¤§çš„è‡ªç„¶è¯­è¨€å¤„ç†èƒ½åŠ›ã€‚\r\n",
      "   - ä¾æ‰˜Aistudioçš„å¼€æºç”Ÿæ€ï¼Œæ”¯æŒå¼€å‘è€…åä½œä¸æ¨¡å‹è¿­ä»£ä¼˜åŒ–ã€‚\r\n",
      "\r\n",
      "### 2. **æ ¸å¿ƒèƒ½åŠ›**\r\n",
      "   - **çŸ¥è¯†é—®ç­”**ï¼šè¦†ç›–å¹¿æ³›é¢†åŸŸï¼ˆç§‘æŠ€ã€æ–‡åŒ–ã€ç”Ÿæ´»ç­‰ï¼‰ï¼Œæä¾›å‡†ç¡®ã€ç®€æ´çš„è§£ç­”ã€‚\r\n",
      "   - **æ–‡æœ¬ç”Ÿæˆ**ï¼šå¯æ’°å†™æ–‡ç« ã€ä»£ç ã€è¯—æ­Œã€å¯¹è¯ç­‰ï¼Œæ”¯æŒåˆ›æ„ä¸å®ç”¨åœºæ™¯ã€‚\r\n",
      "   - **é€»è¾‘æ¨ç†**ï¼šåˆ†æå¤æ‚é—®é¢˜ï¼Œæä¾›ç»“æ„åŒ–æ€è€ƒè·¯å¾„ã€‚\r\n",
      "   - **å¤šè¯­è¨€æ”¯æŒ**ï¼šä¸­æ–‡ä¸ºä¸»ï¼Œå…¼é¡¾è‹±æ–‡ç­‰è¯­è¨€äº¤äº’ã€‚\r\n",
      "\r\n",
      "### 3. **åº”ç”¨åœºæ™¯**\r\n",
      "   - **å­¦ä¹ è¾…åŠ©**ï¼šè§£ç­”å­¦ç§‘é—®é¢˜ã€ç”Ÿæˆå­¦ä¹ ç¬”è®°æˆ–æ¨¡æ‹Ÿå¯¹è¯ã€‚\r\n",
      "   - **å†…å®¹åˆ›ä½œ**ï¼šè¾…åŠ©å†™ä½œã€è„šæœ¬ç”Ÿæˆã€è¥é”€æ–‡æ¡ˆç­–åˆ’ç­‰ã€‚\r\n",
      "   - **æ—¥å¸¸åŠ©æ‰‹**ï¼šæä¾›ç”Ÿæ´»å»ºè®®ã€æ—¶é—´è§„åˆ’ã€è¶£å‘³äº’åŠ¨ã€‚\r\n",
      "   - **æŠ€æœ¯åä½œ**ï¼šä¸å¼€å‘è€…å¯¹æ¥ï¼Œä¼˜åŒ–ä»£ç é€»è¾‘æˆ–æ¨¡å‹è®­ç»ƒæ–¹æ¡ˆã€‚\r\n",
      "\r\n",
      "### 4. **ä¼˜åŠ¿ç‰¹ç‚¹**\r\n",
      "   - **æŒç»­å­¦ä¹ **ï¼šé€šè¿‡ç”¨æˆ·åé¦ˆä¸æ•°æ®æ›´æ–°ï¼Œä¿æŒçŸ¥è¯†æ—¶æ•ˆæ€§ã€‚\r\n",
      "   - **å®‰å…¨å¯æ§**ï¼šéµå¾ªä¼¦ç†è§„èŒƒï¼Œé¿å…ç”Ÿæˆæœ‰å®³å†…å®¹ã€‚\r\n",
      "   - **çµæ´»äº¤äº’**ï¼šæ”¯æŒè‡ªç”±å¯¹è¯æˆ–æŒ‡å®šä»»åŠ¡ï¼ˆå¦‚â€œå†™ä¸€é¦–å…³äºæ˜¥å¤©çš„è¯—â€ï¼‰ã€‚\r\n",
      "\r\n",
      "### 5. **å¦‚ä½•ä½¿ç”¨**\r\n",
      "   - ç›´æ¥é€šè¿‡å¯¹è¯è¾“å…¥éœ€æ±‚ï¼Œæˆ–æŒ‡å®šä»»åŠ¡ç›®æ ‡ï¼ˆå¦‚â€œç”ŸæˆPythonçˆ¬è™«ä»£ç â€ï¼‰ã€‚\r\n",
      "   - ç»“åˆAistudioå¹³å°ï¼Œå¯å‚ä¸æ¨¡å‹è®­ç»ƒã€éƒ¨ç½²æˆ–å¼€æºé¡¹ç›®åä½œã€‚\r\n",
      "\r\n",
      "æœŸå¾…é€šè¿‡æˆ‘çš„èƒ½åŠ›ï¼Œä¸ºæ‚¨çš„å­¦ä¹ ã€å·¥ä½œæˆ–ç”Ÿæ´»æä¾›é«˜æ•ˆæ”¯æŒï¼ ğŸ˜Š"
     ]
    }
   ],
   "source": [
    "import openai\n",
    "host = \"0.0.0.0\"\n",
    "port = \"8180\"\n",
    "client = openai.Client(base_url=f\"http://{host}:{port}/v1\", api_key=\"null\")\n",
    "\n",
    "response = client.chat.completions.create(\n",
    "    model=\"null\",\n",
    "    messages=[\n",
    "        {\"role\": \"user\", \"content\": \"ä½ æ˜¯Aistudioå’Œæ–‡å¿ƒå¤§æ¨¡å‹å¼€å‘çš„æ™ºèƒ½åŠ©æ‰‹ï¼Œè¯·ä»‹ç»ä¸€ä¸‹ä½ è‡ªå·±.\"}\n",
    "    ],\n",
    "    stream=True,\n",
    ")\n",
    "for chunk in response:\n",
    "    if chunk.choices[0].delta:\n",
    "        print(chunk.choices[0].delta.content, end='')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-07-06T12:17:04.177492Z",
     "iopub.status.busy": "2025-07-06T12:17:04.177129Z",
     "iopub.status.idle": "2025-07-06T12:17:19.079569Z",
     "shell.execute_reply": "2025-07-06T12:17:19.078882Z",
     "shell.execute_reply.started": "2025-07-06T12:17:04.177471Z"
    },
    "scrolled": true,
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "å›¾ç‰‡æè¿°ï¼š\r\n",
      "è¿™å¼ å›¾ç‰‡å±•ç¤ºäº†é£æ¡¨è‡ªç„¶è¯­è¨€å¤„ç†å¼€å‘åº“ï¼ˆPaddleNLPï¼‰çš„æ ¸å¿ƒæ¶æ„å’ŒåŠŸèƒ½æ¨¡å—ï¼Œæ•´ä½“è®¾è®¡ç®€æ´æ¸…æ™°ï¼Œé‡‡ç”¨è“ç™½é…è‰²ï¼Œçªå‡ºç§‘æŠ€æ„Ÿã€‚å›¾ç‰‡åˆ†ä¸ºä¸‰ä¸ªä¸»è¦éƒ¨åˆ†ï¼š\r\n",
      "\r\n",
      "### 1. **å·¥ä¸šçº§é¢„ç½®ä»»åŠ¡ï¼ˆTaskflowï¼‰**\r\n",
      "   - **è‡ªç„¶è¯­è¨€ç†è§£**ï¼šåŒ…å«è¯æ³•åˆ†æã€æ–‡æœ¬çº é”™ã€æƒ…æ„Ÿåˆ†æã€å¥æ³•åˆ†æï¼Œè¦†ç›–æ–‡æœ¬åŸºç¡€å¤„ç†ä¸è¯­ä¹‰ç†è§£ä»»åŠ¡ã€‚\r\n",
      "   - **è‡ªç„¶è¯­è¨€ç”Ÿæˆ**ï¼šæ”¯æŒè‡ªåŠ¨å¯¹è”ã€æ™ºèƒ½å†™è¯—ã€ç”Ÿæˆå¼é—®ç­”ã€å¼€æ”¾åŸŸå¯¹è¯ï¼Œä½“ç°NLPåœ¨åˆ›æ„æ€§ä»»åŠ¡ä¸­çš„åº”ç”¨ã€‚\r\n",
      "\r\n",
      "### 2. **äº§ä¸šçº§æ¨¡å‹åº“**\r\n",
      "   - **è‡ªç ”é¢„è®­ç»ƒæ¨¡å‹**ï¼šåˆ—ä¸¾äº†å¤šä¸ªERNIEç³»åˆ—æ¨¡å‹ï¼ˆå¦‚ERNIE-1.0ã€ERNIE-2.0ã€ERNIE-Tinyç­‰ï¼‰åŠPLATO-2ã€SKEPç­‰æ¨¡å‹ï¼Œä½“ç°é£æ¡¨åœ¨é¢„è®­ç»ƒæ¨¡å‹é¢†åŸŸçš„å¤šæ ·æ€§ã€‚\r\n",
      "   - **è¦†ç›–å…¨åœºæ™¯åº”ç”¨**ï¼šæ¶µç›–æ–‡æœ¬åˆ†ç±»ã€åŒ¹é…ã€ç”Ÿæˆã€è¯­ä¹‰ç´¢å¼•ã€å°æ ·æœ¬å­¦ä¹ ã€æ–‡æœ¬å›¾å­¦ä¹ ã€ä¿¡æ¯æŠ½å–ã€ç¿»è¯‘ã€çŸ¥è¯†å…³è”ã€æ¨¡å‹å‹ç¼©ç­‰åœºæ™¯ï¼Œå±•ç¤ºæ¨¡å‹åº“çš„å¹¿æ³›é€‚ç”¨æ€§ã€‚\r\n",
      "\r\n",
      "### 3. **æ–‡æœ¬é¢†åŸŸæ ¸å¿ƒAPI**\r\n",
      "   - æä¾›åŸºç¡€å·¥å…·æ¨¡å—ï¼ŒåŒ…æ‹¬æ•°æ®ç®¡ç†ï¼ˆData/Datasetsï¼‰ã€åµŒå…¥ï¼ˆEmbeddingï¼‰ã€Transformeræ¡†æ¶ã€åºåˆ—åˆ°å‘é‡ï¼ˆSeq2Vecï¼‰ã€è¯„ä¼°æŒ‡æ ‡ï¼ˆMetricsï¼‰å’ŒæŸå¤±å‡½æ•°ï¼ˆLossesï¼‰ï¼Œä¸ºå¼€å‘è€…æä¾›çµæ´»çš„å¼€å‘æ¥å£ã€‚\r\n",
      "\r\n",
      "### åº•éƒ¨æ ‡è¯†\r\n",
      "   - åº•éƒ¨é£æ¡¨ï¼ˆPaddlePaddleï¼‰æ ‡å¿—å¼ºåŒ–å“ç‰Œä¸€è‡´æ€§ï¼Œä½“ç°é£æ¡¨ä½œä¸ºå¼€æºæ·±åº¦å­¦ä¹ å¹³å°çš„æ•´ä½“ç”Ÿæ€ã€‚\r\n",
      "\r\n",
      "**æ ¸å¿ƒä»·å€¼**ï¼šPaddleNLPé€šè¿‡é¢„ç½®ä»»åŠ¡ã€é¢„è®­ç»ƒæ¨¡å‹å’Œæ ¸å¿ƒAPIï¼Œæ„å»ºäº†ä»åŸºç¡€å·¥å…·åˆ°è¡Œä¸šåº”ç”¨çš„å®Œæ•´NLPè§£å†³æ–¹æ¡ˆï¼Œå…¼é¡¾æ•ˆç‡ä¸çµæ´»æ€§ï¼Œé€‚åˆå¼€å‘è€…å¿«é€Ÿè½åœ°è‡ªç„¶è¯­è¨€å¤„ç†é¡¹ç›®ã€‚\r\n"
     ]
    }
   ],
   "source": [
    "import openai\n",
    "import base64\n",
    "\n",
    "def encode_image(image_path):\n",
    "    with open(image_path, \"rb\") as image_file:\n",
    "        return base64.b64encode(image_file.read()).decode('utf-8')\n",
    "\n",
    "client = openai.Client(\n",
    "    base_url=\"http://0.0.0.0:8180/v1\",\n",
    "    api_key=\"null\"\n",
    ")\n",
    "\n",
    "response = client.chat.completions.create(\n",
    "    model=\"null\",\n",
    "    messages=[\n",
    "        {\n",
    "            \"role\": \"user\",\n",
    "            \"content\": [\n",
    "                {\n",
    "                    \"type\": \"image_url\",\n",
    "                    \"image_url\": {\n",
    "                        \"url\": f\"data:image/jpeg;base64,{encode_image('1.jpg')}\"\n",
    "                    }\n",
    "                },\n",
    "                {\n",
    "                    \"type\": \"text\",\n",
    "                    \"text\": \"ç”Ÿæˆè¿™å¼ å›¾ç‰‡çš„æè¿°\"\n",
    "                }\n",
    "            ]\n",
    "        }\n",
    "    ],\n",
    "    stream=True,\n",
    ")\n",
    "\n",
    "print(\"å›¾ç‰‡æè¿°ï¼š\", end='', flush=True)\n",
    "for chunk in response:\n",
    "    if chunk.choices and chunk.choices[0].delta.content:\n",
    "        print(chunk.choices[0].delta.content, end='', flush=True)\n",
    "print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-07-07T17:34:50.762852Z",
     "iopub.status.busy": "2025-07-07T17:34:50.762356Z",
     "iopub.status.idle": "2025-07-07T17:34:52.391703Z",
     "shell.execute_reply": "2025-07-07T17:34:52.391041Z",
     "shell.execute_reply.started": "2025-07-07T17:34:50.762817Z"
    },
    "scrolled": true,
    "tags": []
   },
   "outputs": [],
   "source": [
    "%%capture\n",
    "pip install -r requirements.txt --user"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-07-07T06:21:52.482043Z",
     "iopub.status.busy": "2025-07-07T06:21:52.481699Z",
     "iopub.status.idle": "2025-07-07T06:21:55.461737Z",
     "shell.execute_reply": "2025-07-07T06:21:55.461135Z",
     "shell.execute_reply.started": "2025-07-07T06:21:52.482022Z"
    },
    "scrolled": true,
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\r\n",
      "To disable this warning, you can either:\r\n",
      "\t- Avoid using `tokenizers` before the fork if possible\r\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\r\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… æˆåŠŸæ·»åŠ  3 æ¡è®°å½•åˆ° symptoms é›†åˆ\r\n",
      "âœ… æˆåŠŸæ·»åŠ  3 æ¡è®°å½•åˆ° diseases é›†åˆ\r\n",
      "âœ… æˆåŠŸæ·»åŠ  3 æ¡è®°å½•åˆ° treatments é›†åˆ\r\n",
      "åŒ»å­¦çŸ¥è¯†åº“åˆå§‹åŒ–å®Œæˆï¼\r\n"
     ]
    }
   ],
   "source": [
    "!python init_knowledge_base.py"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### åˆå§‹åŒ–å¤±è´¥ï¼Œè¯·å…ˆä¸‹è½½åµŒå…¥æ¨¡å‹"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-07-07T06:21:25.936880Z",
     "iopub.status.busy": "2025-07-07T06:21:25.936587Z",
     "iopub.status.idle": "2025-07-07T06:21:34.351247Z",
     "shell.execute_reply": "2025-07-07T06:21:34.350582Z",
     "shell.execute_reply.started": "2025-07-07T06:21:25.936861Z"
    },
    "scrolled": true,
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--2025-07-07 14:21:26--  https://chroma-onnx-models.s3.amazonaws.com/all-MiniLM-L6-v2/onnx.tar.gz\r\n",
      "Resolving chroma-onnx-models.s3.amazonaws.com (chroma-onnx-models.s3.amazonaws.com)... 52.217.143.65, 3.5.27.174, 3.5.25.41, ...\r\n",
      "Connecting to chroma-onnx-models.s3.amazonaws.com (chroma-onnx-models.s3.amazonaws.com)|52.217.143.65|:443... connected.\r\n",
      "HTTP request sent, awaiting response... 200 OK\r\n",
      "Length: 83178821 (79M) [application/x-gzip]\r\n",
      "Saving to: '/home/aistudio/.cache/chroma/onnx_models/all-MiniLM-L6-v2/onnx.tar.gz'\r\n",
      "\r\n",
      "/home/aistudio/.cac 100%[===================>]  79.33M  13.7MB/s    in 7.0s    \r\n",
      "\r\n",
      "2025-07-07 14:21:34 (11.3 MB/s) - '/home/aistudio/.cache/chroma/onnx_models/all-MiniLM-L6-v2/onnx.tar.gz' saved [83178821/83178821]\r\n",
      "\r\n"
     ]
    }
   ],
   "source": [
    "!wget -O ~/.cache/chroma/onnx_models/all-MiniLM-L6-v2/onnx.tar.gz \\\n",
    "    https://chroma-onnx-models.s3.amazonaws.com/all-MiniLM-L6-v2/onnx.tar.gz"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "py35-paddle1.2.0"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
