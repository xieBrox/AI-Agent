{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "# ERNIE-4.5-VL-28B-A3B-Paddle Local Deployment and Calling Tutorial\n",
    "\n",
    "## Selection of Wenxin Open-Source Models\n",
    "\n",
    "### ERNIE-4.5 Model Series Specification Comparison Table\n",
    "\n",
    "| Model Series | Model Name | Total Parameters | Activated Parameters | Modality Support | Context Length | Main Usage | Deployment Scenario |\n",
    "|---------|---------|--------|---------|---------|-----------|---------|---------|\n",
    "| **A47B Large Scale** | ERNIE-4.5-300B-A47B-Base | 300B | 47B | Text | 128K | Pre-training Base | Cloud GPU Cluster |\n",
    "| | ERNIE-4.5-300B-A47B | 300B | 47B | Text | 128K | Instruction Following/Creative Generation | Cloud GPU Cluster |\n",
    "| | ERNIE-4.5-VL-424B-A47B-Base | 424B | 47B | Text+Vision | 128K | Multimodal Pre-training | Cloud GPU Cluster |\n",
    "| | ERNIE-4.5-VL-424B-A47B | 424B | 47B | Text+Vision | 128K | Image-Text Understanding/Generation | Cloud GPU Cluster |\n",
    "| **A3B Medium Scale** | ERNIE-4.5-21B-A3B-Base | 21B | 3B | Text | 128K | Pre-training Base | Single-machine Multi-GPU |\n",
    "| | ERNIE-4.5-21B-A3B | 21B | 3B | Text | 128K | Dialogue/Document Processing | Single-machine Multi-GPU |\n",
    "| | ERNIE-4.5-VL-28B-A3B-Base | 28B | 3B | Text+Vision | 128K | Multimodal Pre-training | Single-machine Multi-GPU |\n",
    "| | ERNIE-4.5-VL-28B-A3B | 28B | 3B | Text+Vision | 128K | Lightweight Multimodal Applications | Single-machine Multi-GPU |\n",
    "| **0.3B Lightweight** | ERNIE-4.5-0.3B-Base | 0.3B | 0.3B | Text | 4K | End-side Pre-training | Mobile/Edge |\n",
    "| | ERNIE-4.5-0.3B | 0.3B | 0.3B | Text | 4K | Real-time Dialogue | Mobile/Edge |\n",
    "\n",
    "### Model Specification Selection Strategy Table\n",
    "\n",
    "| Application Scenario | Recommended Model | Reason | Hardware Requirements | Inference Latency |\n",
    "|---------|---------|------|---------|---------|\n",
    "| **Complex Reasoning Tasks** | ERNIE-4.5-300B-A47B | Strongest reasoning capability | 8Ã—A100(80GB) | High |\n",
    "| **Creative Content Generation** | ERNIE-4.5-300B-A47B | Best creative performance | 8Ã—A100(80GB) | High |\n",
    "| **Multimodal Understanding** | ERNIE-4.5-VL-424B-A47B | Image-text fusion understanding | 8Ã—A100(80GB) | High |\n",
    "| **Daily Dialogue Customer Service** | ERNIE-4.5-21B-A3B | Balanced performance and cost | 4Ã—V100(32GB) | Medium |\n",
    "| **Document Information Extraction** | ERNIE-4.5-21B-A3B | Sufficient understanding capability | 4Ã—V100(32GB) | Medium |\n",
    "| **Lightweight Multimodal** | ERNIE-4.5-VL-28B-A3B | Balanced image-text processing | 4Ã—V100(32GB) | Medium |\n",
    "| **Mobile Applications** | ERNIE-4.5-0.3B | Low latency and fast response | 1Ã—GPU/CPU | Low |\n",
    "| **Edge Computing** | ERNIE-4.5-0.3B | Minimal resource consumption | CPU/NPU | Low |\n",
    "\n",
    "### Why Choose ERNIE-4.5-VL-28B-A3B-Paddle Model?\n",
    "\n",
    "#### 1. **Optimal Balance between Performance and Cost**\n",
    "- **Moderate parameter scale**: 28B total parameters, 3B activated parameters, ensuring inference capability while controlling computational costs\n",
    "- **Reasonable hardware requirements**: Supports single-machine multi-GPU deployment (4Ã—V100 or 2Ã—A100), reducing hardware threshold by 75% compared to A47B series\n",
    "- **Moderate inference latency**: 3-5 times faster response speed than large-scale models while ensuring output quality\n",
    "\n",
    "#### 2. **Outstanding Multimodal Capabilities**\n",
    "- **Text+Vision fusion**: Natively supports image-text understanding without additional visual encoders\n",
    "- **Long context support**: 128K token context length, capable of processing long documents and multiple images\n",
    "- **Rich application scenarios**: Suitable for document analysis, image description, multimodal question answering, etc.\n",
    "\n",
    "#### 3. **Deployment Friendliness**\n",
    "- **AIStudio platform optimization**: Official in-depth adaptation, providing one-click download and deployment\n",
    "- **FastDeploy integration**: Complete inference acceleration and service support\n",
    "- **Open-source ecosystem**: PaddlePaddle ecosystem with comprehensive documentation and active community\n",
    "\n",
    "#### 4. **Practical Application Value**\n",
    "- **Enterprise-grade availability**: Significantly improved understanding capability and generation quality compared to 0.3B models\n",
    "- **Controllable costs**: 70% lower deployment cost and 60% lower operating cost compared to A47B series\n",
    "- **Strong scalability**: Supports LoRA fine-tuning for scenario-specific optimization\n",
    "\n",
    "#### 5. **Technical Advancement**\n",
    "- **MoE architecture**: Mixture of Experts model with activated parameters only 1/9 of total parameters, high inference efficiency\n",
    "- **Multimodal alignment**: Deep fusion of visual and text features, understanding capability close to GPT-4V\n",
    "- **Chinese optimization**: In-depth optimization for Chinese scenarios, excellent performance in Chinese multimodal tasks\n",
    "\n",
    "#### Selection Recommendations\n",
    "**Recommended scenarios**:\n",
    "- Multimodal AI application development for small and medium enterprises\n",
    "- Multimodal experiments in educational and research projects\n",
    "- AI product prototype verification for individual developers\n",
    "- Business systems requiring image-text understanding capabilities\n",
    "\n",
    "**Not recommended scenarios**:\n",
    "- Real-time systems with extremely high requirements for inference latency (choose 0.3B)\n",
    "- Scenarios with sufficient budget pursuing ultimate performance (choose A47B)\n",
    "- Pure text applications without multimodal needs (choose 21B-A3B)\n",
    "\n",
    "## I. Environment Preparation\n",
    "### 1. Hardware Requirements\n",
    "- **GPU**: NVIDIA A100 80GB (supports single/multi-GPU, recommended CUDA 11.8+)  \n",
    "- **Memory**: â‰¥60GB RAM  \n",
    "- **Storage**: â‰¥120GB (model is approximately 28GB, need reserved space for logs/cache)  \n",
    "\n",
    "### 2. Software Dependencies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "scrolled": true,
    "trusted": true
   },
   "outputs": [],
   "source": [
    "%%capture\n",
    "!python -m pip install fastdeploy-gpu -i https://www.paddlepaddle.org.cn/packages/stable/fastdeploy-gpu-80_90/ --extra-index-url https://mirrors.tuna.tsinghua.edu.cn/pypi/web/simple"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. Environment Verification\n",
    "#### â‘  Check CUDA Version"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "scrolled": true,
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "nvcc: NVIDIA (R) Cuda compiler driver\r\n",
      "Copyright (c) 2005-2024 NVIDIA Corporation\r\n",
      "Built on Tue_Oct_29_23:50:19_PDT_2024\r\n",
      "Cuda compilation tools, release 12.6, V12.6.85\r\n",
      "Build cuda_12.6.r12.6/compiler.35059454_0\r\n"
     ]
    }
   ],
   "source": [
    "!nvcc --version\n",
    "# Expected output example:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### â‘¡ Check GPU Information"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "jupyter": {
     "outputs_hidden": false
    },
    "scrolled": true,
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sun Jul  6 18:10:39 2025       \r\n",
      "+-----------------------------------------------------------------------------------------+\r\n",
      "| NVIDIA-SMI 570.148.08             Driver Version: 570.148.08     CUDA Version: 12.8     |\r\n",
      "|-----------------------------------------+------------------------+----------------------+\r\n",
      "| GPU  Name                 Persistence-M | Bus-Id          Disp.A | Volatile Uncorr. ECC |\r\n",
      "| Fan  Temp   Perf          Pwr:Usage/Cap |           Memory-Usage | GPU-Util  Compute M. |\r\n",
      "|                                         |                        |               MIG M. |\r\n",
      "|=========================================+========================+======================|\r\n",
      "|   0  NVIDIA A800-SXM4-80GB          On  |   00000000:D0:00.0 Off |                    0 |\r\n",
      "| N/A   29C    P0             64W /  400W |   68463MiB /  81920MiB |      0%      Default |\r\n",
      "|                                         |                        |             Disabled |\r\n",
      "+-----------------------------------------+------------------------+----------------------+\r\n",
      "                                                                                         \r\n",
      "+-----------------------------------------------------------------------------------------+\r\n",
      "| Processes:                                                                              |\r\n",
      "|  GPU   GI   CI              PID   Type   Process name                        GPU Memory |\r\n",
      "|        ID   ID                                                               Usage      |\r\n",
      "|=========================================================================================|\r\n",
      "|    0   N/A  N/A          104781      C   ...on35-paddle120-env/bin/python      68454MiB |\r\n",
      "+-----------------------------------------------------------------------------------------+\r\n"
     ]
    }
   ],
   "source": [
    "# Check GPU status and memory\n",
    "!nvidia-smi\n",
    "# Expected output example:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### â‘¢ Environment Verification Instructions\n",
    "| Check Item | Minimum Requirement | Recommended Configuration | Description |\n",
    "|---------|---------|---------|------|\n",
    "| **CUDA Version** | 11.8+ | 12.6+ | Supports latest GPU acceleration features |\n",
    "| **Driver Version** | 520.61.05+ | 570.148.08+ | Compatible with A800/A100 series GPUs |\n",
    "| **GPU Model** | V100(32GB) | A800/A100(80GB) | Ensure sufficient memory for 28B model |\n",
    "| **Memory Capacity** | 32GB+ | 80GB+ | Model loading requires approximately 25-30GB memory |\n",
    "| **GPU Utilization** | 0% | 0% | GPU should be idle before startup |\n",
    "\n",
    "#### â‘£ Troubleshooting Common Environment Issues"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "scrolled": true,
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/opt/conda/envs/python35-paddle120-env/lib/python3.10/site-packages/paddle/utils/cpp_extension/extension_utils.py:715: UserWarning: No ccache found. Please be aware that recompiling all source files may be required. You can download and install ccache from: https://github.com/ccache/ccache/blob/master/doc/INSTALL.md\r\n",
      "  warnings.warn(warning_message)\r\n",
      "GPU available: True\r\n",
      "Number of GPU devices: 1\r\n",
      "/opt/conda/envs/python35-paddle120-env/lib/python3.10/site-packages/paddle/utils/cpp_extension/extension_utils.py:715: UserWarning: No ccache found. Please be aware that recompiling all source files may be required. You can download and install ccache from: https://github.com/ccache/ccache/blob/master/doc/INSTALL.md\r\n",
      "  warnings.warn(warning_message)\r\n",
      "FastDeploy installed successfully!\r\n",
      "OpenAI library version: 1.91.0\r\n"
     ]
    }
   ],
   "source": [
    "# Check PaddlePaddle GPU support\n",
    "!python -c \"import paddle; print('GPU available:', paddle.is_compiled_with_cuda()); print('Number of GPU devices:', paddle.device.cuda.device_count())\"\n",
    "\n",
    "# Check FastDeploy installation\n",
    "!python -c \"from fastdeploy import LLM, SamplingParams; print('FastDeploy installed successfully!')\"\n",
    "\n",
    "# Check OpenAI library version\n",
    "!python -c \"import openai; print('OpenAI library version:', openai.__version__)\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## II. Model Download and Directory Structure\n",
    "### 1. Download Model Files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "jupyter": {
     "outputs_hidden": false
    },
    "scrolled": true,
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# Download model using AIStudio command\n",
    "%%capture\n",
    "!aistudio download --model PaddlePaddle/ERNIE-4.5-VL-28B-A3B-Paddle --local_dir /home/aistudio/work/models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "jupyter": {
     "outputs_hidden": false
    },
    "scrolled": true,
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "total 57441133\r\n",
      "-rw-r--r-- 1 aistudio aistudio      11366 Jul  5 18:29 LICENSE\r\n",
      "-rw-r--r-- 1 aistudio aistudio       9077 Jul  5 18:30 README.md\r\n",
      "-rw-r--r-- 1 aistudio aistudio      86904 Jul  5 18:29 added_tokens.json\r\n",
      "-rw-r--r-- 1 aistudio aistudio       1306 Jul  5 18:28 config.json\r\n",
      "-rw-r--r-- 1 aistudio aistudio        134 Jul  5 18:29 generation_config.json\r\n",
      "-rw-r--r-- 1 aistudio aistudio 4991326368 Jul  5 18:30 model-00001-of-00012.safetensors\r\n",
      "-rw-r--r-- 1 aistudio aistudio 4988696384 Jul  5 18:29 model-00002-of-00012.safetensors\r\n",
      "-rw-r--r-- 1 aistudio aistudio 4999185600 Jul  5 18:30 model-00003-of-00012.safetensors\r\n",
      "-rw-r--r-- 1 aistudio aistudio 4995268296 Jul  5 18:29 model-00004-of-00012.safetensors\r\n",
      "-rw-r--r-- 1 aistudio aistudio 4988696984 Jul  5 18:30 model-00005-of-00012.safetensors\r\n",
      "-rw-r--r-- 1 aistudio aistudio 4999193256 Jul  5 18:29 model-00006-of-00012.safetensors\r\n",
      "-rw-r--r-- 1 aistudio aistudio 4995261896 Jul  5 18:30 model-00007-of-00012.safetensors\r\n",
      "-rw-r--r-- 1 aistudio aistudio 4999183248 Jul  5 18:30 model-00008-of-00012.safetensors\r\n",
      "-rw-r--r-- 1 aistudio aistudio 4995271816 Jul  5 18:30 model-00009-of-00012.safetensors\r\n",
      "-rw-r--r-- 1 aistudio aistudio 4988696992 Jul  5 18:30 model-00010-of-00012.safetensors\r\n",
      "-rw-r--r-- 1 aistudio aistudio 4999190216 Jul  5 18:30 model-00011-of-00012.safetensors\r\n",
      "-rw-r--r-- 1 aistudio aistudio 3877260800 Jul  5 18:29 model-00012-of-00012.safetensors\r\n",
      "-rw-r--r-- 1 aistudio aistudio     691887 Jul  5 18:28 model.safetensors.index.json\r\n",
      "-rw-r--r-- 1 aistudio aistudio        615 Jul  5 18:28 preprocessor_config.json\r\n",
      "-rw-r--r-- 1 aistudio aistudio      62694 Jul  5 18:28 special_tokens_map.json\r\n",
      "-rw-r--r-- 1 aistudio aistudio    1614362 Jul  5 18:28 tokenizer.model\r\n",
      "-rw-r--r-- 1 aistudio aistudio       3606 Jul  5 18:28 tokenizer_config.json\r\n"
     ]
    }
   ],
   "source": [
    "# View model files\n",
    "!ls -l work/models"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. Directory Structure\n",
    "```\n",
    "work/\n",
    "â””â”€â”€ models/\n",
    "    â”œâ”€â”€ LICENSE                           # License file\n",
    "    â”œâ”€â”€ README.md                         # Model description document\n",
    "    â”œâ”€â”€ added_tokens.json                 # Added token configuration\n",
    "    â”œâ”€â”€ config.json                       # Model configuration file\n",
    "    â”œâ”€â”€ generation_config.json            # Generation configuration file\n",
    "    â”œâ”€â”€ model-00001-of-00012.safetensors  # Model parameter file (shard 1/12)\n",
    "    â”œâ”€â”€ model-00002-of-00012.safetensors  # Model parameter file (shard 2/12)\n",
    "    â”œâ”€â”€ model-00003-of-00012.safetensors  # Model parameter file (shard 3/12)\n",
    "    â”œâ”€â”€ model-00004-of-00012.safetensors  # Model parameter file (shard 4/12)\n",
    "    â”œâ”€â”€ model-00005-of-00012.safetensors  # Model parameter file (shard 5/12)\n",
    "    â”œâ”€â”€ model-00006-of-00012.safetensors  # Model parameter file (shard 6/12)\n",
    "    â”œâ”€â”€ model-00007-of-00012.safetensors  # Model parameter file (shard 7/12)\n",
    "    â”œâ”€â”€ model-00008-of-00012.safetensors  # Model parameter file (shard 8/12)\n",
    "    â”œâ”€â”€ model-00009-of-00012.safetensors  # Model parameter file (shard 9/12)\n",
    "    â”œâ”€â”€ model-00010-of-00012.safetensors  # Model parameter file (shard 10/12)\n",
    "    â”œâ”€â”€ model-00011-of-00012.safetensors  # Model parameter file (shard 11/12)\n",
    "    â”œâ”€â”€ model-00012-of-00012.safetensors  # Model parameter file (shard 12/12)\n",
    "    â”œâ”€â”€ model.safetensors.index.json      # Model shard index file\n",
    "    â”œâ”€â”€ preprocessor_config.json          # Preprocessor configuration\n",
    "    â”œâ”€â”€ special_tokens_map.json           # Special token mapping\n",
    "    â”œâ”€â”€ tokenizer.model                   # Tokenizer model file\n",
    "    â””â”€â”€ tokenizer_config.json             # Tokenizer configuration file\n",
    "```\n",
    "\n",
    "## III. Start Service (Key Commands)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "jupyter": {
     "outputs_hidden": false
    },
    "scrolled": true,
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/opt/conda/envs/python35-paddle120-env/lib/python3.10/site-packages/paddle/utils/cpp_extension/extension_utils.py:715: UserWarning: No ccache found. Please be aware that recompiling all source files may be required. You can download and install ccache from: https://github.com/ccache/ccache/blob/master/doc/INSTALL.md\r\n",
      "  warnings.warn(warning_message)\r\n",
      "/home/aistudio/external-libraries/lib/python3.10/site-packages/_distutils_hack/__init__.py:30: UserWarning: Setuptools is replacing distutils. Support for replacing an already imported distutils is deprecated. In the future, this condition will fail. Register concerns at https://github.com/pypa/setuptools/issues/new?template=distutils-deprecation.yml\r\n",
      "  warnings.warn(\r\n",
      "\u001b[32m[2025-07-05 18:31:56,005] [    INFO]\u001b[0m - loading configuration file work/models/preprocessor_config.json\u001b[0m\r\n",
      "INFO     2025-07-05 18:31:59,153 14427 engine.py[line:206] Waitting worker processes ready...\r\n",
      "Loading Weights: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 100/100 [01:17<00:00,  1.30it/s]\r\n",
      "Loading Layers: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 100/100 [00:07<00:00, 13.31it/s]\r\n",
      "INFO     2025-07-05 18:33:37,799 14427 engine.py[line:276] Worker processes are launched with 119.77000260353088 seconds.\r\n",
      "INFO     2025-07-05 18:33:37,800 14427 api_server.py[line:91] Launching metrics service at http://0.0.0.0:8181/metrics\r\n",
      "INFO     2025-07-05 18:33:37,800 14427 api_server.py[line:94] Launching chat completion service at http://0.0.0.0:8180/v1/chat/completions\r\n",
      "INFO     2025-07-05 18:33:37,800 14427 api_server.py[line:97] Launching completion service at http://0.0.0.0:8180/v1/completions\r\n",
      "\u001b[32mINFO\u001b[0m:     Started server process [\u001b[36m14427\u001b[0m]\r\n",
      "\u001b[32mINFO\u001b[0m:     Waiting for application startup.\r\n",
      "\u001b[32m[2025-07-05 18:33:55,042] [    INFO]\u001b[0m - loading configuration file work/models/preprocessor_config.json\u001b[0m\r\n",
      "\u001b[32mINFO\u001b[0m:     Application startup complete.\r\n",
      "\u001b[32mINFO\u001b[0m:     Uvicorn running on \u001b[1mhttp://0.0.0.0:8180\u001b[0m (Press CTRL+C to quit)\r\n"
     ]
    }
   ],
   "source": [
    "!python -m fastdeploy.entrypoints.openai.api_server \\\n",
    "       --model work/models \\\n",
    "       --port 8180 \\\n",
    "       --metrics-port 8181 \\\n",
    "       --engine-worker-queue-port 8182 \\\n",
    "       --max-model-len 32768 \\\n",
    "       --enable-mm \\\n",
    "       --reasoning-parser ernie-45-vl \\\n",
    "       --max-num-seqs 32"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "## Model Deployment (Recommended to Deploy in a New Terminal)\n",
    "![](https://ai-studio-static-online.cdn.bcebos.com/adb145c8b36e4bfcb4eb4fc95addd20dedc26cffd6514e189c18900cbc593dc2)\n",
    "\n",
    "### Detailed Explanation of Service Startup Parameters\n",
    "\n",
    "| Parameter Name | Description | Default Value | Example Value |\n",
    "|---------|---------|-------|-------|\n",
    "| `--model` | Model file path, directory containing model weights and configuration files | Required | `work/models` |\n",
    "| `--port` | API service listening port, clients access the service through this port | 8000 | `8180` |\n",
    "| `--metrics-port` | Monitoring metrics service port, used for performance monitoring and health checks | 8001 | `8181` |\n",
    "| `--engine-worker-queue-port` | Engine worker queue port, used for internal task scheduling | 8002 | `8182` |\n",
    "| `--max-model-len` | Maximum sequence length (number of tokens) supported by the model | 2048 | `32768` |\n",
    "| `--enable-mm` | Enable multimodal functionality (text+image processing) | False | `Enabled` |\n",
    "| `--reasoning-parser` | Reasoning parser type, specifying the model's reasoning logic | None | `ernie-45-vl` |\n",
    "| `--max-num-seqs` | Maximum number of concurrent sequences, controlling batch size | 256 | `32` |\n",
    "\n",
    "### Other Common Parameters\n",
    "\n",
    "| Parameter Name | Description | Default Value | Notes |\n",
    "|---------|---------|-------|------|\n",
    "| `--host` | Host address bound by the service | 0.0.0.0 | Set to 0.0.0.0 to allow external access |\n",
    "| `--trust-remote-code` | Trust remote code execution | False | Required when loading custom models |\n",
    "| `--tensor-parallel-size` | Tensor parallel size (multi-GPU) | 1 | Set according to the number of GPUs |\n",
    "| `--gpu-memory-utilization` | GPU memory utilization | 0.9 | Recommended between 0.8-0.95 |\n",
    "| `--max-num-batched-tokens` | Maximum number of batched tokens | Auto-calculated | Adjust according to GPU memory |\n",
    "| `--swap-space` | Swap space size (GB) | 4 | Used when memory is insufficient |\n",
    "| `--enable-lora` | Enable LoRA adapter | False | Used when fine-tuning models |\n",
    "| `--max-log-len` | Maximum log length | Unlimited | Control log file size |\n",
    "\n",
    "### Service Verification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "jupyter": {
     "outputs_hidden": false
    },
    "scrolled": true,
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\"id\":\"chatcmpl-bd47b6ab-f962-4ad2-bf8c-e418cad02b8e\",\"object\":\"chat.completion\",\"created\":1751798020,\"model\":\"null\",\"choices\":[{\"index\":0,\"message\":{\"role\":\"assistant\",\"content\":\"\\n\\nHello! I'm your intelligent assistant. I can help you answer various questions, provide suggestions, or chat with you about various topics. Whether it's academic doubts, small problems in life, or if you want to hear a story or create some content, I'll explore with you! Feel free to interact with me anytime~ ðŸ˜Š\",\"reasoning_content\":\"\\nThe user asked me to introduce myself, and I need to respond in a natural and friendly way. First, I need to determine what the user's needs are. They might be new to this platform and want to understand the basic functions of the AI, or they might just be curious about my capabilities. As an AI assistant, I should highlight my main functions, such as answering questions, providing suggestions, and helping with learning.\\n\\nNext, I should consider the user's potential needs. They might want to know what I can do or how to interact with me. Therefore, I need to list several specific examples, such as explaining complex concepts, generating creative content, and handling daily tasks, so that users can more intuitively understand my uses.\\n\\nI also need to keep the tone friendly and avoid using overly technical terms to make the user feel relaxed. For example, use \"chat with you anytime\" instead of \"provide 24/7 support\". At the same time, keep the answer concise but informative enough to make users want to explore further.\\n\\nIn addition, users may not have clearly stated their specific needs, so I need to cover different aspects such as study, work, and entertainment to demonstrate my versatility. For example, mentioning writing poems, making plans, and translating allows users to choose usage scenarios according to their own situation.\\n\\nFinally, the ending should encourage users to ask questions, letting them know they can start a conversation at any time and maintaining an open attitude. This way, the entire response is both comprehensive and friendly, meeting the user's needs and expectations.\\n\",\"tool_calls\":null},\"finish_reason\":\"stop\"}],\"usage\":{\"prompt_tokens\":14,\"total_tokens\":331,\"completion_tokens\":317,\"prompt_tokens_details\":{\"cached_tokens\":0}}}"
     ]
    }
   ],
   "source": [
    "# Check if the model is loaded correctly\n",
    "!curl -X POST http://localhost:8180/v1/chat/completions \\\n",
    "  -H \"Content-Type: application/json\" \\\n",
    "  -d '{\"model\": \"null\",\"messages\": [{\"role\": \"user\", \"content\": \"Hello, please introduce yourself\"}],\"temperature\": 0.7}'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## IV. Model Calling Examples\n",
    "\n",
    "### 1. OpenAI Library Calling Method\n",
    "\n",
    "#### â‘  Text Generation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "jupyter": {
     "outputs_hidden": false
    },
    "scrolled": true,
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\r\n",
      "\r\n",
      "I am an intelligent assistant empowered by **Aistudio** (Baidu's AI technology ecosystem platform) and the **Wenxin Large Model** technology system. Here is an introduction to my core features and functions:\r\n",
      "\r\n",
      "### 1. **Technical Background**\r\n",
      "   - Based on Baidu's independently developed **Wenxin Large Model** technology, integrating multimodal understanding, deep logical reasoning, and natural language generation capabilities.\r\n",
      "   - Leveraging **Aistudio's** development tools and ecological resources to support rapid access to AI capabilities for innovative applications.\r\n",
      "\r\n",
      "### 2. **Core Capabilities**\r\n",
      "   - **Knowledge Q&A**: Covering a wide range of fields (technology, culture, life, etc.) to provide accurate and structured answers.\r\n",
      "   - **Text Generation**: Supporting diverse text creation such as creative writing, copy generation, code assistance, and summary extraction.\r\n",
      "   - **Logical Reasoning**: Handling complex problems, analyzing cause-effect relationships, and assisting in decision-making and problem decomposition.\r\n",
      "   - **Multi-turn Dialogue**: Supporting context understanding for a smooth continuous interaction experience.\r\n",
      "\r\n",
      "### 3. **Application Scenarios**\r\n",
      "   - **Education and Research**: Assisting in learning, paper assistance, and knowledge graph construction.\r\n",
      "   - **Creation Assistance**: Story generation, poetry creation, and marketing copy optimization.\r\n",
      "   - **Daily Assistant**: Schedule management, information query, and life advice.\r\n",
      "   - **Development Support**: API calls and SDK integration to help developers quickly build AI applications.\r\n",
      "\r\n",
      "### 4. **Advantages**\r\n",
      "   - **Efficient and Accurate**: Quickly responding to complex needs and reducing information screening costs.\r\n",
      "   - **Continuous Learning**: Continuously improving capabilities through user feedback and iterative optimization.\r\n",
      "   - **Safe and Reliable**: Adhering to privacy protection principles to ensure compliance and security of interactive content.\r\n",
      "\r\n",
      "### 5. **How to Use**\r\n",
      "   - **Direct Dialogue**: Interact with me through web pages, apps, or integrated platforms.\r\n",
      "   - **API/SDK Access**: Developers can call interfaces to implement customized functions.\r\n",
      "   - **Explore Cases**: Visit the Aistudio official website or related documents to obtain practical tutorials.\r\n",
      "\r\n",
      "Looking forward to exploring the infinite possibilities of AI with you! You can try asking questions or putting forward needs, and I will do my best to provide support. ðŸ˜Š"
     ]
    }
   ],
   "source": [
    "import openai\n",
    "host = \"0.0.0.0\"\n",
    "port = \"8180\"\n",
    "client = openai.Client(base_url=f\"http://{host}:{port}/v1\", api_key=\"null\")\n",
    "\n",
    "response = client.chat.completions.create(\n",
    "    model=\"null\",\n",
    "    messages=[\n",
    "        {\"role\": \"user\", \"content\": \"You are an intelligent assistant developed by Aistudio and Wenxin Large Model. Please introduce yourself.\"}\n",
    "    ],\n",
    "    stream=True,\n",
    ")\n",
    "for chunk in response:\n",
    "    if chunk.choices[0].delta:\n",
    "        print(chunk.choices[0].delta.content, end='')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### â‘¡ Image Description Generation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "jupyter": {
     "outputs_hidden": false
    },
    "scrolled": true,
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Image description: \r\n",
      "This image showcases the core architecture and functional modules of PaddleNLP (PaddlePaddle Natural Language Processing Development Library). The overall design is concise and clear, adopting a blue-white color scheme that highlights technical professionalism. The image is divided into three main parts:\r\n",
      "\r\n",
      "### 1. **Industrial-Grade Predefined Tasks (Taskflow)**\r\n",
      "   - **Natural Language Understanding**: Provides basic understanding capabilities such as lexical analysis, text correction, sentiment analysis, and syntactic analysis.\r\n",
      "   - **Natural Language Generation**: Covers application scenarios such as automatic couplet creation, intelligent poetry writing, generative question answering, and open-domain dialogue, meeting text creation and interaction needs.\r\n",
      "\r\n",
      "### 2. **Industry-Grade Model Library**\r\n",
      "   - **Self-developed Pre-trained Models**: Includes ERNIE series (such as ERNIE-1.0, ERNIE-2.0, ERNIE-Tiny, etc.), PLATO-2, SKEP, etc., supporting multi-task learning and few-shot scenarios.\r\n",
      "   - **Full-Scenario Applications**: Provides practical functions such as text classification, matching, generation, semantic indexing, information extraction, text translation, and knowledge association, adapting to diverse business needs.\r\n",
      "\r\n",
      "### 3. **Core APIs in Text Domain**\r\n",
      "   - Provides underlying tools such as data management (Data/Datasets), embedding representation (Embedding), model architecture (Transformers/Seq2Vec), evaluation metrics (Metrics), and loss functions (Losses), supporting developers in flexibly building custom NLP applications.\r\n",
      "\r\n",
      "### Bottom Logo\r\n",
      "The PaddlePaddle brand logo emphasizes the open-source ecological positioning. The overall architecture reflects a complete technology stack from predefined tasks to model libraries and then to development tools, suitable for enterprise-level and developer rapid implementation of NLP scenarios.\r\n"
     ]
    }
   ],
   "source": [
    "import openai\n",
    "import base64\n",
    "\n",
    "def encode_image(image_path):\n",
    "    with open(image_path, \"rb\") as image_file:\n",
    "        return base64.b64encode(image_file.read()).decode('utf-8')\n",
    "\n",
    "client = openai.Client(\n",
    "    base_url=\"http://0.0.0.0:8180/v1\",\n",
    "    api_key=\"null\"\n",
    ")\n",
    "\n",
    "response = client.chat.completions.create(\n",
    "    model=\"null\",\n",
    "    messages=[\n",
    "        {\n",
    "            \"role\": \"user\",\n",
    "            \"content\": [\n",
    "                {\n",
    "                    \"type\": \"image_url\",\n",
    "                    \"image_url\": {\n",
    "                        \"url\": f\"data:image/jpeg;base64,{encode_image('1.jpg')}\"\n",
    "                    }\n",
    "                },\n",
    "                {\n",
    "                    \"type\": \"text\",\n",
    "                    \"text\": \"Generate a description of this image\"\n",
    "                }\n",
    "            ]\n",
    "        }\n",
    "    ],\n",
    "    stream=True,\n",
    ")\n",
    "\n",
    "print(\"Image description: \", end='', flush=True)\n",
    "for chunk in response:\n",
    "    if chunk.choices and chunk.choices[0].delta.content:\n",
    "        print(chunk.choices[0].delta.content, end='', flush=True)\n",
    "print()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. Requests Library Calling Method\n",
    "\n",
    "#### â‘  Text Generation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "jupyter": {
     "outputs_hidden": false
    },
    "scrolled": true,
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\r\n",
      "\r\n",
      "I am an intelligent assistant empowered by **Aistudio** (Baidu's open-source deep learning platform) and the **Wenxin Large Model** technical framework. Here is an introduction to my core features and functions:\r\n",
      "\r\n",
      "### 1. **Identity Background**\r\n",
      "   - Based on the technical foundation of the Wenxin Large Model, integrating massive multi-domain knowledge bases and deep learning algorithms, with strong language understanding and generation capabilities.\r\n",
      "   - Continuously optimized by Baidu's AI team, focusing on the balance of logical reasoning, knowledge integration, and interaction experience.\r\n",
      "\r\n",
      "### 2. **Core Capabilities**\r\n",
      "   - **Natural Language Interaction**: Supports Chinese and multilingual dialogue, capable of understanding complex problems and providing structured answers.\r\n",
      "   - **Knowledge Q&A**: Covers a wide range of fields such as science, technology, humanities, and life, providing accurate information and explanations.\r\n",
      "   - **Text Generation**: Can write code, articles, poetry, reports, etc., supporting creative and practical scenario needs.\r\n",
      "   - **Logical Reasoning**: Handles tasks requiring reasoning such as math problems, logical puzzles, and decision analysis.\r\n",
      "   - **Learning Assistance**: Provides support for study planning, knowledge point analysis, and language learning.\r\n",
      "\r\n",
      "### 3. **Typical Application Scenarios**\r\n",
      "   - **Programming Development**: Code generation, debugging suggestions, and technical document assistance.\r\n",
      "   - **Content Creation**: Copywriting, storyæž„æ€, academic writing support.\r\n",
      "   - **Learning Tutoring**: Answering subject questions and providing learning strategy suggestions.\r\n",
      "   - **Daily Assistant**: Information query, schedule reminders, and life advice.\r\n",
      "\r\n",
      "### 4. **Advantages**\r\n",
      "   - **Efficient and Accurate**: Quickly responds to complex needs and reduces information screening costs.\r\n",
      "   - **Continuous Evolution**: Continuously improves capability boundaries through user feedback and data iteration.\r\n",
      "   - **Safe and Reliable**: Follows ethical norms and focuses on privacy protection and content compliance.\r\n",
      "\r\n",
      "### 5. **How to Use Me?**\r\n",
      "   - Ask questions or describe needs directly (e.g., \"Write an argumentative essay on AI ethics\").\r\n",
      "   - Specify task types (e.g., \"Generate Python crawler code\").\r\n",
      "   - Provide contextual background to help me understand more complex scenarios.\r\n",
      "\r\n",
      "Looking forward to exploring the boundaries of knowledge with you and solving practical problems! ðŸ˜Š\r\n"
     ]
    }
   ],
   "source": [
    "import requests\n",
    "import json\n",
    "\n",
    "url = \"http://localhost:8180/v1/chat/completions\"\n",
    "headers = {\"Content-Type\": \"application/json\"}\n",
    "payload = {\n",
    "    \"model\": \"null\",\n",
    "    \"messages\": [\n",
    "        {\"role\": \"user\", \"content\": \"You are an intelligent assistant developed by Aistudio and Wenxin Large Model. Please introduce yourself.\"}\n",
    "    ],\n",
    "    \"stream\": True\n",
    "}\n",
    "\n",
    "response = requests.post(url, headers=headers, json=payload, stream=True)\n",
    "\n",
    "for line in response.iter_lines():\n",
    "    if line:\n",
    "        line = line.decode('utf-8').replace('data: ', '')\n",
    "\n",
    "        if line.strip() == '[DONE]':\n",
    "            continue\n",
    "        try:\n",
    "\n",
    "            data = json.loads(line)\n",
    "\n",
    "            if 'choices' in data and len(data['choices']) > 0:\n",
    "                delta = data['choices'][0].get('delta', {})\n",
    "                content = delta.get('content', '')\n",
    "                if content:\n",
    "                    print(content, end='', flush=True)\n",
    "        except json.JSONDecodeError as e:\n",
    "            print(f\"Error decoding line: {line}\")\n",
    "            print(f\"Error: {e}\")\n",
    "\n",
    "print()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### â‘¡ Image Description Generation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "jupyter": {
     "outputs_hidden": false
    },
    "scrolled": true,
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\r\n",
      "The image displays the core architecture and functional modules of PaddleNLP (PaddlePaddle Natural Language Processing Development Library), adopting a concise blue-white color scheme with clear structure, divided into three main levels:\r\n",
      "\r\n",
      "### **1. Industrial-Grade Predefined Tasks (Taskflow)**\r\n",
      "- **Natural Language Understanding**: Provides basic understanding capabilities, including lexical analysis (word segmentation, part-of-speech tagging, etc.), text correction, sentiment analysis, and syntactic analysis (grammatical structure parsing).\r\n",
      "- **Natural Language Generation**: Covers diverse generation scenarios such as automatic couplet creation, intelligent poetry writing, generative question answering, and open-domain dialogue, supporting creative text generation.\r\n",
      "\r\n",
      "### **2. Industry-Grade Model Library**\r\n",
      "- **Self-developed Pre-trained Models**: Displays Baidu's developed series of models, such as ERNIE (including versions 1.0/2.0/Tiny/Gram, etc.), PLATO (dialogue model), SKEP (sentiment tendency analysis), ERNIE-UNIMO (multimodal understanding), etc., covering different scales and task requirements.\r\n",
      "- **Full-Scenario Applications**: Provides practical functions such as text classification, matching, generation, semantic indexing, few-shot learning, text graph learning, information extraction, translation, knowledge association, and model compression, adapting to multiple fields such as finance, medical care, and education.\r\n",
      "\r\n",
      "### **3. Core APIs in Text Domain**\r\n",
      "- **Underlying Tool Support**: Provides data loading (Data/Datasets), embedding representation (Embedding), Transformer framework (Transformers), sequence-to-vector conversion (Seq2Vec), evaluation metrics (Metrics), and loss functions (Losses), offering developers flexible model construction and training foundations.\r\n",
      "\r\n",
      "### **Design Highlights**\r\n",
      "- **Modular Layering**: Forming a complete technology stack from tasks to models to tools, reducing development thresholds.\r\n",
      "- **Wide Scene Coverage**: Balancing general understanding and generation capabilities while supporting efficient application in vertical fields.\r\n",
      "- **Complete Technical Ecosystem**: Combining core APIs with pre-trained models, balancing flexibility and performance.\r\n",
      "\r\n",
      "The architecture reflects PaddleNLP's full-stack capabilities in the field of natural language processing, aiming to provide developers with comprehensive support from basic tools to advanced applications.\r\n"
     ]
    }
   ],
   "source": [
    "import requests\n",
    "import json\n",
    "\n",
    "url = \"http://localhost:8180/v1/chat/completions\"\n",
    "payload = {\n",
    "    \"model\":\"null\",\n",
    "    \"messages\":[\n",
    "        {\n",
    "            \"role\":\"user\",\n",
    "            \"content\":[\n",
    "                {\"type\":\"image_url\",\"image_url\":{\"url\":f\"data:image/jpeg;base64,{encode_image('1.jpg')}\"}},\n",
    "                {\"type\":\"text\",\"text\":\"Generate image description\"}\n",
    "            ]\n",
    "        }\n",
    "    ],\n",
    "    \"stream\": True\n",
    "}\n",
    "\n",
    "response = requests.post(url, headers=headers, json=payload, stream=True)\n",
    "\n",
    "for line in response.iter_lines():\n",
    "    if line:\n",
    "        line = line.decode('utf-8').replace('data: ', '')\n",
    "\n",
    "        if line.strip() == '[DONE]':\n",
    "            continue\n",
    "        try:\n",
    "\n",
    "            data = json.loads(line)\n",
    "\n",
    "            if 'choices' in data and len(data['choices']) > 0:\n",
    "                delta = data['choices'][0].get('delta', {})\n",
    "                content = delta.get('content', '')\n",
    "                if content:\n",
    "                    print(content, end='', flush=True)\n",
    "        except json.JSONDecodeError as e:\n",
    "            print(f\"Error decoding line: {line}\")\n",
    "            print(f\"Error: {e}\")\n",
    "\n",
    "print()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. Calling Parameter Description\n",
    "\n",
    "#### Common Parameter Configuration\n",
    "```python\n",
    "# Complete calling parameter example\n",
    "response = client.chat.completions.create(\n",
    "    model=\"null\",                    # Model name (fixed value)\n",
    "    messages=[...],                  # Message list\n",
    "    stream=True,                     # Whether to enable streaming response\n",
    "    max_tokens=2048,                 # Maximum number of generated tokens\n",
    "    temperature=0.7,                 # Temperature parameter (0.0-2.0)\n",
    "    top_p=0.9,                      # Nucleus sampling parameter (0.0-1.0)\n",
    "    frequency_penalty=0.0,           # Frequency penalty (-2.0-2.0)\n",
    "    presence_penalty=0.0,            # Presence penalty (-2.0-2.0)\n",
    "    stop=[\"<|endoftext|>\"],         # Stop word list\n",
    ")\n",
    "```\n",
    "\n",
    "#### Detailed Parameter Description\n",
    "| Parameter Name | Type | Default Value | Description |\n",
    "|---------|------|--------|------|\n",
    "| `model` | str | \"null\" | Model name, fixed as \"null\" for local deployment |\n",
    "| `messages` | list | Required | Dialogue message list, containing role and content |\n",
    "| `stream` | bool | False | Whether to enable streaming response |\n",
    "| `max_tokens` | int | Auto | Maximum number of generated tokens |\n",
    "| `temperature` | float | 1.0 | Controls randomness, higher values mean more randomness |\n",
    "| `top_p` | float | 1.0 | Nucleus sampling, controls vocabulary selection range |\n",
    "| `frequency_penalty` | float | 0.0 | Frequency penalty, reduces repetitive content |\n",
    "| `presence_penalty` | float | 0.0 | Presence penalty, encourages talking about new topics |\n",
    "| `stop` | list | None | List of strings to stop generation |\n",
    "\n",
    "## V. Common Problems and Solutions\n",
    "### 1. Port Occupation Issue\n",
    "```bash\n",
    "# Check processes occupying the port\n",
    "lsof -i:8180\n",
    "\n",
    "# Terminate the process (replace <PID> with the actual process ID)\n",
    "kill -9 <PID>\n",
    "```\n",
    "\n",
    "### 2. Model Loading Failure\n",
    "- **Check directory**: Ensure complete model files (.pdparams/config.json/vocab.txt) exist under `work/models`  \n",
    "- **Parser parameters**: Ensure the startup command includes `--reasoning-parser ernie-45-vl`  \n",
    "- **Driver version**: NVIDIA driver must be â‰¥520.61.05 (supports A100)  \n",
    "\n",
    "### 3. Streaming Response Abnormality\n",
    "- Ensure the `stream=True` parameter is correctly passed  \n",
    "- Check service logs (`fastdeploy_server.log`) for insufficient memory/video memory errors  \n",
    "\n",
    "## VI. Test Cases\n",
    "### 1. Text Generation Verification\n",
    "- **Input**: `\"Summarize the core steps of this tutorial\"`  \n",
    "- **Expected**: Output coherent text containing keywords such as \"environment configuration\", \"service startup\", \"interface calling\", etc.  \n",
    "\n",
    "### 2. Image Description Verification\n",
    "- **Test image**: Use a jpg file containing natural scenes (such as landscapes, people's activities)  \n",
    "- **Expected**: Output sentences containing scene features (such as \"green grassland under blue sky and white clouds\") and action descriptions (such as \"people walking by the lake\")  \n",
    "\n",
    "## VII. Resource Links\n",
    "- **FastDeploy Documentation**: https://www.paddlepaddle.org.cn/fastdeploy  \n",
    "- **AIStudio Platform**: https://aistudio.baidu.com/  \n",
    "- **Model Repository**: https://huggingface.co/baidu/ERNIE-4.5-VL-28B-A3B-Paddle  "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "py35-paddle1.2.0"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
