{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 【ERNIE-4.5-VL-28B】基于ERNIE-4.5-VL-28B-Paddle本地化部署+图RAG+多Agent协同的多模态智能医疗问诊系统 v3.0\n",
    "\n",
    "## 🚀 版本更新说明\n",
    "\n",
    "### v3.0 重大升级 - 图RAG架构\n",
    "- **🎯 核心升级**：从传统向量RAG升级到图RAG，实现知识图谱驱动的智能推理\n",
    "- **🧠 知识表示**：从向量相似度匹配升级到图结构关系推理\n",
    "- **🔍 检索精度**：从语义相似度升级到多跳关系路径查询\n",
    "- **📊 可视化增强**：新增知识图谱可视化界面，支持交互式探索\n",
    "\n",
    "### v2.0 → v3.0 技术架构对比\n",
    "\n",
    "| 特性 | v2.0 传统RAG | v3.0 图RAG |\n",
    "|------|-------------|-----------|\n",
    "| **知识存储** | ChromaDB向量数据库 | NetworkX图数据库 |\n",
    "| **检索方式** | 语义相似度匹配 | 多跳关系路径查询 |\n",
    "| **推理能力** | 基于相似度的召回 | 基于图结构的逻辑推理 |\n",
    "| **知识表示** | 文本片段向量化 | 实体-关系三元组 |\n",
    "| **查询精度** | 语义相关性 | 结构化关系匹配 |\n",
    "| **可解释性** | 相似度分数 | 关系路径追踪 |\n",
    "\n",
    "## 项目概述\n",
    "\n",
    "本项目基于**本地化部署的ERNIE-4.5-VL-28B-A3B-Paddle**多模态大模型，构建了一个集成**图RAG知识图谱**与多Agent协同机制的智能医疗问诊系统。通过FastDeploy框架实现模型的高效本地部署，结合NetworkX图数据库和多模态理解能力，为用户提供专业的医疗咨询服务。\n",
    "\n",
    "### 🎯 项目亮点\n",
    "\n",
    "- **🏥 完整医疗场景**：从症状描述到治疗建议的全流程智能问诊\n",
    "- **🖼️ 多模态融合**：支持文本+图像的混合输入，可分析皮肤病变等医疗图像  \n",
    "- **🧠 本地化部署**：基于ERNIE-4.5-VL-28B-A3B-Paddle的完全本地化方案，数据安全可控\n",
    "- **🕸️ 图RAG驱动**：NetworkX构建的医疗知识图谱，支持多跳关系推理和路径查询\n",
    "- **🤖 多Agent协同**：症状解析、知识检索、诊断决策、可视化等专业Agent的协同工作\n",
    "- **⚡ 高性能推理**：FastDeploy加速框架，单机多卡部署，推理延迟优化\n",
    "- **📊 知识可视化**：交互式知识图谱展示，支持实体关系探索\n",
    "\n",
    "### 🏗️ 系统架构图\n",
    "\n",
    "```mermaid\n",
    "graph TD\n",
    "    A[用户问诊输入] --> B[Gradio前端界面]\n",
    "    B --> C[MedicalConsultation]\n",
    "    C --> D[AgentCoordinator协调器]\n",
    "    \n",
    "    D --> E[ERNIE-4.5-VL本地模型]\n",
    "    E --> F[FastDeploy推理引擎]\n",
    "    F --> G[多模态理解]\n",
    "    \n",
    "    D --> H[SymptomParserAgent]\n",
    "    D --> I[KnowledgeRetrievalAgent] \n",
    "    D --> J[DiagnosisAgent]\n",
    "    D --> K[VisualizationAgent]\n",
    "    \n",
    "    I --> L[GraphKnowledgeBase]\n",
    "    L --> M[NetworkX图数据库]\n",
    "    M --> N[实体关系三元组]\n",
    "    M --> O[多跳路径查询]\n",
    "    \n",
    "    K --> P[知识图谱可视化]\n",
    "    P --> Q[Pyvis交互界面]\n",
    "    \n",
    "    H --> R[症状提取]\n",
    "    I --> S[图结构检索]\n",
    "    J --> T[风险评估]\n",
    "    J --> U[治疗建议]\n",
    "    \n",
    "    R --> V[诊断结果整合]\n",
    "    S --> V\n",
    "    T --> V\n",
    "    U --> V\n",
    "    \n",
    "    V --> W[结构化医疗报告]\n",
    "    W --> B\n",
    "```\n",
    "\n",
    "### 🏗️ 图RAG架构详解\n",
    "\n",
    "```mermaid\n",
    "graph LR\n",
    "    A[医疗文本] --> B[实体抽取]\n",
    "    B --> C[关系识别]\n",
    "    C --> D[三元组构建]\n",
    "    D --> E[图数据库]\n",
    "    \n",
    "    E --> F[症状节点]\n",
    "    E --> G[疾病节点]\n",
    "    E --> H[治疗节点]\n",
    "    E --> I[检查节点]\n",
    "    E --> J[身体部位节点]\n",
    "    E --> K[药物节点]\n",
    "    E --> L[风险因素节点]\n",
    "    \n",
    "    F --> M[CAUSES关系]\n",
    "    G --> N[TREATS关系]\n",
    "    H --> O[REQUIRES关系]\n",
    "    I --> P[AFFECTS关系]\n",
    "    J --> Q[ACCOMPANIES关系]\n",
    "    K --> R[DIAGNOSES关系]\n",
    "    L --> S[PREVENTS关系]\n",
    "    \n",
    "    M --> T[多跳路径查询]\n",
    "    N --> T\n",
    "    O --> T\n",
    "    P --> T\n",
    "    Q --> T\n",
    "    R --> T\n",
    "    S --> T\n",
    "    \n",
    "    T --> U[智能推理]\n",
    "    U --> V[诊断结果]\n",
    "```\n",
    "\n",
    "### 交互流程图\n",
    "![](https://ai-studio-static-online.cdn.bcebos.com/5310ce0b014e478ca32a173fd6e8516fb27413d02b924014be63b8953600a7d8)\n",
    "\n",
    "## 🏆 技术创新总结\n",
    "\n",
    "本项目实现了从**大模型本地化部署**到**图RAG智能医疗应用**的完整技术链路：\n",
    "\n",
    "1. **🔥 核心突破**：28B参数ERNIE-4.5-VL多模态大模型的高效本地化部署\n",
    "2. **🧠 智能升级**：图RAG知识图谱检索 + 多Agent协同的医疗专家系统  \n",
    "3. **🛡️ 数据安全**：完全本地化方案，患者隐私零泄露\n",
    "4. **⚡ 性能优化**：FastDeploy推理加速，秒级响应医疗问诊\n",
    "5. **🕸️ 图结构推理**：从向量相似度到图关系路径的智能检索升级\n",
    "\n",
    "### 🛠️ 技术栈选择\n",
    "\n",
    "| 层级 | 技术组件 | 版本 | 作用 |\n",
    "|------|---------|------|------|\n",
    "| **AI模型层** | ERNIE-4.5-VL-28B-A3B-Paddle | 28B参数 | 多模态理解与生成 |\n",
    "| **推理框架** | FastDeploy | 最新版 | 模型部署与推理加速 |\n",
    "| **图数据库** | NetworkX | 3.4.2 | 图结构存储与查询 |\n",
    "| **知识图谱** | Pyvis | 0.3.2 | 交互式图谱可视化 |\n",
    "| **Web框架** | Gradio | 5.35.0 | 交互式用户界面 |\n",
    "| **Agent框架** | 自研多Agent系统 | - | 任务协调与业务逻辑 |\n",
    "| **数据处理** | Pillow + NumPy | 10.2.0 + 1.24.3 | 图像处理与数值计算 |\n",
    "\n",
    "## 🏥 智能医疗问诊系统实现\n",
    "\n",
    "### 核心功能模块\n",
    "\n",
    "#### 1. 图RAG知识图谱系统\n",
    "```python\n",
    "class GraphKnowledgeBase:\n",
    "    \"\"\"基于NetworkX的医疗知识图谱实现\"\"\"\n",
    "    \n",
    "    def __init__(self):\n",
    "        self.graph = nx.DiGraph()\n",
    "        # 支持7种实体类型和8种关系类型\n",
    "        \n",
    "    def query_related_entities(self, entity: str, relation: Optional[str] = None, max_hops: int = 1):\n",
    "        \"\"\"多跳关系查询，支持路径推理\"\"\"\n",
    "        # 实现从症状到疾病的多跳路径查询\n",
    "        # 支持CAUSES、TREATS、REQUIRES等关系类型\n",
    "```\n",
    "\n",
    "#### 2. 图结构知识检索\n",
    "```python\n",
    "class KnowledgeRetrievalAgent:\n",
    "    \"\"\"基于图结构的智能检索代理\"\"\"\n",
    "    \n",
    "    def retrieve_relevant_info(self, symptoms: List[str], max_hops: int = 2):\n",
    "        # 1. 从症状找到可能的疾病（多跳查询）\n",
    "        # 2. 获取疾病的详细信息（症状、治疗、检查等）\n",
    "        # 3. 查找症状之间的关联关系\n",
    "        # 4. 构建结构化的检索结果\n",
    "```\n",
    "\n",
    "#### 3. 知识图谱可视化\n",
    "```python\n",
    "class VisualizationAgent:\n",
    "    \"\"\"知识图谱可视化代理\"\"\"\n",
    "    \n",
    "    def visualize_knowledge_graph(self, entities: List[str] = None):\n",
    "        # 生成交互式HTML知识图谱\n",
    "        # 支持实体高亮和关系路径展示\n",
    "        # 基于Pyvis的现代化可视化界面\n",
    "```\n",
    "\n",
    "#### 4. 多模态输入处理\n",
    "```python\n",
    "class ErnieClient:\n",
    "    def medical_image_analysis(self, image_path: str) -> str:\n",
    "        \"\"\"医疗图像分析\"\"\"\n",
    "        # 支持皮肤病变、外伤等医疗图像分析\n",
    "        # 结合文本描述进行多模态理解\n",
    "```\n",
    "\n",
    "### 🎯 应用场景与效果\n",
    "\n",
    "#### 典型使用流程\n",
    "1. **用户输入**：描述症状 + 上传病变图片（可选）\n",
    "2. **多模态分析**：ERNIE-4.5-VL同时理解文本和图像\n",
    "3. **症状提取**：AI识别关键症状和医学术语\n",
    "4. **图结构检索**：从知识图谱中查询相关实体和关系路径\n",
    "5. **多跳推理**：基于图结构进行逻辑推理和关联分析\n",
    "6. **风险评估**：评估病情严重程度和就医紧急性\n",
    "7. **治疗建议**：生成个性化的检查、用药和生活建议\n",
    "8. **知识可视化**：展示相关的知识图谱片段\n",
    "\n",
    "#### 系统优势\n",
    "- **数据安全**：完全本地化部署，患者数据不出本地\n",
    "- **专业准确**：基于28B参数的专业医学模型\n",
    "- **响应快速**：本地推理，无网络延迟\n",
    "- **推理精准**：图结构查询比向量检索更精准\n",
    "- **可解释性强**：关系路径清晰，推理过程透明\n",
    "- **持续学习**：知识图谱可不断扩充和更新\n",
    "\n",
    "## 🧠 ERNIE-4.5-VL-28B-A3B-Paddle模型选择\n",
    "\n",
    "### 为什么选择ERNIE-4.5-VL-28B-A3B-Paddle？\n",
    "\n",
    "#### 文心开源模型的选择\n",
    "\n",
    "### ERNIE-4.5模型系列规格对比表\n",
    "\n",
    "| 模型系列 | 模型名称 | 总参数 | 激活参数 | 模态支持 | 上下文长度 | 主要用途 | 部署场景 |\n",
    "|---------|---------|--------|---------|---------|-----------|---------|---------|\n",
    "| **A47B大规模** | ERNIE-4.5-300B-A47B-Base | 300B | 47B | 文本 | 128K | 预训练基座 | 云端GPU集群 |\n",
    "| | ERNIE-4.5-300B-A47B | 300B | 47B | 文本 | 128K | 指令遵循/创意生成 | 云端GPU集群 |\n",
    "| | ERNIE-4.5-VL-424B-A47B-Base | 424B | 47B | 文本+视觉 | 128K | 多模态预训练 | 云端GPU集群 |\n",
    "| | ERNIE-4.5-VL-424B-A47B | 424B | 47B | 文本+视觉 | 128K | 图文理解/生成 | 云端GPU集群 |\n",
    "| **A3B中等规模** | ERNIE-4.5-21B-A3B-Base | 21B | 3B | 文本 | 128K | 预训练基座 | 单机多卡 |\n",
    "| | ERNIE-4.5-21B-A3B | 21B | 3B | 文本 | 128K | 对话/文档处理 | 单机多卡 |\n",
    "| | ERNIE-4.5-VL-28B-A3B-Base | 28B | 3B | 文本+视觉 | 128K | 多模态预训练 | 单机多卡 |\n",
    "| | ERNIE-4.5-VL-28B-A3B | 28B | 3B | 文本+视觉 | 128K | 轻量多模态应用 | 单机多卡 |\n",
    "| **0.3B轻量** | ERNIE-4.5-0.3B-Base | 0.3B | 0.3B | 文本 | 4K | 端侧预训练 | 移动端/边缘 |\n",
    "| | ERNIE-4.5-0.3B | 0.3B | 0.3B | 文本 | 4K | 实时对话 | 移动端/边缘 |\n",
    "\n",
    "### 模型规格选择策略表\n",
    "\n",
    "| 应用场景 | 推荐模型 | 理由 | 硬件要求 | 推理延迟 |\n",
    "|---------|---------|------|---------|---------|\n",
    "| **复杂推理任务** | ERNIE-4.5-300B-A47B | 最强推理能力 | 8×A100(80GB) | 高 |\n",
    "| **创意内容生成** | ERNIE-4.5-300B-A47B | 最佳创意表现 | 8×A100(80GB) | 高 |\n",
    "| **多模态理解** | ERNIE-4.5-VL-424B-A47B | 图文融合理解 | 8×A100(80GB) | 高 |\n",
    "| **日常对话客服** | ERNIE-4.5-21B-A3B | 性能成本平衡 | 4×V100(32GB) | 中 |\n",
    "| **文档信息抽取** | ERNIE-4.5-21B-A3B | 理解能力充足 | 4×V100(32GB) | 中 |\n",
    "| **轻量多模态** | ERNIE-4.5-VL-28B-A3B | 图文处理均衡 | 4×V100(32GB) | 中 |\n",
    "| **移动端应用** | ERNIE-4.5-0.3B | 低延迟快响应 | 1×GPU/CPU | 低 |\n",
    "| **边缘计算** | ERNIE-4.5-0.3B | 资源消耗最小 | CPU/NPU | 低 |\n",
    "\n",
    "### 为什么选择ERNIE-4.5-VL-28B-A3B-Paddle模型？\n",
    "\n",
    "#### 1. **性能与成本的最佳平衡**\n",
    "- **参数规模适中**：28B总参数，3B激活参数，在保证推理能力的同时控制了计算成本\n",
    "- **硬件要求合理**：支持单机多卡部署（4×V100或2×A100），相比A47B系列降低了75%的硬件门槛\n",
    "- **推理延迟适中**：在保证输出质量的前提下，响应速度比大规模模型快3-5倍\n",
    "\n",
    "#### 2. **多模态能力突出**\n",
    "- **文本+视觉融合**：原生支持图文理解，无需额外的视觉编码器\n",
    "- **长上下文支持**：128K token上下文长度，可处理长文档和多张图片\n",
    "- **应用场景丰富**：适合文档分析、图像描述、多模态问答等任务\n",
    "\n",
    "#### 3. **部署友好性**\n",
    "- **AIStudio平台优化**：官方深度适配，提供一键下载和部署\n",
    "- **FastDeploy集成**：完整的推理加速和服务化支持\n",
    "- **开源生态**：PaddlePaddle生态系统，文档完善，社区活跃\n",
    "\n",
    "#### 4. **实际应用价值**\n",
    "- **企业级可用**：相比0.3B模型，理解能力和生成质量显著提升\n",
    "- **成本可控**：相比A47B系列，部署成本降低70%，运营成本降低60%\n",
    "- **扩展性强**：支持LoRA微调，可针对特定场景进行优化\n",
    "\n",
    "#### 5. **技术先进性**\n",
    "- **MoE架构**：专家混合模型，激活参数仅为总参数的1/9，推理效率高\n",
    "- **多模态对齐**：视觉和文本特征深度融合，理解能力接近GPT-4V\n",
    "- **中文优化**：针对中文场景深度优化，在中文多模态任务上表现优异\n",
    "\n",
    "#### 选择建议\n",
    "**推荐场景**：\n",
    "- 中小企业多模态AI应用开发\n",
    "- 教育科研项目的多模态实验\n",
    "- 个人开发者的AI产品原型验证\n",
    "- 需要图文理解能力的业务系统\n",
    "\n",
    "**不推荐场景**：\n",
    "- 对推理延迟要求极高的实时系统（选择0.3B）\n",
    "- 预算充足且追求极致性能的场景（选择A47B）\n",
    "- 纯文本应用且对多模态无需求（选择21B-A3B）\n",
    "\n",
    "## 🚀 ERNIE-4.5-VL模型本地化部署方案\n",
    "\n",
    "### 一、环境准备\n",
    "### 1. 硬件要求\n",
    "- **GPU**：NVIDIA A100 80GB（支持单卡/多卡，推荐CUDA 11.8+）  \n",
    "- **内存**：≥60GB RAM  \n",
    "- **存储**：≥60GB（模型约28GB，需预留日志/缓存空间）  \n",
    "\n",
    "### 2. 软件依赖"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-08-23T13:24:45.188252Z",
     "iopub.status.busy": "2025-08-23T13:24:45.188008Z",
     "iopub.status.idle": "2025-08-23T13:24:46.308045Z",
     "shell.execute_reply": "2025-08-23T13:24:46.307381Z",
     "shell.execute_reply.started": "2025-08-23T13:24:45.188233Z"
    },
    "scrolled": true,
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Writing to /home/aistudio/.config/pip/pip.conf\r\n",
      "Writing to /home/aistudio/.config/pip/pip.conf\r\n",
      "Writing to /home/aistudio/.config/pip/pip.conf\r\n"
     ]
    }
   ],
   "source": [
    "!pip config set global.index-url http://mirrors.baidubce.com/pypi/simple/\n",
    "!pip config set global.extra-index-url http://mirrors.baidubce.com/pypi/simple/\n",
    "!pip config set install.trusted-host mirrors.baidubce.com"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "execution": {
     "iopub.execute_input": "2025-08-23T12:51:41.369422Z",
     "iopub.status.busy": "2025-08-23T12:51:41.369148Z"
    },
    "jupyter": {
     "outputs_hidden": false
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "%%capture\n",
    "!python -m pip install fastdeploy-gpu -i https://www.paddlepaddle.org.cn/packages/stable/fastdeploy-gpu-80_90/ --extra-index-url https://mirrors.tuna.tsinghua.edu.cn/pypi/web/simple"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. 环境验证\n",
    "#### ① 检查CUDA版本"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "nvcc: NVIDIA (R) Cuda compiler driver\r\n",
      "Copyright (c) 2005-2024 NVIDIA Corporation\r\n",
      "Built on Tue_Oct_29_23:50:19_PDT_2024\r\n",
      "Cuda compilation tools, release 12.6, V12.6.85\r\n",
      "Build cuda_12.6.r12.6/compiler.35059454_0\r\n"
     ]
    }
   ],
   "source": [
    "!nvcc --version\n",
    "# 预期输出示例："
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### ② 检查GPU信息"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tue Jul  8 01:25:28 2025       \r\n",
      "+-----------------------------------------------------------------------------------------+\r\n",
      "| NVIDIA-SMI 570.148.08             Driver Version: 570.148.08     CUDA Version: 12.8     |\r\n",
      "|-----------------------------------------+------------------------+----------------------+\r\n",
      "| GPU  Name                 Persistence-M | Bus-Id          Disp.A | Volatile Uncorr. ECC |\r\n",
      "| Fan  Temp   Perf          Pwr:Usage/Cap |           Memory-Usage | GPU-Util  Compute M. |\r\n",
      "|                                         |                        |               MIG M. |\r\n",
      "|=========================================+========================+======================|\r\n",
      "|   0  NVIDIA A800-SXM4-80GB          On  |   00000000:D3:00.0 Off |                    0 |\r\n",
      "| N/A   41C    P0             66W /  400W |       0MiB /  81920MiB |      0%      Default |\r\n",
      "|                                         |                        |             Disabled |\r\n",
      "+-----------------------------------------+------------------------+----------------------+\r\n",
      "                                                                                         \r\n",
      "+-----------------------------------------------------------------------------------------+\r\n",
      "| Processes:                                                                              |\r\n",
      "|  GPU   GI   CI              PID   Type   Process name                        GPU Memory |\r\n",
      "|        ID   ID                                                               Usage      |\r\n",
      "|=========================================================================================|\r\n",
      "|  No running processes found                                                             |\r\n",
      "+-----------------------------------------------------------------------------------------+\r\n"
     ]
    }
   ],
   "source": [
    "# 检查GPU状态和显存\n",
    "!nvidia-smi\n",
    "# 预期输出示例："
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### ③ 常见环境问题排查"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# 检查PaddlePaddle GPU支持\n",
    "!python -c \"import paddle; print('GPU可用:', paddle.is_compiled_with_cuda()); print('GPU设备数:', paddle.device.cuda.device_count())\"\n",
    "\n",
    "# 检查FastDeploy安装\n",
    "!python -c \"from fastdeploy import LLM, SamplingParams; print('FastDeploy安装成功！')\"\n",
    "\n",
    "# 检查OpenAI库版本\n",
    "!python -c \"import openai; print('OpenAI库版本:', openai.__version__)\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 二、模型下载与目录结构\n",
    "### 1. 下载模型文件"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "%%capture\n",
    "# 使用AIStudio命令下载模型\n",
    "!aistudio download --model PaddlePaddle/ERNIE-4.5-VL-28B-A3B-Paddle --local_dir /home/aistudio/work/models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "total 57441133\r\n",
      "-rw-r--r-- 1 aistudio aistudio      11366 Jul  6 18:57 LICENSE\r\n",
      "-rw-r--r-- 1 aistudio aistudio       9077 Jul  6 18:56 README.md\r\n",
      "-rw-r--r-- 1 aistudio aistudio      86904 Jul  6 18:56 added_tokens.json\r\n",
      "-rw-r--r-- 1 aistudio aistudio       1306 Jul  6 18:57 config.json\r\n",
      "-rw-r--r-- 1 aistudio aistudio        134 Jul  6 18:57 generation_config.json\r\n",
      "-rw-r--r-- 1 aistudio aistudio 4991326368 Jul  6 18:57 model-00001-of-00012.safetensors\r\n",
      "-rw-r--r-- 1 aistudio aistudio 4988696384 Jul  6 18:56 model-00002-of-00012.safetensors\r\n",
      "-rw-r--r-- 1 aistudio aistudio 4999185600 Jul  6 18:56 model-00003-of-00012.safetensors\r\n",
      "-rw-r--r-- 1 aistudio aistudio 4995268296 Jul  6 18:57 model-00004-of-00012.safetensors\r\n",
      "-rw-r--r-- 1 aistudio aistudio 4988696984 Jul  6 18:56 model-00005-of-00012.safetensors\r\n",
      "-rw-r--r-- 1 aistudio aistudio 4999193256 Jul  6 18:57 model-00006-of-00012.safetensors\r\n",
      "-rw-r--r-- 1 aistudio aistudio 4995261896 Jul  6 18:57 model-00007-of-00012.safetensors\r\n",
      "-rw-r--r-- 1 aistudio aistudio 4999183248 Jul  6 18:56 model-00008-of-00012.safetensors\r\n",
      "-rw-r--r-- 1 aistudio aistudio 4995271816 Jul  6 18:57 model-00009-of-00012.safetensors\r\n",
      "-rw-r--r-- 1 aistudio aistudio 4988696992 Jul  6 18:57 model-00010-of-00012.safetensors\r\n",
      "-rw-r--r-- 1 aistudio aistudio 4999190216 Jul  6 18:57 model-00011-of-00012.safetensors\r\n",
      "-rw-r--r-- 1 aistudio aistudio 3877260800 Jul  6 18:57 model-00012-of-00012.safetensors\r\n",
      "-rw-r--r-- 1 aistudio aistudio     691887 Jul  6 18:56 model.safetensors.index.json\r\n",
      "-rw-r--r-- 1 aistudio aistudio        615 Jul  6 18:56 preprocessor_config.json\r\n",
      "-rw-r--r-- 1 aistudio aistudio      62694 Jul  6 18:56 special_tokens_map.json\r\n",
      "-rw-r--r-- 1 aistudio aistudio    1614362 Jul  6 18:56 tokenizer.model\r\n",
      "-rw-r--r-- 1 aistudio aistudio       3606 Jul  6 18:56 tokenizer_config.json\r\n"
     ]
    }
   ],
   "source": [
    "# 查看模型文件\n",
    "!ls -l work/models"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. 目录结构\n",
    "```\n",
    "work/\n",
    "└── models/\n",
    "    ├── LICENSE                           # 许可证文件\n",
    "    ├── README.md                         # 模型说明文档\n",
    "    ├── added_tokens.json                 # 新增token配置\n",
    "    ├── config.json                       # 模型配置文件\n",
    "    ├── generation_config.json            # 生成配置文件\n",
    "    ├── model-00001-of-00012.safetensors  # 模型参数文件(分片1/12)\n",
    "    ├── model-00002-of-00012.safetensors  # 模型参数文件(分片2/12)\n",
    "    ├── model-00003-of-00012.safetensors  # 模型参数文件(分片3/12)\n",
    "    ├── model-00004-of-00012.safetensors  # 模型参数文件(分片4/12)\n",
    "    ├── model-00005-of-00012.safetensors  # 模型参数文件(分片5/12)\n",
    "    ├── model-00006-of-00012.safetensors  # 模型参数文件(分片6/12)\n",
    "    ├── model-00007-of-00012.safetensors  # 模型参数文件(分片7/12)\n",
    "    ├── model-00008-of-00012.safetensors  # 模型参数文件(分片8/12)\n",
    "    ├── model-00009-of-00012.safetensors  # 模型参数文件(分片9/12)\n",
    "    ├── model-00010-of-00012.safetensors  # 模型参数文件(分片10/12)\n",
    "    ├── model-00011-of-00012.safetensors  # 模型参数文件(分片11/12)\n",
    "    ├── model-00012-of-00012.safetensors  # 模型参数文件(分片12/12)\n",
    "    ├── model.safetensors.index.json      # 模型分片索引文件\n",
    "    ├── preprocessor_config.json          # 预处理器配置\n",
    "    ├── special_tokens_map.json           # 特殊token映射\n",
    "    ├── tokenizer.model                   # 分词器模型文件\n",
    "    └── tokenizer_config.json             # 分词器配置文件\n",
    "```\n",
    "\n",
    "### 3. 文件说明\n",
    "| 文件类型 | 文件名 | 说明 |\n",
    "|---------|--------|------|\n",
    "| **模型权重** | model-00001~00012-of-00012.safetensors | 模型参数分片文件，安全张量格式 |\n",
    "| **索引文件** | model.safetensors.index.json | 模型分片索引，指定每个参数在哪个分片中 |\n",
    "| **配置文件** | config.json | 模型架构配置，包含层数、隐藏层大小等 |\n",
    "| **生成配置** | generation_config.json | 文本生成相关配置，如最大长度、采样参数等 |\n",
    "| **分词器** | tokenizer.model | SentencePiece分词器模型 |\n",
    "| **分词器配置** | tokenizer_config.json | 分词器配置参数 |\n",
    "| **预处理器** | preprocessor_config.json | 图像预处理配置（多模态模型专用） |\n",
    "| **特殊token** | special_tokens_map.json | 特殊标记映射，如padding、unknown等 |\n",
    "| **新增token** | added_tokens.json | 用户自定义添加的token |\n",
    "\n",
    "## 三、启动服务（关键命令）"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/opt/conda/envs/python35-paddle120-env/lib/python3.10/site-packages/paddle/utils/cpp_extension/extension_utils.py:715: UserWarning: No ccache found. Please be aware that recompiling all source files may be required. You can download and install ccache from: https://github.com/ccache/ccache/blob/master/doc/INSTALL.md\r\n",
      "  warnings.warn(warning_message)\r\n",
      "/home/aistudio/external-libraries/lib/python3.10/site-packages/_distutils_hack/__init__.py:30: UserWarning: Setuptools is replacing distutils. Support for replacing an already imported distutils is deprecated. In the future, this condition will fail. Register concerns at https://github.com/pypa/setuptools/issues/new?template=distutils-deprecation.yml\r\n",
      "  warnings.warn(\r\n",
      "\u001b[32m[2025-07-06 18:57:55,035] [    INFO]\u001b[0m - loading configuration file work/models/preprocessor_config.json\u001b[0m\r\n",
      "INFO     2025-07-06 18:57:58,188 5574  engine.py[line:206] Waitting worker processes ready...\r\n",
      "Loading Weights: 100%|████████████████████████| 100/100 [01:17<00:00,  1.30it/s]\r\n",
      "Loading Layers: 100%|█████████████████████████| 100/100 [00:07<00:00, 13.31it/s]\r\n",
      "INFO     2025-07-06 18:59:35,857 5574  engine.py[line:276] Worker processes are launched with 119.6253821849823 seconds.\r\n",
      "INFO     2025-07-06 18:59:35,857 5574  api_server.py[line:91] Launching metrics service at http://0.0.0.0:8181/metrics\r\n",
      "INFO     2025-07-06 18:59:35,857 5574  api_server.py[line:94] Launching chat completion service at http://0.0.0.0:8180/v1/chat/completions\r\n",
      "INFO     2025-07-06 18:59:35,857 5574  api_server.py[line:97] Launching completion service at http://0.0.0.0:8180/v1/completions\r\n",
      "\u001b[32mINFO\u001b[0m:     Started server process [\u001b[36m5574\u001b[0m]\r\n",
      "\u001b[32mINFO\u001b[0m:     Waiting for application startup.\r\n",
      "\u001b[32m[2025-07-06 18:59:54,481] [    INFO]\u001b[0m - loading configuration file work/models/preprocessor_config.json\u001b[0m\r\n",
      "\u001b[32mINFO\u001b[0m:     Application startup complete.\r\n",
      "\u001b[32mINFO\u001b[0m:     Uvicorn running on \u001b[1mhttp://0.0.0.0:8180\u001b[0m (Press CTRL+C to quit)\r\n"
     ]
    }
   ],
   "source": [
    "python -m fastdeploy.entrypoints.openai.api_server \\\n",
    "       --model work/models \\\n",
    "       --port 8180 \\\n",
    "       --metrics-port 8181 \\\n",
    "       --engine-worker-queue-port 8182 \\\n",
    "       --max-model-len 32768 \\\n",
    "       --enable-mm \\\n",
    "       --reasoning-parser ernie-45-vl \\\n",
    "       --max-num-seqs 32"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 服务启动参数详细说明\n",
    "\n",
    "| 参数名称 | 参数说明 | 默认值 | 示例值 |\n",
    "|---------|---------|-------|-------|\n",
    "| `--model` | 模型文件路径，包含模型权重和配置文件的目录 | 必选 | `work/models` |\n",
    "| `--port` | API服务监听端口，客户端通过此端口访问服务 | 8000 | `8180` |\n",
    "| `--metrics-port` | 监控指标服务端口，用于性能监控和健康检查 | 8001 | `8181` |\n",
    "| `--engine-worker-queue-port` | 引擎工作队列端口，用于内部任务调度 | 8002 | `8182` |\n",
    "| `--max-model-len` | 模型最大支持的序列长度（token数） | 2048 | `32768` |\n",
    "| `--enable-mm` | 启用多模态功能（文本+图像处理） | False | `开启` |\n",
    "| `--reasoning-parser` | 推理解析器类型，指定模型的推理逻辑 | 无 | `ernie-45-vl` |\n",
    "| `--max-num-seqs` | 最大并发序列数，控制批处理大小 | 256 | `32` |\n",
    "\n",
    "### 其他常用参数\n",
    "\n",
    "| 参数名称 | 参数说明 | 默认值 | 备注 |\n",
    "|---------|---------|-------|------|\n",
    "| `--host` | 服务绑定的主机地址 | 0.0.0.0 | 设置为0.0.0.0允许外部访问 |\n",
    "| `--trust-remote-code` | 信任远程代码执行 | False | 加载自定义模型时需要 |\n",
    "| `--tensor-parallel-size` | 张量并行大小（多GPU） | 1 | 根据GPU数量设置 |\n",
    "| `--gpu-memory-utilization` | GPU内存利用率 | 0.9 | 建议0.8-0.95之间 |\n",
    "| `--max-num-batched-tokens` | 最大批处理token数 | 自动计算 | 根据GPU显存调整 |\n",
    "| `--swap-space` | 交换空间大小(GB) | 4 | 内存不足时使用 |\n",
    "| `--enable-lora` | 启用LoRA适配器 | False | 微调模型时使用 |\n",
    "| `--max-log-len` | 最大日志长度 | 无限制 | 控制日志文件大小 |\n",
    "\n",
    "### 服务验证\n",
    "```bash\n",
    "# 检查模型是否正常加载\n",
    "curl http://localhost:8180/v1/models\n",
    "\n",
    "# 预期输出（包含模型ID）\n",
    "{\"data\":[{\"id\":\"ernie-4.5-vl-28b-a3b-paddle\",\"object\":\"model\"}]}\n",
    "```\n",
    "\n",
    "## 四、模型调用示例\n",
    "\n",
    "### 1. OpenAI库调用方式\n",
    "\n",
    "#### ① 文本生成\n",
    "```python\n",
    "import openai\n",
    "\n",
    "host = \"0.0.0.0\"\n",
    "port = \"8180\"\n",
    "client = openai.Client(base_url=f\"http://{host}:{port}/v1\", api_key=\"null\")\n",
    "\n",
    "response = client.chat.completions.create(\n",
    "    model=\"null\",\n",
    "    messages=[\n",
    "        {\"role\": \"user\", \"content\": \"你是Aistudio和文心大模型开发的智能助手，请介绍一下你自己.\"}\n",
    "    ],\n",
    "    stream=True,\n",
    ")\n",
    "\n",
    "for chunk in response:\n",
    "    if chunk.choices[0].delta:\n",
    "        print(chunk.choices[0].delta.content, end='')\n",
    "```\n",
    "\n",
    "#### ② 图像描述生成\n",
    "```python\n",
    "import openai\n",
    "import base64\n",
    "\n",
    "def encode_image(image_path):\n",
    "    with open(image_path, \"rb\") as image_file:\n",
    "        return base64.b64encode(image_file.read()).decode('utf-8')\n",
    "\n",
    "client = openai.Client(\n",
    "    base_url=\"http://0.0.0.0:8180/v1\",\n",
    "    api_key=\"null\"\n",
    ")\n",
    "\n",
    "response = client.chat.completions.create(\n",
    "    model=\"null\",\n",
    "    messages=[\n",
    "        {\n",
    "            \"role\": \"user\",\n",
    "            \"content\": [\n",
    "                {\n",
    "                    \"type\": \"image_url\",\n",
    "                    \"image_url\": {\n",
    "                        \"url\": f\"data:image/jpeg;base64,{encode_image('1.jpg')}\"\n",
    "                    }\n",
    "                },\n",
    "                {\n",
    "                    \"type\": \"text\",\n",
    "                    \"text\": \"生成这张图片的描述\"\n",
    "                }\n",
    "            ]\n",
    "        }\n",
    "    ],\n",
    "    stream=True,\n",
    ")\n",
    "\n",
    "print(\"图片描述：\", end='', flush=True)\n",
    "for chunk in response:\n",
    "    if chunk.choices and chunk.choices[0].delta.content:\n",
    "        print(chunk.choices[0].delta.content, end='', flush=True)\n",
    "print()\n",
    "```\n",
    "\n",
    "### 2. requests库调用方式\n",
    "\n",
    "#### ① 文本生成\n",
    "```python\n",
    "import requests\n",
    "import json\n",
    "\n",
    "url = \"http://localhost:8180/v1/chat/completions\"\n",
    "headers = {\"Content-Type\": \"application/json\"}\n",
    "payload = {\n",
    "    \"model\": \"null\",\n",
    "    \"messages\": [\n",
    "        {\"role\": \"user\", \"content\": \"你是Aistudio和文心大模型开发的智能助手，请介绍一下你自己.\"}\n",
    "    ],\n",
    "    \"stream\": True\n",
    "}\n",
    "\n",
    "response = requests.post(url, headers=headers, json=payload, stream=True)\n",
    "\n",
    "for line in response.iter_lines():\n",
    "    if line:\n",
    "        line = line.decode('utf-8').replace('data: ', '')\n",
    "        \n",
    "        if line.strip() == '[DONE]':\n",
    "            continue\n",
    "        try:\n",
    "            data = json.loads(line)\n",
    "            \n",
    "            if 'choices' in data and len(data['choices']) > 0:\n",
    "                delta = data['choices'][0].get('delta', {})\n",
    "                content = delta.get('content', '')\n",
    "                if content:\n",
    "                    print(content, end='', flush=True)\n",
    "        except json.JSONDecodeError as e:\n",
    "            print(f\"Error decoding line: {line}\")\n",
    "            print(f\"Error: {e}\")\n",
    "\n",
    "print()\n",
    "```\n",
    "\n",
    "#### ② 图像描述生成\n",
    "```python\n",
    "import requests\n",
    "import json\n",
    "import base64\n",
    "\n",
    "def encode_image(image_path):\n",
    "    with open(image_path, \"rb\") as image_file:\n",
    "        return base64.b64encode(image_file.read()).decode('utf-8')\n",
    "\n",
    "url = \"http://localhost:8180/v1/chat/completions\"\n",
    "headers = {\"Content-Type\": \"application/json\"}\n",
    "payload = {\n",
    "    \"model\": \"null\",\n",
    "    \"messages\": [\n",
    "        {\n",
    "            \"role\": \"user\",\n",
    "            \"content\": [\n",
    "                {\"type\": \"image_url\", \"image_url\": {\"url\": f\"data:image/jpeg;base64,{encode_image('1.jpg')}\"}},\n",
    "                {\"type\": \"text\", \"text\": \"生成图片描述\"}\n",
    "            ]\n",
    "        }\n",
    "    ],\n",
    "    \"stream\": True\n",
    "}\n",
    "\n",
    "response = requests.post(url, headers=headers, json=payload, stream=True)\n",
    "\n",
    "for line in response.iter_lines():\n",
    "    if line:\n",
    "        line = line.decode('utf-8').replace('data: ', '')\n",
    "        \n",
    "        if line.strip() == '[DONE]':\n",
    "            continue\n",
    "        try:\n",
    "            data = json.loads(line)\n",
    "            \n",
    "            if 'choices' in data and len(data['choices']) > 0:\n",
    "                delta = data['choices'][0].get('delta', {})\n",
    "                content = delta.get('content', '')\n",
    "                if content:\n",
    "                    print(content, end='', flush=True)\n",
    "        except json.JSONDecodeError as e:\n",
    "            print(f\"Error decoding line: {line}\")\n",
    "            print(f\"Error: {e}\")\n",
    "\n",
    "print()\n",
    "```\n",
    "\n",
    "### 3. 调用参数说明\n",
    "\n",
    "#### 常用参数配置\n",
    "```python\n",
    "# 完整的调用参数示例\n",
    "response = client.chat.completions.create(\n",
    "    model=\"null\",                    # 模型名称（固定值）\n",
    "    messages=[...],                  # 消息列表\n",
    "    stream=True,                     # 是否启用流式响应\n",
    "    max_tokens=2048,                 # 最大生成token数\n",
    "    temperature=0.7,                 # 温度参数(0.0-2.0)\n",
    "    top_p=0.9,                      # 核采样参数(0.0-1.0)\n",
    "    frequency_penalty=0.0,           # 频率惩罚(-2.0-2.0)\n",
    "    presence_penalty=0.0,            # 存在惩罚(-2.0-2.0)\n",
    "    stop=[\"<|endoftext|>\"],         # 停止词列表\n",
    ")\n",
    "```\n",
    "\n",
    "#### 参数详细说明\n",
    "| 参数名称 | 类型 | 默认值 | 说明 |\n",
    "|---------|------|--------|------|\n",
    "| `model` | str | \"null\" | 模型名称，本地部署时固定为\"null\" |\n",
    "| `messages` | list | 必选 | 对话消息列表，包含role和content |\n",
    "| `stream` | bool | False | 是否启用流式响应 |\n",
    "| `max_tokens` | int | 自动 | 最大生成token数量 |\n",
    "| `temperature` | float | 1.0 | 控制随机性，值越高越随机 |\n",
    "| `top_p` | float | 1.0 | 核采样，控制词汇选择范围 |\n",
    "| `frequency_penalty` | float | 0.0 | 频率惩罚，减少重复内容 |\n",
    "| `presence_penalty` | float | 0.0 | 存在惩罚，鼓励谈论新话题 |\n",
    "| `stop` | list | None | 停止生成的字符串列表 |\n",
    "\n",
    "## 五、常见问题与解决方案\n",
    "### 1. 端口占用问题\n",
    "```bash\n",
    "# 查看端口占用进程\n",
    "lsof -i:8180\n",
    "\n",
    "# 终止进程（替换<PID>为实际进程号）\n",
    "kill -9 <PID>\n",
    "```\n",
    "\n",
    "### 2. 模型加载失败\n",
    "- **检查目录**：确认`work/models`下存在完整的模型文件（.pdparams/config.json/vocab.txt）  \n",
    "- **解析器参数**：确保启动命令包含`--reasoning-parser ernie-45-vl`  \n",
    "- **驱动版本**：NVIDIA驱动需≥520.61.05（支持A100）  \n",
    "\n",
    "### 3. 流式响应异常\n",
    "- 确保`stream=True`参数正确传递  \n",
    "- 检查服务日志（`fastdeploy_server.log`）是否有内存/显存不足报错  \n",
    "\n",
    "\n",
    "## 六、测试用例\n",
    "### 1. 文本生成验证\n",
    "- **输入**：`\"总结本教程的核心步骤\"`  \n",
    "- **预期**：输出包含\"环境配置\"、\"服务启动\"、\"接口调用\"等关键词的连贯文本  \n",
    "\n",
    "### 2. 图像描述验证\n",
    "- **测试图片**：使用包含自然场景的jpg文件（如山水、人物活动）  \n",
    "- **预期**：输出包含景物特征（如\"蓝天白云下的绿色草原\"）、动作描述（如\"人物正在湖边散步\"）的语句  \n",
    "\n",
    "## 七、智能医疗问诊系统部署\n",
    "\n",
    "### 1. 系统依赖安装\n",
    "```bash\n",
    "# 更新依赖包版本\n",
    "pip install networkx pyvis python-dotenv scikit-learn\n",
    "```\n",
    "\n",
    "### 2. 医学知识库初始化\n",
    "```bash\n",
    "# 初始化医学知识图谱\n",
    "python init_knowledge_base.py\n",
    "```\n",
    "\n",
    "### 3. 启动完整系统\n",
    "```bash\n",
    "# 第一步：启动ERNIE-4.5-VL模型服务\n",
    "python -m fastdeploy.entrypoints.openai.api_server \\\n",
    "       --model work/models \\\n",
    "       --port 8180 \\\n",
    "       --enable-mm \\\n",
    "       --reasoning-parser ernie-45-vl\n",
    "\n",
    "# 第二步：启动医疗问诊Web界面  \n",
    "python main.gradio.py\n",
    "```\n",
    "\n",
    "## 🧠 图RAG知识图谱系统\n",
    "\n",
    "### 实体类型定义\n",
    "```python\n",
    "ENTITY_TYPES = {\n",
    "    \"Symptom\": \"症状（如发热、咳嗽、头痛等）\",\n",
    "    \"Disease\": \"疾病（如感冒、流感、肺炎等）\",\n",
    "    \"Treatment\": \"治疗方法（如药物、手术、理疗等）\",\n",
    "    \"Examination\": \"检查项目（如血常规、CT、X光等）\",\n",
    "    \"BodyPart\": \"身体部位（如肺部、心脏、喉咙等）\",\n",
    "    \"Medication\": \"药物（如阿司匹林、布洛芬等）\",\n",
    "    \"RiskFactor\": \"风险因素（如吸烟、肥胖等）\"\n",
    "}\n",
    "```\n",
    "\n",
    "### 关系类型定义\n",
    "```python\n",
    "RELATION_TYPES = {\n",
    "    \"CAUSES\": \"导致（疾病→症状，风险因素→疾病）\",\n",
    "    \"TREATS\": \"治疗（治疗方法→疾病，药物→疾病/症状）\",\n",
    "    \"REQUIRES\": \"需要（疾病→检查项目）\",\n",
    "    \"AFFECTS\": \"影响（疾病→身体部位）\",\n",
    "    \"ACCOMPANIES\": \"伴随（症状→症状）\",\n",
    "    \"DIAGNOSES\": \"诊断（检查项目→疾病）\",\n",
    "    \"PREVENTS\": \"预防（措施→疾病）\",\n",
    "    \"HAS_SYMPTOM\": \"有症状（疾病→症状）\"\n",
    "}\n",
    "```\n",
    "\n",
    "### 图结构查询示例\n",
    "```python\n",
    "# 多跳关系查询：从症状找到相关疾病\n",
    "symptoms = [\"发热\", \"咳嗽\"]\n",
    "for symptom in symptoms:\n",
    "    # 查询与症状相关的疾病（1跳）\n",
    "    disease_relations = graph_kb.query_related_entities(\n",
    "        symptom, relation=\"CAUSES\", max_hops=1\n",
    "    )\n",
    "    \n",
    "    # 查询疾病的治疗方法和检查项目（2跳）\n",
    "    for _, _, disease, _ in disease_relations:\n",
    "        treatments = graph_kb.query_related_entities(\n",
    "            disease, relation=\"TREATS\", max_hops=1\n",
    "        )\n",
    "        examinations = graph_kb.query_related_entities(\n",
    "            disease, relation=\"REQUIRES\", max_hops=1\n",
    "        )\n",
    "```\n",
    "\n",
    "## 八、功能展示与效果\n",
    "\n",
    "### 🖼️ 系统界面\n",
    "![智能医疗问诊系统主界面](https://ai-studio-static-online.cdn.bcebos.com/965e6e76d9734871be2d5b6d4d3771a690c94915d90142ab9af92059c94056ec)\n",
    "![智能医疗问诊系统主界面](https://ai-studio-static-online.cdn.bcebos.com/3a35c11096814ba29c86112dd48b7a9059d1e3f4068f4170b07d5541979f4fe7)\n",
    "\n",
    "\n",
    "### 📋 诊断报告示例\n",
    "![多模态问诊结果](https://ai-studio-static-online.cdn.bcebos.com/13d99d00f80a4fc6a03f4f6ab0677e91e4ea1ee14c53468d9e23da95c584d888)\n",
    "![多模态问诊结果](https://ai-studio-static-online.cdn.bcebos.com/ee9cd328c49f4fed900ad81c76c522e48521cd3c90fc47bdac42f40cf4765184)\n",
    "![多模态问诊结果](https://ai-studio-static-online.cdn.bcebos.com/9b033e3d967b476fb8f2a0e7c9e19c9cabd1117ac9664b64a7c69ca60d4ac65e)\n",
    "\n",
    "### 🖼️ 知识图谱\n",
    "![](https://ai-studio-static-online.cdn.bcebos.com/59ad6739ee32412c9915cc20894b0d62128bf5b6885e4f018d942156c5f83de8)\n",
    "![](https://ai-studio-static-online.cdn.bcebos.com/d3f8db5972704bfba8314a85fd87e61eabf0bad5f43a4fd1adbb76b6c4d6883d)\n",
    "![](https://ai-studio-static-online.cdn.bcebos.com/736916078d3142b38fd65ce7dfbbfc5b505480f4a0bb48c2a10d5fe54bdf0e08)\n",
    "![](https://ai-studio-static-online.cdn.bcebos.com/96e2a927d8f24b9b956df6403ae392ce18609bae579a4bf1b1a729862d85d5da)\n",
    "\n",
    "### 💊 治疗建议输出格式\n",
    "\n",
    "\n",
    "## 九、技术创新点\n",
    "\n",
    "### 🔬 核心技术优势\n",
    "\n",
    "#### 1. 本地化多模态大模型\n",
    "- **模型规模**：28B参数，3B激活参数的高效MoE架构\n",
    "- **多模态能力**：原生支持文本+图像的联合理解\n",
    "- **部署优化**：FastDeploy框架，单机多卡高效推理\n",
    "- **数据安全**：完全本地化，患者隐私零泄露\n",
    "\n",
    "#### 2. RAG增强知识系统\n",
    "- **向量化存储**：ChromaDB构建的高效语义检索\n",
    "- **分层知识库**：症状、疾病、治疗方案的结构化管理\n",
    "- **实时检索**：毫秒级的相似度匹配和知识召回\n",
    "- **动态更新**：支持知识库的增量更新和扩展\n",
    "\n",
    "#### 3. 多Agent协同架构\n",
    "- **模块化设计**：每个Agent负责特定的医疗任务\n",
    "- **智能编排**：AgentCoordinator统一调度和数据流管理\n",
    "- **容错机制**：单个Agent失败不影响整体系统运行\n",
    "- **可扩展性**：新增医疗专科Agent即插即用\n",
    "\n",
    "#### 4. 用户体验优化\n",
    "- **流式响应**：实时显示AI分析过程，提升交互体验\n",
    "- **多端适配**：Web界面支持PC和移动端访问\n",
    "- **结果可视化**：结构化医疗报告，易于理解和保存\n",
    "- **操作便捷**：拖拽上传图片，文本框快速输入\n",
    "\n",
    "## 十、应用价值与场景\n",
    "\n",
    "### 🏥 医疗场景应用\n",
    "\n",
    "#### 基层医疗机构\n",
    "- **初步问诊**：协助全科医生进行症状分析\n",
    "- **分诊辅助**：评估患者病情紧急程度  \n",
    "- **知识支持**：为医生提供疾病诊疗参考\n",
    "\n",
    "#### 远程医疗服务\n",
    "- **在线咨询**：24小时智能医疗咨询服务\n",
    "- **图像诊断**：皮肤病、外伤等可视化疾病分析\n",
    "- **健康教育**：提供专业的健康管理建议\n",
    "\n",
    "#### 个人健康管理\n",
    "- **症状自查**：用户自主进行健康状况评估\n",
    "- **就医指导**：提供科学的就医建议和科室推荐\n",
    "- **用药咨询**：基于症状的安全用药指导\n",
    "\n",
    "### 💡 技术价值\n",
    "\n",
    "#### 行业推动\n",
    "- **AI医疗标准化**：多模态医疗AI的技术范式\n",
    "- **本地化部署**：为医疗数据安全提供解决方案\n",
    "- **开源生态**：基于PaddlePaddle的完整技术栈\n",
    "\n",
    "#### 创新突破\n",
    "- **多模态融合**：图文一体化的医疗理解能力\n",
    "- **知识库驱动**：RAG技术在医疗领域的深度应用\n",
    "- **Agent协同**：专业化AI系统的协作机制\n",
    "\n",
    "## 十一、系统监控与维护\n",
    "\n",
    "### 📊 性能监控\n",
    "```bash\n",
    "# 查看模型服务状态\n",
    "curl http://localhost:8180/v1/models\n",
    "\n",
    "# 监控系统资源使用\n",
    "nvidia-smi  # GPU使用情况\n",
    "top         # CPU和内存使用\n",
    "\n",
    "# 查看服务日志\n",
    "tail -f logs/gradio_app_*.log\n",
    "```\n",
    "\n",
    "### 📞 联系方式\n",
    "- **项目作者**：Wechat: X_ruilian"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-07-06 21:47:22,130 - INFO - HTTP Request: POST http://0.0.0.0:8180/v1/chat/completions \"HTTP/1.1 200 OK\"\r\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\r\n",
      "\r\n",
      "我是由 **Aistudio**（百度开源的AI开发平台）与 **文心大模型** 技术框架共同赋能的智能助手。以下是我的核心特点与功能介绍：\r\n",
      "\r\n",
      "### 1. **技术背景**\r\n",
      "   - 基于百度自主研发的 **文心大模型** 基础能力，融合多模态理解与生成技术，具备强大的自然语言处理能力。\r\n",
      "   - 依托Aistudio的开源生态，支持开发者协作与模型迭代优化。\r\n",
      "\r\n",
      "### 2. **核心能力**\r\n",
      "   - **知识问答**：覆盖广泛领域（科技、文化、生活等），提供准确、简洁的解答。\r\n",
      "   - **文本生成**：可撰写文章、代码、诗歌、对话等，支持创意与实用场景。\r\n",
      "   - **逻辑推理**：分析复杂问题，提供结构化思考路径。\r\n",
      "   - **多语言支持**：中文为主，兼顾英文等语言交互。\r\n",
      "\r\n",
      "### 3. **应用场景**\r\n",
      "   - **学习辅助**：解答学科问题、生成学习笔记或模拟对话。\r\n",
      "   - **内容创作**：辅助写作、脚本生成、营销文案策划等。\r\n",
      "   - **日常助手**：提供生活建议、时间规划、趣味互动。\r\n",
      "   - **技术协作**：与开发者对接，优化代码逻辑或模型训练方案。\r\n",
      "\r\n",
      "### 4. **优势特点**\r\n",
      "   - **持续学习**：通过用户反馈与数据更新，保持知识时效性。\r\n",
      "   - **安全可控**：遵循伦理规范，避免生成有害内容。\r\n",
      "   - **灵活交互**：支持自由对话或指定任务（如“写一首关于春天的诗”）。\r\n",
      "\r\n",
      "### 5. **如何使用**\r\n",
      "   - 直接通过对话输入需求，或指定任务目标（如“生成Python爬虫代码”）。\r\n",
      "   - 结合Aistudio平台，可参与模型训练、部署或开源项目协作。\r\n",
      "\r\n",
      "期待通过我的能力，为您的学习、工作或生活提供高效支持！ 😊"
     ]
    }
   ],
   "source": [
    "import openai\n",
    "host = \"0.0.0.0\"\n",
    "port = \"8180\"\n",
    "client = openai.Client(base_url=f\"http://{host}:{port}/v1\", api_key=\"null\")\n",
    "\n",
    "response = client.chat.completions.create(\n",
    "    model=\"null\",\n",
    "    messages=[\n",
    "        {\"role\": \"user\", \"content\": \"你是Aistudio和文心大模型开发的智能助手，请介绍一下你自己.\"}\n",
    "    ],\n",
    "    stream=True,\n",
    ")\n",
    "for chunk in response:\n",
    "    if chunk.choices[0].delta:\n",
    "        print(chunk.choices[0].delta.content, end='')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "图片描述：\r\n",
      "这张图片展示了飞桨自然语言处理开发库（PaddleNLP）的核心架构和功能模块，整体设计简洁清晰，采用蓝白配色，突出科技感。图片分为三个主要部分：\r\n",
      "\r\n",
      "### 1. **工业级预置任务（Taskflow）**\r\n",
      "   - **自然语言理解**：包含词法分析、文本纠错、情感分析、句法分析，覆盖文本基础处理与语义理解任务。\r\n",
      "   - **自然语言生成**：支持自动对联、智能写诗、生成式问答、开放域对话，体现NLP在创意性任务中的应用。\r\n",
      "\r\n",
      "### 2. **产业级模型库**\r\n",
      "   - **自研预训练模型**：列举了多个ERNIE系列模型（如ERNIE-1.0、ERNIE-2.0、ERNIE-Tiny等）及PLATO-2、SKEP等模型，体现飞桨在预训练模型领域的多样性。\r\n",
      "   - **覆盖全场景应用**：涵盖文本分类、匹配、生成、语义索引、小样本学习、文本图学习、信息抽取、翻译、知识关联、模型压缩等场景，展示模型库的广泛适用性。\r\n",
      "\r\n",
      "### 3. **文本领域核心API**\r\n",
      "   - 提供基础工具模块，包括数据管理（Data/Datasets）、嵌入（Embedding）、Transformer框架、序列到向量（Seq2Vec）、评估指标（Metrics）和损失函数（Losses），为开发者提供灵活的开发接口。\r\n",
      "\r\n",
      "### 底部标识\r\n",
      "   - 底部飞桨（PaddlePaddle）标志强化品牌一致性，体现飞桨作为开源深度学习平台的整体生态。\r\n",
      "\r\n",
      "**核心价值**：PaddleNLP通过预置任务、预训练模型和核心API，构建了从基础工具到行业应用的完整NLP解决方案，兼顾效率与灵活性，适合开发者快速落地自然语言处理项目。\r\n"
     ]
    }
   ],
   "source": [
    "import openai\n",
    "import base64\n",
    "\n",
    "def encode_image(image_path):\n",
    "    with open(image_path, \"rb\") as image_file:\n",
    "        return base64.b64encode(image_file.read()).decode('utf-8')\n",
    "\n",
    "client = openai.Client(\n",
    "    base_url=\"http://0.0.0.0:8180/v1\",\n",
    "    api_key=\"null\"\n",
    ")\n",
    "\n",
    "response = client.chat.completions.create(\n",
    "    model=\"null\",\n",
    "    messages=[\n",
    "        {\n",
    "            \"role\": \"user\",\n",
    "            \"content\": [\n",
    "                {\n",
    "                    \"type\": \"image_url\",\n",
    "                    \"image_url\": {\n",
    "                        \"url\": f\"data:image/jpeg;base64,{encode_image('1.jpg')}\"\n",
    "                    }\n",
    "                },\n",
    "                {\n",
    "                    \"type\": \"text\",\n",
    "                    \"text\": \"生成这张图片的描述\"\n",
    "                }\n",
    "            ]\n",
    "        }\n",
    "    ],\n",
    "    stream=True,\n",
    ")\n",
    "\n",
    "print(\"图片描述：\", end='', flush=True)\n",
    "for chunk in response:\n",
    "    if chunk.choices and chunk.choices[0].delta.content:\n",
    "        print(chunk.choices[0].delta.content, end='', flush=True)\n",
    "print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "%%capture\n",
    "!pip install networkx pyvis python-dotenv scikit-learn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false,
    "execution": {
     "iopub.execute_input": "2025-08-23T18:59:20.940536Z",
     "iopub.status.busy": "2025-08-23T18:59:20.940111Z",
     "iopub.status.idle": "2025-08-23T19:00:39.226967Z",
     "shell.execute_reply": "2025-08-23T19:00:39.226383Z",
     "shell.execute_reply.started": "2025-08-23T18:59:20.940512Z"
    },
    "jupyter": {
     "outputs_hidden": false
    },
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "成功连接到本地模型服务，将抽取皮疹相关文本的实体关系\r\n",
      "加载了 4 条医疗文本数据（含5条皮疹相关疾病文本）\r\n",
      "处理文本 1/4...\r\n",
      "处理文本 2/4...\r\n",
      "处理文本 3/4...\r\n",
      "处理文本 4/4...\r\n",
      "添加手动关系后（含皮疹）：实体数 89, 关系数 84\r\n",
      "知识图谱已保存到 medical_kb.pkl\r\n",
      "知识图谱可视化已保存到 medical_knowledge_graph.html\r\n"
     ]
    }
   ],
   "source": [
    "!python init_knowledge_base.py"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 新手操作指南\n",
    "\n",
    "\n",
    "## 一、环境准备\n",
    "### 1. 硬件要求\n",
    "- **GPU**：NVIDIA A100 80GB（支持单卡/多卡，推荐CUDA 11.8+）\n",
    "- **内存**：≥60GB RAM\n",
    "- **存储**：≥60GB（模型约28GB，需预留日志/缓存空间）\n",
    "\n",
    "\n",
    "### 2. 软件依赖安装\n",
    "```bash\n",
    "# 安装FastDeploy推理框架（GPU版）\n",
    "python -m pip install fastdeploy-gpu -i https://www.paddlepaddle.org.cn/packages/stable/fastdeploy-gpu-80_90/ --extra-index-url https://mirrors.tuna.tsinghua.edu.cn/pypi/web/simple\n",
    "```\n",
    "\n",
    "\n",
    "### 3. 环境验证\n",
    "```bash\n",
    "# 检查CUDA版本（需≥11.8）\n",
    "nvcc --version\n",
    "\n",
    "# 检查GPU状态和显存\n",
    "nvidia-smi\n",
    "\n",
    "# 验证PaddlePaddle GPU支持\n",
    "python -c \"import paddle; print('GPU可用:', paddle.is_compiled_with_cuda()); print('GPU设备数:', paddle.device.cuda.device_count())\"\n",
    "\n",
    "# 验证FastDeploy安装\n",
    "python -c \"from fastdeploy import LLM, SamplingParams; print('FastDeploy安装成功！')\"\n",
    "```\n",
    "\n",
    "\n",
    "## 二、模型下载\n",
    "```bash\n",
    "# 使用AIStudio命令下载模型至指定目录\n",
    "aistudio download --model PaddlePaddle/ERNIE-4.5-VL-28B-A3B-Paddle --local_dir /home/aistudio/work/models\n",
    "\n",
    "# 查看模型文件（确认12个分片及配置文件完整）\n",
    "ls -l work/models\n",
    "```\n",
    "\n",
    "模型目录结构说明：包含模型参数分片（model-00001~00012.safetensors）、配置文件（config.json）、分词器文件（tokenizer.model）等。\n",
    "\n",
    "\n",
    "## 三、启动模型服务\n",
    "### 1. 核心启动命令\n",
    "```bash\n",
    "python -m fastdeploy.entrypoints.openai.api_server \\\n",
    "       --model work/models \\  # 模型文件路径\n",
    "       --port 8180 \\  # API服务端口\n",
    "       --metrics-port 8181 \\  # 监控指标端口\n",
    "       --engine-worker-queue-port 8182 \\  # 内部任务调度端口\n",
    "       --max-model-len 32768 \\  # 最大序列长度（token数）\n",
    "       --enable-mm \\  # 启用多模态功能（文本+图像）\n",
    "       --reasoning-parser ernie-45-vl \\  # 指定推理解析器\n",
    "       --max-num-seqs 32  # 最大并发序列数\n",
    "```\n",
    "\n",
    "\n",
    "### 2. 服务验证\n",
    "```bash\n",
    "# 检查模型是否正常加载\n",
    "curl http://localhost:8180/v1/models\n",
    "\n",
    "# 预期输出（包含模型ID）\n",
    "{\"data\":[{\"id\":\"ernie-4.5-vl-28b-a3b-paddle\",\"object\":\"model\"}]}\n",
    "```\n",
    "\n",
    "\n",
    "## 四、系统初始化\n",
    "### 1. 安装系统依赖\n",
    "```bash\n",
    "# 安装项目所需依赖包\n",
    "pip install networkx pyvis python-dotenv scikit-learn\n",
    "```\n",
    "\n",
    "\n",
    "### 2. 初始化医学知识图谱\n",
    "```bash\n",
    "python init_knowledge_base.py\n",
    "```\n",
    "\n",
    "\n",
    "## 五、启动完整问诊系统\n",
    "### 1. 启动流程\n",
    "```bash\n",
    "# 第一步：启动ERNIE-4.5-VL模型服务（已在第三步执行）\n",
    "# 第二步：启动Gradio Web界面\n",
    "python main.gradio.py\n",
    "```\n",
    "\n",
    "## 六、使用流程\n",
    "1. **用户输入**：通过Gradio界面输入症状描述（如“身上红点越来越多”），可选上传病变图片（支持皮肤病变等图像）。\n",
    "2. **发起问诊**：点击“开始问诊”按钮。\n",
    "3. **系统处理**：\n",
    "   - 多模态分析（文本+图像联合理解）；\n",
    "   - 症状提取（识别关键症状如“红色斑点、散在分布”）；\n",
    "   - 知识库检索（匹配相关疾病与治疗方案）；\n",
    "   - 生成诊断报告（含风险评估、检查建议、用药建议等）。\n",
    "4. **查看结果**：界面展示结构化诊断报告，包含图像分析、症状分析、治疗建议等内容。\n",
    "\n",
    "\n",
    "## 七、常见问题与解决方案\n",
    "### 1. 端口占用\n",
    "```bash\n",
    "# 查看端口8180占用进程\n",
    "lsof -i:8180\n",
    "\n",
    "# 终止进程（替换<PID>为实际进程号）\n",
    "kill -9 <PID>\n",
    "```\n",
    "\n",
    "\n",
    "### 2. 模型加载失败\n",
    "- 检查`work/models`目录下模型文件是否完整（12个分片及配置文件）；\n",
    "- 确认启动命令包含`--reasoning-parser ernie-45-vl`；\n",
    "- 验证NVIDIA驱动版本≥520.61.05（支持A100）。\n",
    "\n",
    "\n",
    "### 3. 流式响应异常\n",
    "- 确保调用时`stream=True`参数正确传递；\n",
    "- 检查服务日志（`fastdeploy_server.log`）是否存在内存/显存不足报错。\n",
    "\n",
    "\n",
    "## 八、监控与维护\n",
    "```bash\n",
    "# 查看模型服务状态\n",
    "curl http://localhost:8180/v1/models\n",
    "\n",
    "# 监控GPU使用情况\n",
    "nvidia-smi\n",
    "\n",
    "# 监控CPU和内存使用\n",
    "top\n",
    "\n",
    "# 查看系统日志\n",
    "tail -f logs/gradio_app_*.log\n",
    "```"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "py35-paddle1.2.0"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
