{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 大模型应用开发：RAG篇\n",
    "\n",
    "## 一、什么是RAG？\n",
    "\n",
    "### 1.1 RAG的核心概念\n",
    "检索增强生成（Retrieval-Augmented Generation，简称RAG）是一种将\"信息检索\"与\"大语言模型（LLM）\"结合的技术框架。简单说：\n",
    "- 让大模型在回答问题前，先\"查资料\"（从你的知识库中检索相关信息）\n",
    "- 再基于查到的资料生成答案，避免\"瞎编\"（减少幻觉）\n",
    "\n",
    "![](https://ai-studio-static-online.cdn.bcebos.com/c41c00052949463692fe89f05751e26bb08bf0d1bce74d76889a1958b7baa954)\n",
    "\n",
    "### 1.2 RAG解决的核心问题\n",
    "传统大模型的3大痛点，RAG来解决：\n",
    "- **知识过时**：模型训练数据有截止日期，RAG可实时调用最新知识\n",
    "- **幻觉生成**：模型可能编造错误信息，RAG让答案基于真实资料\n",
    "- **领域局限**：通用模型对专业领域知识不足，RAG可接入行业知识库\n",
    "\n",
    "![](https://ai-studio-static-online.cdn.bcebos.com/091ca1c290fd479da526488c6a400c262c902e01c8bc4314bb1a1521eb6b507f)\n",
    "![](https://ai-studio-static-online.cdn.bcebos.com/d87ee748c6c9416eb5d380585954c40d09ed166cf26244bc9169adefca3d1512)\n",
    "\n",
    "\n",
    "## 二、RAG的基本工作流程\n",
    "\n",
    "```mermaid\n",
    "graph TD\n",
    "    A[用户提问] --> B[问题解析]\n",
    "    B --> C[检索知识库]\n",
    "    C --> D[获取相关文档]\n",
    "    D --> E[拼接成提示词]\n",
    "    E --> F[大模型生成答案]\n",
    "    F --> G[输出结果]\n",
    "```\n",
    "\n",
    "具体步骤：\n",
    "1. **用户提问**：比如\"文心大模型4.5有什么新功能？\"\n",
    "2. **问题解析**：提取关键词\"文心大模型4.5\"\"新功能\"\n",
    "3. **检索知识库**：从你的文档中找关于文心4.5的内容\n",
    "4. **获取相关文档**：返回2-3段最相关的描述\n",
    "5. **生成提示词**：把问题+相关文档组合成提示（如\"根据以下内容回答：[文档] 问题：...\"）\n",
    "6. **模型生成**：本地部署的ERNIE-4.5-21B-A3B模型基于提示生成答案\n",
    "7. **输出结果**：返回带资料依据的回答\n",
    "\n",
    "![](https://ai-studio-static-online.cdn.bcebos.com/b6eef408e01d4becaca2efa6b839a3fef79a2790b53448c8a407cb395914fb1f)\n",
    "\n",
    "## 三、RAG系统的核心组件\n",
    "\n",
    "### 3.1 三大核心模块\n",
    "1. **知识库**：你的私有资料（文档、网页、对话记录等）\n",
    "2. **检索器**：从知识库中快速找到与问题相关的内容（关键是\"向量数据库\"）\n",
    "3. **生成器**：本地部署的ERNIE-4.5-21B-A3B模型（基于检索到的内容生成答案）\n",
    "\n",
    "### 3.2 向量数据库是什么？\n",
    "- 把文本转换成\"数字向量\"（类似文字的\"数学指纹\"）\n",
    "- 两个文本语义越像，向量距离越近\n",
    "\n",
    "## 四、文心开源模型的选择\n",
    "\n",
    "### 4.1 ERNIE-4.5模型系列规格对比表\n",
    "\n",
    "| 模型系列 | 模型名称 | 总参数 | 激活参数 | 模态支持 | 上下文长度 | 主要用途 | 部署场景 |\n",
    "|---------|---------|--------|---------|---------|-----------|---------|---------|\n",
    "| **A47B大规模** | ERNIE-4.5-300B-A47B-Base | 300B | 47B | 文本 | 128K | 预训练基座 | 云端GPU集群 |\n",
    "| | ERNIE-4.5-300B-A47B | 300B | 47B | 文本 | 128K | 指令遵循/创意生成 | 云端GPU集群 |\n",
    "| | ERNIE-4.5-VL-424B-A47B-Base | 424B | 47B | 文本+视觉 | 128K | 多模态预训练 | 云端GPU集群 |\n",
    "| | ERNIE-4.5-VL-424B-A47B | 424B | 47B | 文本+视觉 | 128K | 图文理解/生成 | 云端GPU集群 |\n",
    "| **A3B中等规模** | ERNIE-4.5-21B-A3B-Base | 21B | 3B | 文本 | 128K | 预训练基座 | 单机多卡 |\n",
    "| | **ERNIE-4.5-21B-A3B** | **21B** | **3B** | **文本** | **128K** | **对话/文档处理** | **单机多卡** |\n",
    "| | ERNIE-4.5-VL-28B-A3B-Base | 28B | 3B | 文本+视觉 | 128K | 多模态预训练 | 单机多卡 |\n",
    "| | ERNIE-4.5-VL-28B-A3B | 28B | 3B | 文本+视觉 | 128K | 轻量多模态应用 | 单机多卡 |\n",
    "| **0.3B轻量** | ERNIE-4.5-0.3B-Base | 0.3B | 0.3B | 文本 | 4K | 端侧预训练 | 移动端/边缘 |\n",
    "| | ERNIE-4.5-0.3B | 0.3B | 0.3B | 文本 | 4K | 实时对话 | 移动端/边缘 |\n",
    "\n",
    "### 4.2 模型规格选择策略表\n",
    "\n",
    "| 应用场景 | 推荐模型 | 理由 | 硬件要求 | 推理延迟 |\n",
    "|---------|---------|------|---------|---------|\n",
    "| **复杂推理任务** | ERNIE-4.5-300B-A47B | 最强推理能力 | 8×A100(80GB) | 高 |\n",
    "| **创意内容生成** | ERNIE-4.5-300B-A47B | 最佳创意表现 | 8×A100(80GB) | 高 |\n",
    "| **多模态理解** | ERNIE-4.5-VL-424B-A47B | 图文融合理解 | 8×A100(80GB) | 高 |\n",
    "| **日常对话客服** | **ERNIE-4.5-21B-A3B** | **性能成本平衡** | **4×V100(32GB)** | **中** |\n",
    "| **文档信息抽取** | **ERNIE-4.5-21B-A3B** | **理解能力充足** | **4×V100(32GB)** | **中** |\n",
    "| **轻量多模态** | ERNIE-4.5-VL-28B-A3B | 图文处理均衡 | 4×V100(32GB) | 中 |\n",
    "| **移动端应用** | ERNIE-4.5-0.3B | 低延迟快响应 | 1×GPU/CPU | 低 |\n",
    "| **边缘计算** | ERNIE-4.5-0.3B | 资源消耗最小 | CPU/NPU | 低 |\n",
    "\n",
    "**本教程选择ERNIE-4.5-21B-A3B的原因：**\n",
    "- 参数规模适中（21B总参数，3B激活参数），在性能和资源消耗间找到平衡\n",
    "- 支持128K长上下文，适合处理长文档\n",
    "- 对话和文档处理能力强，非常适合RAG应用场景\n",
    "\n",
    "## 五、动手实现：基础RAG系统\n",
    "\n",
    "### 5.1 环境准备\n",
    "#### 5.1.1 安装必要库"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-07-11T12:29:41.720323Z",
     "iopub.status.busy": "2025-07-11T12:29:41.720001Z",
     "iopub.status.idle": "2025-07-11T12:29:43.179791Z",
     "shell.execute_reply": "2025-07-11T12:29:43.178969Z",
     "shell.execute_reply.started": "2025-07-11T12:29:41.720303Z"
    },
    "scrolled": true,
    "tags": []
   },
   "outputs": [],
   "source": [
    "%%capture\n",
    "!pip install chromadb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-07-11T09:41:20.899848Z",
     "iopub.status.busy": "2025-07-11T09:41:20.899453Z",
     "iopub.status.idle": "2025-07-11T09:41:22.500888Z",
     "shell.execute_reply": "2025-07-11T09:41:22.499998Z",
     "shell.execute_reply.started": "2025-07-11T09:41:20.899820Z"
    },
    "scrolled": true,
    "tags": []
   },
   "outputs": [],
   "source": [
    "%%capture\n",
    "!python -m pip install fastdeploy-gpu -i https://www.paddlepaddle.org.cn/packages/stable/fastdeploy-gpu-80_90/ --extra-index-url https://mirrors.tuna.tsinghua.edu.cn/pypi/web/simple"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 5.1.2 模型下载与部署\n",
    "**1. 下载ERNIE-4.5-21B-A3B模型**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-07-11T09:41:24.963235Z",
     "iopub.status.busy": "2025-07-11T09:41:24.962840Z",
     "iopub.status.idle": "2025-07-11T09:41:27.805835Z",
     "shell.execute_reply": "2025-07-11T09:41:27.805159Z",
     "shell.execute_reply.started": "2025-07-11T09:41:24.963211Z"
    },
    "scrolled": true,
    "tags": []
   },
   "outputs": [],
   "source": [
    "%%capture\n",
    "# 使用AIStudio命令下载模型\n",
    "!aistudio download --model PaddlePaddle/ERNIE-4.5-21B-A3B-Paddle --local_dir /home/aistudio/work/models"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**2. 启动模型服务**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "python -m fastdeploy.entrypoints.openai.api_server \\\n",
    "       --model /home/aistudio/work/models \\\n",
    "       --port 7000 \\\n",
    "       --metrics-port 7001 \\\n",
    "       --engine-worker-queue-port 7001 \\\n",
    "       --max-model-len 32768 \\\n",
    "       --max-num-seqs 32"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**3. 测试模型连接**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-07-11T12:51:05.905972Z",
     "iopub.status.busy": "2025-07-11T12:51:05.905653Z",
     "iopub.status.idle": "2025-07-11T12:51:08.713126Z",
     "shell.execute_reply": "2025-07-11T12:51:08.712508Z",
     "shell.execute_reply.started": "2025-07-11T12:51:05.905952Z"
    },
    "scrolled": true,
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "您好！我是由Aistudio和文心大模型联合开发的智能助手。我的核心功能是通过自然语言交互，帮助用户完成知识问答、文本创作、代码调试、逻辑推理等任务。无论是学术研究、日常咨询还是创意生成，您都可以通过文字与我交流，我会结合多模态大模型的技术优势，提供准确、高效且符合语境的解决方案。\r\n",
      "\r\n",
      "我的设计理念是“理解需求，创造价值”，支持中英文双语交互，并持续通过用户反馈优化能力边界。如果您有任何具体需求（如数据分析、代码实现、文本润色等），欢迎随时告诉我，我会尽力协助！"
     ]
    }
   ],
   "source": [
    "import openai\n",
    "\n",
    "host = \"0.0.0.0\"\n",
    "port = \"7000\"\n",
    "client = openai.Client(base_url=f\"http://{host}:{port}/v1\", api_key=\"null\")\n",
    "\n",
    "response = client.chat.completions.create(\n",
    "    model=\"null\",\n",
    "    messages=[\n",
    "        {\"role\": \"user\", \"content\": \"你是Aistudio和文心大模型开发的智能助手，请介绍一下你自己.\"}\n",
    "    ],\n",
    "    stream=True,\n",
    ")\n",
    "\n",
    "for chunk in response:\n",
    "    if chunk.choices[0].delta:\n",
    "        print(chunk.choices[0].delta.content, end='')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5.2 第一步：文档处理"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-07-11T12:51:18.504417Z",
     "iopub.status.busy": "2025-07-11T12:51:18.504074Z",
     "iopub.status.idle": "2025-07-11T12:51:19.642176Z",
     "shell.execute_reply": "2025-07-11T12:51:19.641607Z",
     "shell.execute_reply.started": "2025-07-11T12:51:18.504397Z"
    },
    "scrolled": true,
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Building prefix dict from the default dictionary ...\r\n",
      "2025-07-11 20:51:18,778 - jieba - DEBUG - Building prefix dict from the default dictionary ...\r\n",
      "Loading model from cache /tmp/jieba.cache\r\n",
      "2025-07-11 20:51:18,778 - jieba - DEBUG - Loading model from cache /tmp/jieba.cache\r\n",
      "Loading model cost 0.667 seconds.\r\n",
      "2025-07-11 20:51:19,445 - jieba - DEBUG - Loading model cost 0.667 seconds.\r\n",
      "Prefix dict has been built successfully.\r\n",
      "2025-07-11 20:51:19,445 - jieba - DEBUG - Prefix dict has been built successfully.\r\n",
      "2025-07-11 20:51:19,445 - DocumentProcessor - INFO - 开始处理 5 个文档...\r\n",
      "Processing:   0%|                                         | 0/5 [00:00<?, ?it/s]2025-07-11 20:51:19,459 - DocumentProcessor - WARNING - Token数超标: 731/450\r\n",
      "2025-07-11 20:51:19,460 - DocumentProcessor - INFO - 成功处理 女巫玩法.txt => processed_data/processed_data.jsonl\r\n",
      "2025-07-11 20:51:19,469 - DocumentProcessor - WARNING - Token数超标: 566/450\r\n",
      "2025-07-11 20:51:19,471 - DocumentProcessor - INFO - 成功处理 猎人玩法.txt => processed_data/processed_data.jsonl\r\n",
      "2025-07-11 20:51:19,487 - DocumentProcessor - INFO - 成功处理 狼人玩法.txt => processed_data/processed_data.jsonl\r\n",
      "2025-07-11 20:51:19,500 - DocumentProcessor - WARNING - Token数超标: 589/450\r\n",
      "2025-07-11 20:51:19,503 - DocumentProcessor - INFO - 成功处理 平民玩法.txt => processed_data/processed_data.jsonl\r\n",
      "2025-07-11 20:51:19,515 - DocumentProcessor - WARNING - Token数超标: 793/450\r\n",
      "2025-07-11 20:51:19,516 - DocumentProcessor - INFO - 成功处理 预言家玩法.txt => processed_data/processed_data.jsonl\r\n",
      "Processing: 100%|█████████████████████████████████| 5/5 [00:00<00:00, 73.20it/s]\r\n"
     ]
    }
   ],
   "source": [
    "!python document_processor.py"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5.3 第二步：创建Chroma向量数据库、测试检索功能"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-07-11T12:52:22.264985Z",
     "iopub.status.busy": "2025-07-11T12:52:22.264633Z",
     "iopub.status.idle": "2025-07-11T12:52:40.902470Z",
     "shell.execute_reply": "2025-07-11T12:52:40.901882Z",
     "shell.execute_reply.started": "2025-07-11T12:52:22.264966Z"
    },
    "scrolled": true,
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-07-11 20:52:23,046 - ChromaBuilder - INFO - 🚀 开始构建Chroma知识库...\r\n",
      "2025-07-11 20:52:23,102 - chromadb.telemetry.product.posthog - INFO - Anonymized telemetry enabled. See                     https://docs.trychroma.com/telemetry for more information.\r\n",
      "2025-07-11 20:52:23,157 - ChromaBuilder - INFO - 使用ChromaDB默认嵌入函数\r\n",
      "2025-07-11 20:52:23,159 - ChromaBuilder - INFO - Chroma知识库初始化完成，数据目录: ./chroma_db\r\n",
      "2025-07-11 20:52:23,159 - ChromaBuilder - INFO - 找到 1 个JSONL文件\r\n",
      "构建知识库:   0%|                                         | 0/1 [00:00<?, ?it/s]2025-07-11 20:52:23,161 - ChromaBuilder - INFO - 开始从 processed_data/processed_data.jsonl 加载数据...\r\n",
      "2025-07-11 20:52:23,162 - ChromaBuilder - ERROR - 批量添加文档失败: Expected IDs to be unique, found duplicates of: 333dca46f32667f00ce6adff4a43f40e, 5cc95892c1ef7061451f7c769e9ed6f4, af452c146011ad354f5d81d27658f43f, 5c36d994c65c46cf1cc415bfda9172cb, b6551d553086493e832970c0dc8ad843, fcad930fca8e3ff39bbb9dbc46c1c066, cbbfb58e7d38dd3efb5e36be576b8c00, 1f71df488b3bee56006bd913a95928e4, fbc3e8f5726c1f7349f16493519970f4 in add.\r\n",
      "2025-07-11 20:52:34,133 - ChromaBuilder - INFO - 数据加载完成，集合 'data' 共有 9 个文档\r\n",
      "构建知识库: 100%|█████████████████████████████████| 1/1 [00:10<00:00, 10.97s/it]\r\n",
      "2025-07-11 20:52:34,134 - ChromaBuilder - INFO - 🎉 知识库构建完成！总共加载了 9 个文档\r\n",
      "2025-07-11 20:52:34,138 - ChromaBuilder - INFO - 📊 集合统计信息:\r\n",
      "2025-07-11 20:52:34,138 - ChromaBuilder - INFO -   knowledge_base: 0 个文档\r\n",
      "2025-07-11 20:52:34,138 - ChromaBuilder - INFO -   data: 9 个文档\r\n",
      "2025-07-11 20:52:34,138 - ChromaBuilder - INFO - ✅ Chroma数据库连接正常，共有 2 个集合\r\n",
      "2025-07-11 20:52:34,139 - ChromaBuilder - INFO -   📚 knowledge_base: 0 个文档\r\n",
      "2025-07-11 20:52:34,139 - ChromaBuilder - INFO -   📚 data: 9 个文档\r\n",
      "2025-07-11 20:52:34,141 - ChromaBuilder - INFO - 🔍 测试搜索: 女巫的高级玩法 (在集合: data)\r\n",
      "2025-07-11 20:52:34,349 - ChromaBuilder - INFO - 查询 '女巫的高级玩法...' 返回 3 个结果\r\n",
      "2025-07-11 20:52:34,349 - ChromaBuilder - INFO - 搜索结果:\r\n",
      "2025-07-11 20:52:34,349 - ChromaBuilder - INFO -   结果1 (相似度:-0.033): 平民玩法知识库（高阶分析版）\r\n",
      "核心目标：通过信息整合与逻辑建模，构建多维视角分析网，辅助神职精准归狼，同时避免成为轮次消耗品。...\r\n",
      "2025-07-11 20:52:34,349 - ChromaBuilder - INFO -     来源: knowledge_data/平民玩法.txt\r\n",
      "2025-07-11 20:52:34,349 - ChromaBuilder - INFO -   结果2 (相似度:-0.220): 若留我，今晚女巫毒5号\" → 狼人5号被迫自爆\r\n",
      "\r\n",
      "案例2：残局双杀\r\n",
      "\r\n",
      "配置：1狼1猎1民，猎人被刀→带走狼人，好人胜利\r\n",
      "\r\n",
      "案例3：概率欺诈\r\n",
      "\r\n",
      "猎人伪装平民保假预言家，诱使狼队刀真预言家→开枪带走悍跳狼...\r\n",
      "2025-07-11 20:52:34,349 - ChromaBuilder - INFO -     来源: knowledge_data/猎人玩法.txt\r\n",
      "2025-07-11 20:52:34,350 - ChromaBuilder - INFO -   结果3 (相似度:-0.273): 狼人玩法知识库（高阶战术版）\r\n",
      "核心目标：通过逻辑欺骗、身份伪装与夜间精准刀法，破坏好人阵营信息链，达成屠神/屠民胜利。一、夜间战术体系\r\n",
      "1. 刀法决策模型\r\n",
      "轮次\t优先级目标\t战术逻辑\r\n",
      "首夜\t女巫/预言...\r\n",
      "2025-07-11 20:52:34,350 - ChromaBuilder - INFO -     来源: knowledge_data/狼人玩法.txt\r\n",
      "2025-07-11 20:52:34,350 - ChromaBuilder - INFO - ✅ 知识库构建和测试完成！\r\n"
     ]
    }
   ],
   "source": [
    "!python chroma_builder.py"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5.4 第三步：调用本地ERNIE-4.5模型生成答案"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-07-11T12:53:35.573507Z",
     "iopub.status.busy": "2025-07-11T12:53:35.573152Z"
    },
    "scrolled": true,
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Building prefix dict from the default dictionary ...\r\n",
      "2025-07-11 20:53:35,694 - jieba - DEBUG - Building prefix dict from the default dictionary ...\r\n",
      "Loading model from cache /tmp/jieba.cache\r\n",
      "2025-07-11 20:53:35,695 - jieba - DEBUG - Loading model from cache /tmp/jieba.cache\r\n",
      "Loading model cost 0.677 seconds.\r\n",
      "2025-07-11 20:53:36,372 - jieba - DEBUG - Loading model cost 0.677 seconds.\r\n",
      "Prefix dict has been built successfully.\r\n",
      "2025-07-11 20:53:36,376 - jieba - DEBUG - Prefix dict has been built successfully.\r\n",
      "2025-07-11 20:53:36,952 - chromadb.telemetry.product.posthog - INFO - Anonymized telemetry enabled. See                     https://docs.trychroma.com/telemetry for more information.\r\n",
      "2025-07-11 20:53:37,009 - ChromaBuilder - INFO - 使用ChromaDB默认嵌入函数\r\n",
      "2025-07-11 20:53:37,012 - ChromaBuilder - INFO - Chroma知识库初始化完成，数据目录: ./chroma_db\r\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "🚀 初始化RAG智能问答系统...\r\n",
      "✅ 知识库已加载，共 9 个文档\r\n",
      "\r\n",
      "🎯 RAG智能问答系统 - 流式对话模式\r\n",
      "✨ 基于本地ERNIE-4.5-21B-A3B模型\r\n",
      "💡 输入问题开始对话，输入 'quit' 或 'exit' 退出\r\n",
      "💡 输入 'stats' 查看知识库统计信息\r\n",
      "💡 输入 'clear' 清屏\r\n",
      "============================================================\r\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "\r\n",
      "❓ 请输入您的问题:  狼人\r\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\r\n",
      "🔍 正在搜索相关资料...\r\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-07-11 20:53:52,587 - ChromaBuilder - INFO - 查询 '狼人...' 返回 3 个结果\r\n",
      "2025-07-11 20:53:52,599 - httpx - INFO - HTTP Request: POST http://0.0.0.0:7000/v1/chat/completions \"HTTP/1.1 200 OK\"\r\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "📚 找到 3 条相关资料，来源: knowledge_data/猎人玩法.txt, knowledge_data/狼人玩法.txt\r\n",
      "\r\n",
      "🤖 ERNIE-4.5 正在思考中\r\n",
      "✨ 回答: 根据提供的参考资料，以下是关于狼人玩法的详细回答：\r\n",
      "\r\n",
      "### 狼人玩法的核心策略与技巧\r\n",
      "\r\n",
      "1. **轮次压力应对表**  \r\n",
      "   - **3狼**：激进悍跳，快速压缩好人信息空间，通过频繁发言或误导性信息混淆好人阵营。  \r\n",
      "   - **2狼**：1狼倒钩+1狼深水，倒钩狼通过伪装好人归票关键神职，深水狼隐藏身份等待时机。  \r\n",
      "   - **1狼**：彻底隐藏，利用好人逻辑漏洞归票关键神职（如预言家、女巫），避免过早暴露。  \r\n",
      "   *信息来源：参考资料3（狼人玩法.txt）*\r\n",
      "\r\n",
      "2. **高阶思维模型**  \r\n",
      "   - **逆向思维推演**：假设自己是好人，构建逻辑链确保发言无矛盾，预判真预言家查验路径并干扰。  \r\n",
      "   - **贝叶斯概率计算**：根据存活人数动态估算屠神/屠民成功率（如剩4民2神1狼时，屠民需3刀，屠神需2刀）。  \r\n",
      "   - **信息污染技术**：  \r\n",
      "     - **虚假共边关系**：故意保一个好人（如“X号绝对好人，出他我买单”），诱导女巫怀疑X。  \r\n",
      "     - **时间线篡改**：伪造夜间信息（如“如果我是女巫，昨晚会毒Y号”），暗示Y可能有毒威胁。  \r\n",
      "   *信息来源：参考资料3（狼人玩法.txt）*\r\n",
      "\r\n",
      "3. **禁忌与容错机制**  \r\n",
      "   - **绝对禁忌行为**：  \r\n",
      "     - 夜间刀法违反优先级（如残局刀民却漏刀猎人）。  \r\n",
      "     - 悍跳预言家报假查杀却选中真预言家。  \r\n",
      "     - 倒钩狼过早暴露导致团队崩盘。  \r\n",
      "   - **容错修复方案**：  \r\n",
      "     - **刀中守卫盾**：次日谎称女巫用药，转移视线。  \r\n",
      "     - **悍跳被识破**：其他狼人立刻倒钩，反咬其“狼查杀”。  \r\n",
      "     - **误杀关键神职**：伪造遗言逻辑链，坐实其“自刀狼”身份。  \r\n",
      "   *信息来源：参考资料3（狼人玩法.txt）*\r\n",
      "\r\n",
      "4. **实战案例库**  \r\n",
      "   - **自刀+倒钩组合拳**：  \r\n",
      "     - 狼A首夜自刀，女巫救药→白天狼B悍跳发狼A金水→真预言家查验狼A为好人→狼C倒钩真预言家，最终污真预言家为狼。  \r\n",
      "   - **残局平衡屠边**：  \r\n",
      "     - 剩1狼（狼D）、1猎人、2民→狼D白天归票民，夜间刀猎人，触发屠民胜利。  \r\n",
      "   *信息来源：参考资料3（狼人玩法.txt）*\r\n",
      "\r\n",
      "### 猎人玩法对狼人的影响\r\n",
      "\r\n",
      "- **猎人伪装平民**：猎人可能伪装平民保假预言家，诱使狼队刀真预言家，随后开枪带走悍跳狼。  \r\n",
      "- **残局双杀案例**：若猎人被刀且携带技能，可带走狼人，好人阵营胜利。  \r\n",
      "*信息来源：参考资料1（猎人玩法.txt）*\r\n",
      "\r\n",
      "### 总结\r\n",
      "\r\n",
      "狼人玩法需结合轮次压力应对、高阶思维模型（如逆向推演、概率计算）、信息污染技术及禁忌行为管理。实战中需灵活运用自刀、倒钩、悍跳等策略，并通过容错机制修复失误。猎人伪装等案例进一步体现了狼人阵营的复杂性与策略深度。\r\n",
      "\r\n",
      "📖 参考来源: knowledge_data/猎人玩法.txt, knowledge_data/狼人玩法.txt\r\n",
      "------------------------------------------------------------\r\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "\r\n",
      "❓ 请输入您的问题:  平民玩法\r\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\r\n",
      "🔍 正在搜索相关资料...\r\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-07-11 20:54:41,438 - ChromaBuilder - INFO - 查询 '平民玩法...' 返回 3 个结果\r\n",
      "2025-07-11 20:54:41,447 - httpx - INFO - HTTP Request: POST http://0.0.0.0:7000/v1/chat/completions \"HTTP/1.1 200 OK\"\r\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "📚 找到 3 条相关资料，来源: knowledge_data/猎人玩法.txt, knowledge_data/平民玩法.txt, knowledge_data/狼人玩法.txt\r\n",
      "\r\n",
      "🤖 ERNIE-4.5 正在思考中\r\n",
      "✨ 回答: 根据提供的参考资料，平民玩法的核心目标是通过信息整合与逻辑建模，构建多维视角分析网，辅助神职精准归狼，同时避免成为轮次消耗品。然而，参考资料中并未直接提供平民玩法的具体操作策略或详细步骤。\r\n",
      "\r\n",
      "在狼人杀游戏中，平民（普通玩家）通常不拥有特殊技能，但可以通过观察其他玩家的行为、发言和投票模式来辅助神职玩家（如预言家、女巫、猎人等）进行归谬。以下是一些平民玩家可能采取的一般性策略：\r\n",
      "\r\n",
      "1. **观察与记录**：平民玩家应密切关注其他玩家的发言和行为，记录下任何可疑或异常的举动。这有助于在后续的投票中做出更准确的判断。\r\n",
      "\r\n",
      "2. **辅助神职**：平民玩家可以尝试与神职玩家建立联系，提供信息或支持他们的判断。例如，如果预言家查杀了某个玩家，平民玩家可以询问预言家的理由，并尝试验证这些信息的真实性。\r\n",
      "\r\n",
      "3. **避免暴露**：平民玩家应尽量避免在游戏中暴露自己的身份或立场，以免成为狼队的攻击目标。这包括在发言中保持中立、不发表过于激进的言论等。\r\n",
      "\r\n",
      "4. **理性投票**：在投票环节，平民玩家应基于观察到的信息和逻辑推理进行投票，避免盲目跟风或冲动投票。\r\n",
      "\r\n",
      "5. **团队合作**：平民玩家应与其他好人玩家保持紧密合作，共同对抗狼队。这包括在游戏中分享信息、互相支持等。\r\n",
      "\r\n",
      "需要注意的是，以上策略是基于狼人杀游戏的一般性规则和逻辑推理得出的，并非针对平民玩法的特定操作指南。由于参考资料中未提供平民玩法的具体策略，因此以上回答仅为一般性建议。\r\n",
      "\r\n",
      "信息来源：平民玩法知识库（高阶分析版），知识库中强调了平民玩法的核心目标是通过信息整合与逻辑建模辅助神职归狼，但未提供具体操作策略。\r\n",
      "\r\n",
      "📖 参考来源: knowledge_data/猎人玩法.txt, knowledge_data/平民玩法.txt, knowledge_data/狼人玩法.txt\r\n",
      "------------------------------------------------------------\r\n"
     ]
    }
   ],
   "source": [
    "# rag_example.py\n",
    "\n",
    "import os\n",
    "import logging\n",
    "from pathlib import Path\n",
    "import openai\n",
    "from document_processor import DocumentProcessor\n",
    "from chroma_builder import ChromaKnowledgeBase, build_knowledge_base_from_processed_data\n",
    "\n",
    "# 配置日志 - 只显示错误和警告\n",
    "logging.basicConfig(\n",
    "    level=logging.WARNING,\n",
    "    format='%(levelname)s: %(message)s'\n",
    ")\n",
    "logger = logging.getLogger(\"RAGExample\")\n",
    "\n",
    "class ERNIERAGSystem:\n",
    "    def __init__(self, \n",
    "                 ernie_host: str = \"0.0.0.0\",\n",
    "                 ernie_port: str = \"7000\",\n",
    "                 chroma_db_dir: str = \"./chroma_db\",\n",
    "                 embedding_model: str = \"default\"):\n",
    "        \"\"\"\n",
    "        初始化RAG系统\n",
    "        \n",
    "        Args:\n",
    "            ernie_host: ERNIE模型服务主机\n",
    "            ernie_port: ERNIE模型服务端口\n",
    "            chroma_db_dir: Chroma数据库目录\n",
    "            embedding_model: 嵌入模型类型\n",
    "        \"\"\"\n",
    "        # 初始化本地ERNIE模型客户端\n",
    "        self.ernie_client = openai.Client(\n",
    "            base_url=f\"http://{ernie_host}:{ernie_port}/v1\", \n",
    "            api_key=\"null\"\n",
    "        )\n",
    "        \n",
    "        # 初始化知识库\n",
    "        self.knowledge_base = ChromaKnowledgeBase(\n",
    "            persist_directory=chroma_db_dir,\n",
    "            embedding_model=embedding_model\n",
    "        )\n",
    "\n",
    "    def retrieve_relevant_docs(self, question: str, top_k: int = 3, \n",
    "                             collection_name: str = None) -> list:\n",
    "        \"\"\"检索相关文档\"\"\"\n",
    "        # 如果没有指定集合名，自动选择有数据的集合\n",
    "        if collection_name is None:\n",
    "            stats = self.knowledge_base.get_collection_stats()\n",
    "            for name, info in stats.items():\n",
    "                if info['document_count'] > 0:\n",
    "                    collection_name = name\n",
    "                    break\n",
    "            \n",
    "            if collection_name is None:\n",
    "                return []\n",
    "        \n",
    "        results = self.knowledge_base.search_knowledge(\n",
    "            query=question,\n",
    "            collection_name=collection_name,\n",
    "            n_results=top_k\n",
    "        )\n",
    "        \n",
    "        documents = results[\"documents\"][0]\n",
    "        metadatas = results[\"metadatas\"][0]\n",
    "        distances = results[\"distances\"][0]\n",
    "        \n",
    "        # 格式化检索结果\n",
    "        retrieved_docs = []\n",
    "        for i, (doc, metadata, distance) in enumerate(zip(documents, metadatas, distances)):\n",
    "            similarity = 1 - distance\n",
    "            retrieved_docs.append({\n",
    "                \"text\": doc,\n",
    "                \"metadata\": metadata,\n",
    "                \"similarity\": similarity,\n",
    "                \"rank\": i + 1\n",
    "            })\n",
    "        \n",
    "        return retrieved_docs\n",
    "\n",
    "    def generate_answer_stream(self, question: str, context_docs: list, \n",
    "                             max_tokens: int = 1000, temperature: float = 0.7):\n",
    "        \"\"\"使用ERNIE模型流式生成答案\"\"\"\n",
    "        \n",
    "        # 构建上下文\n",
    "        context_parts = []\n",
    "        for i, doc_info in enumerate(context_docs):\n",
    "            source = doc_info[\"metadata\"].get(\"source\", \"未知来源\")\n",
    "            similarity = doc_info[\"similarity\"]\n",
    "            context_parts.append(f\"参考资料{i+1} (相似度:{similarity:.3f}，来源:{source}):\\n{doc_info['text']}\")\n",
    "        \n",
    "        context_text = \"\\n\\n\".join(context_parts)\n",
    "        \n",
    "        # 构建提示词\n",
    "        prompt = f\"\"\"请根据以下参考资料回答问题。如果参考资料中没有相关信息，请明确说明\"根据提供的参考资料无法完全回答此问题\"。\n",
    "\n",
    "参考资料：\n",
    "{context_text}\n",
    "\n",
    "问题：{question}\n",
    "\n",
    "请基于以上参考资料给出准确、详细的回答，并在适当位置标注信息来源：\"\"\"\n",
    "\n",
    "        try:\n",
    "            # 调用本地ERNIE模型（流式）\n",
    "            response = self.ernie_client.chat.completions.create(\n",
    "                model=\"null\",\n",
    "                messages=[{\"role\": \"user\", \"content\": prompt}],\n",
    "                max_tokens=max_tokens,\n",
    "                temperature=temperature,\n",
    "                stream=True  # 开启流式输出\n",
    "            )\n",
    "            \n",
    "            return response\n",
    "            \n",
    "        except Exception as e:\n",
    "            logger.error(f\"❌ 调用ERNIE模型失败: {e}\")\n",
    "            return None\n",
    "\n",
    "    def ask_stream(self, question: str, top_k: int = 3, collection_name: str = None):\n",
    "        \"\"\"流式RAG问答流程\"\"\"\n",
    "        print(f\"\\n🔍 正在搜索相关资料...\")\n",
    "        \n",
    "        # 1. 检索相关文档\n",
    "        retrieved_docs = self.retrieve_relevant_docs(question, top_k, collection_name)\n",
    "        \n",
    "        if not retrieved_docs:\n",
    "            print(\"💔 抱歉，未找到相关的参考资料来回答您的问题。\")\n",
    "            return\n",
    "        \n",
    "        # 显示检索到的资料信息\n",
    "        sources = list(set([doc[\"metadata\"].get(\"source\", \"未知来源\") for doc in retrieved_docs]))\n",
    "        print(f\"📚 找到 {len(retrieved_docs)} 条相关资料，来源: {', '.join(sources)}\")\n",
    "        print(f\"\\n🤖 ERNIE-4.5 正在思考中\")\n",
    "        \n",
    "        # 2. 流式生成答案\n",
    "        response_stream = self.generate_answer_stream(question, retrieved_docs)\n",
    "        \n",
    "        if response_stream is None:\n",
    "            print(\"❌ 生成答案时遇到错误，请检查ERNIE模型服务是否正常。\")\n",
    "            return\n",
    "        \n",
    "        print(\"✨ 回答: \", end=\"\", flush=True)\n",
    "        \n",
    "        # 处理流式响应\n",
    "        full_answer = \"\"\n",
    "        try:\n",
    "            for chunk in response_stream:\n",
    "                if chunk.choices[0].delta and chunk.choices[0].delta.content:\n",
    "                    content = chunk.choices[0].delta.content\n",
    "                    print(content, end=\"\", flush=True)\n",
    "                    full_answer += content\n",
    "            \n",
    "            print(f\"\\n\\n📖 参考来源: {', '.join(sources)}\")\n",
    "            print(\"-\" * 60)\n",
    "            \n",
    "        except Exception as e:\n",
    "            print(f\"\\n❌ 流式输出过程中出现错误: {e}\")\n",
    "            \n",
    "        return full_answer\n",
    "\n",
    "\n",
    "\n",
    "def interactive_rag_chat(rag_system: ERNIERAGSystem):\n",
    "    \"\"\"交互式RAG流式对话\"\"\"\n",
    "    print(\"\\n🎯 RAG智能问答系统 - 流式对话模式\")\n",
    "    print(\"✨ 基于本地ERNIE-4.5-21B-A3B模型\")\n",
    "    print(\"💡 输入问题开始对话，输入 'quit' 或 'exit' 退出\")\n",
    "    print(\"💡 输入 'stats' 查看知识库统计信息\")\n",
    "    print(\"💡 输入 'clear' 清屏\")\n",
    "    print(\"=\" * 60)\n",
    "    \n",
    "    while True:\n",
    "        try:\n",
    "            question = input(\"\\n❓ 请输入您的问题: \").strip()\n",
    "            \n",
    "            if question.lower() in ['quit', 'exit', '退出', 'q']:\n",
    "                print(\"\\n👋 感谢使用RAG智能问答系统，再见！\")\n",
    "                break\n",
    "            elif question.lower() == 'stats':\n",
    "                stats = rag_system.knowledge_base.get_collection_stats()\n",
    "                print(\"\\n📊 知识库统计信息:\")\n",
    "                total_docs = 0\n",
    "                for name, info in stats.items():\n",
    "                    count = info['document_count']\n",
    "                    total_docs += count\n",
    "                    if count > 0:\n",
    "                        print(f\"  ✅ {name}: {count} 个文档\")\n",
    "                    else:\n",
    "                        print(f\"  ⚪ {name}: {count} 个文档\")\n",
    "                print(f\"📈 总计: {total_docs} 个文档\")\n",
    "                continue\n",
    "            elif question.lower() == 'clear':\n",
    "                import os\n",
    "                os.system('cls' if os.name == 'nt' else 'clear')\n",
    "                print(\"🎯 RAG智能问答系统 - 流式对话模式\")\n",
    "                continue\n",
    "            elif not question:\n",
    "                print(\"⚠️ 请输入有效的问题\")\n",
    "                continue\n",
    "            \n",
    "            # 进行RAG流式问答\n",
    "            rag_system.ask_stream(question, top_k=3)\n",
    "            \n",
    "        except KeyboardInterrupt:\n",
    "            print(\"\\n\\n👋 程序已中断，再见！\")\n",
    "            break\n",
    "        except Exception as e:\n",
    "            print(f\"\\n❌ 发生错误: {e}\")\n",
    "            print(\"💡 请检查ERNIE模型服务是否正常运行\")\n",
    "\n",
    "def main():\n",
    "    \"\"\"主程序入口\"\"\"\n",
    "    print(\"🚀 初始化RAG智能问答系统...\")\n",
    "    \n",
    "    try:\n",
    "        # 直接初始化RAG系统\n",
    "        rag_system = ERNIERAGSystem(\n",
    "            ernie_host=\"0.0.0.0\",\n",
    "            ernie_port=\"7000\",\n",
    "            chroma_db_dir=\"./chroma_db\",\n",
    "            embedding_model=\"default\"\n",
    "        )\n",
    "        \n",
    "        # 检查知识库是否有数据\n",
    "        stats = rag_system.knowledge_base.get_collection_stats()\n",
    "        total_docs = sum(info['document_count'] for info in stats.values())\n",
    "        \n",
    "        if total_docs == 0:\n",
    "            print(\"⚠️ 警告: 知识库中没有数据！\")\n",
    "            print(\"💡 请先运行以下命令构建知识库:\")\n",
    "            print(\"   python document_processor.py\")\n",
    "            print(\"   python chroma_builder.py\")\n",
    "            return\n",
    "        \n",
    "        print(f\"✅ 知识库已加载，共 {total_docs} 个文档\")\n",
    "        \n",
    "        # 启动交互式对话\n",
    "        interactive_rag_chat(rag_system)\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"❌ 系统初始化失败: {e}\")\n",
    "        print(\"💡 请检查:\")\n",
    "        print(\"  1. ERNIE模型服务是否在7000端口运行\")\n",
    "        print(\"  2. 知识库目录 ./chroma_db 是否存在\")\n",
    "        print(\"  3. 相关依赖是否正确安装\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 六、RAG的行业应用场景\n",
    "\n",
    "### 6.1 企业客服\n",
    "- 用RAG接入产品手册、售后流程，客服机器人实时调用最新资料回答用户问题，减少人工干预\n",
    "- **本地化优势**：企业数据不出公司，保证数据安全\n",
    "\n",
    "### 6.2 医疗辅助\n",
    "- 医生输入患者症状，RAG检索最新临床指南和病例，辅助医生判断可能病因（需专业审核）\n",
    "- **本地化优势**：患者隐私数据完全本地化处理\n",
    "\n",
    "### 6.3 教育辅导\n",
    "- 学生提问数学题，RAG从教材和习题集中找相关知识点，大模型基于教材内容讲解，确保和教学同步\n",
    "- **本地化优势**：教学内容可控，无需担心网络连接问题\n",
    "\n",
    "### 6.4 法律检索\n",
    "- 律师输入案件情况，RAG检索相关法条和判例，大模型生成法律分析，提高检索效率\n",
    "- **本地化优势**：案件信息保密，符合法律行业数据安全要求\n",
    "\n",
    "## 七、初学者优化小技巧\n",
    "\n",
    "1. **文本分块优化**：长文档拆分时，按\"语义完整\"拆分（如按段落），避免切断句子\n",
    "   ```python\n",
    "   from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
    "   text_splitter = RecursiveCharacterTextSplitter(\n",
    "       chunk_size=500, \n",
    "       chunk_overlap=50,\n",
    "       separators=[\"\\n\\n\", \"\\n\", \"。\", \"！\", \"？\", \"；\"]\n",
    "   )\n",
    "   chunks = text_splitter.split_text(long_document)\n",
    "   ```\n",
    "\n",
    "2. **提示词优化**：明确告诉模型\"只基于提供的资料回答\"\n",
    "   ```\n",
    "   请严格根据以下资料回答，资料外的信息不要提及。如果资料不足，直接说\"根据提供的资料无法回答此问题\"。\n",
    "   资料：{context}\n",
    "   问题：{question}\n",
    "   ```\n",
    "\n",
    "通过以上步骤，你已经掌握了基于本地部署ERNIE-4.5-21B-A3B模型的RAG系统核心逻辑和完整实现。这套方案既保证了数据安全（完全本地化），又提供了强大的知识问答能力，是企业级RAG应用的理想选择～"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "py35-paddle1.2.0"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
